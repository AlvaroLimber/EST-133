[
["index.html", "Estadística I EST-133 Prefacio Audiencia Estructura del libro Software y acuerdos", " Estadística I EST-133 Alvaro Chirino Gutierrez 2020-12-06 Prefacio Este documento de Alvaro Chirino esta bajo la licencia de Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Audiencia El libro fue diseñado originalmente para los estudiantes de la materia de Estadística I, de la carrera de Informática de la Universidad Mayor de San Andres. Estructura del libro El libro inluye 5 capitulos, estos son: Estadística Descriptiva Probabilidades Variable Aleatoria Distribuciones discretas Distribuciones continuas Software y acuerdos El sofware de apoyo que se emplea es R, para la instalación y otros tutoriales se recomienda ver acá sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19041) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Spanish_Bolivia.1252 ## [2] LC_CTYPE=Spanish_Bolivia.1252 ## [3] LC_MONETARY=Spanish_Bolivia.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=Spanish_Bolivia.1252 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods ## [7] base ## ## loaded via a namespace (and not attached): ## [1] compiler_4.0.3 magrittr_2.0.1 bookdown_0.18 ## [4] htmltools_0.5.0 tools_4.0.3 rstudioapi_0.11 ## [7] yaml_2.2.1 stringi_1.5.3 rmarkdown_2.5 ## [10] knitr_1.30 stringr_1.4.0 xfun_0.19 ## [13] digest_0.6.27 packrat_0.5.0 rlang_0.4.9 ## [16] evaluate_0.14 "],
["tema-1-estadística-descriptiva.html", "1 Tema 1: Estadística Descriptiva 1.1 Definición de la estadística. 1.2 Historia 1.3 Conceptos importantes 1.4 Ordenando los datos 1.5 Medidas de tendencia central 1.6 Medidas de dispersión 1.7 Gráficos", " 1 Tema 1: Estadística Descriptiva 1.1 Definición de la estadística. El arte de contar una historia con datos La información, los datos, son la fuente primaria para la estadística. La estadística cubre los métodos, técnicas detrás de: Recolección de información Procesar la información (limpieza, depuración, coherencia, etc.) Análisis de la información Visualización de la información Es una ciencia transversal La estadística es la gramática de las ciencia La ciencia de datos en el nombre sexy de la estadística 1.2 Historia Censo. En la antigüedad se listaba de forma completa una determinada población, con el fin de conocer sus características. (Estadística descriptiva) Censos de población y vivienda (2012, 2001, 1992, 1976, etc.) Censos de Agropecuario (2013, 1984) Censos económicos, unidades económicas de un país o región. Muestra e inferencia. El objetivo de esta fase es explicar lo que le sucede a una población a partir de una muestra de ella. (Probabilidad, variables aleatorias). Explosión de conocimiento. Nace a partir de la aparición del ordenador. Minería de datos, machine learning, ciencia de datos, big data, etc. 1.2.1 Tarea de repaso. Buscar los conceptos de: Machine learning Minería de datos Minería de texto Estadística multivariante 1.3 Conceptos importantes 1.3.1 Población Una colección de objetos/elementos, por ejemplo; personas, cosas, animales, etc. Sea la población o universo de estudio identificado como \\(U\\). Debemos distinguir entre las poblaciones finitas y poblaciones infinitas, en este capítulo se trabaja sobre universos finitos. \\[U=\\{u_1, u_2, \\ldots u_i,\\ldots, u_N \\}\\] ### Muestra Es un sub conjunto del universo, lo vamos a denotar con \\(s\\). \\(s \\subset U\\). \\[s=\\{u_{(1)}, u_{(2), \\ldots}, u_{(n)} \\}\\] Donde \\(u_{(i)} \\in U\\). Nota: El tamaño del universo o la población sera denotado por \\(N\\), y \\(n\\) al tamaño de la muestra. 1.3.2 Variable Una variable en estadística expresa una característica asociado a algún elemento en la población. Normalmente esta se la denota con \\(X\\) e \\(Y\\). Por ejemplo, en la población de estudiantes inscritos en la materia de EST-133(c) el tamaño es \\(N=90\\) los elementos de esta población corresponden a estudiantes de la carrera de informática algunas variables en esta población pueden ser: (\\(X\\)) Edad (\\(Y\\)) Sexo (\\(Z\\)) Horas de sueño la pasada noche (\\(W\\)) El color de los ojos (\\(V\\)) El número de celular Las variables asociadas a un elemento en la población, la podemos denotar de la siguiente forma: \\[u_i=\\{X_{i1}, X_{i2},\\ldots, X_{ip} \\}\\] Siguiendo el ejemplo: \\[u_{Juana}=\\{ 23, Mujer, 5, Cafe, 77777777 \\}\\] ## Tipos de variables 1.3.3 Cualitativos (cualidades) No se pueden realizar operaciones algebraicas sobre este tipo de variables. Estas tienen una sub clasificación: Nominales: Las categorías de la variable no tienen un orden de jerarquía (el orden no importa) Ordinales: Las categorías de la variable tienen un orden de jerarquía (el orden importa) Ejercicio de clase. Definan una población, sus elementos y liste al menos 3 variables cualitativas nominales y 2 variables cualitativas ordinales. Resp. 1: Universo, Doctores que vivan en el municipio de La Paz, elemento: Doctor/a. nominales: lugar de trabajo, si tiene familia, apellido ordinales: nivel de postgrado, cargo, especialidad (si, no) Resp. 2: Universo, clase de estudiantes de colegio, sus elementos, los alumnos que conforman la clase. cualitativas nominales apellido, nombre, género cualitativas ordinales: cargo dentro del gobierno estudiantil, rendimiento escolar (malo, regular, bueno) Resp. 3: universo: televisores que están en venta en la ciudad de La Paz; elementos los diferentes tipos de televisores que existan ; * variables cualitativas nominales -&gt; color, material; * variables cualitativas ordinales -&gt; modelo, garantía, marca. 1.3.4 Cuantitativos (cantidad) Se pueden realizar operaciones algebraicas. Estas se dividen en 2. Discretas: Numerables, ejemplos; edad en años, precio de un televisor, peso en kilogramos, la altura en cm, la cantidad de personas es un evento. Continuas: No numerables; edad de una persona, cualquier variables definida en los números reales. Nota: Las variables continuas se pueden volver variables discretas (discretizar una variable) Nota: Todo el contenido de la materia en adelante esta mas relacionado con variables cuantitativas. 1.4 Ordenando los datos La idea de este punto es conocer las formas en las que se puede manejar las información disponible. Podemos observar tres formas de ordenar la información proveniente de una sola variable. Imaginar que tenemos la información de edades de una población de 1000 personas. ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union Mantenerlos en su forma simple (Datos no ordenados, datos simples). ## [1] 11 62 61 62 86 64 1 23 67 51 69 54 28 92 29 ## [16] 84 29 27 19 23 32 30 16 4 22 81 53 91 83 5 ## [31] 46 27 30 51 18 76 20 26 99 81 55 65 31 62 33 ## [46] 50 68 48 24 77 7 31 72 50 15 50 49 75 17 85 ## [61] 86 4 32 1 24 71 31 51 5 56 12 89 1 78 9 ## [76] 52 38 7 32 67 93 47 14 54 20 90 39 31 16 90 ## [91] 17 90 13 13 11 51 30 3 31 74 4 57 28 20 13 ## [106] 33 16 13 44 4 71 10 95 12 22 91 95 28 12 80 ## [121] 74 92 99 94 49 28 25 50 50 32 96 63 13 42 91 ## [136] 47 91 60 63 87 50 98 32 48 36 63 74 57 98 58 ## [151] 44 23 8 85 23 99 60 100 38 56 43 58 43 22 8 ## [166] 64 43 7 80 33 76 58 71 43 34 76 42 56 12 30 ## [181] 48 34 60 8 96 2 84 63 31 74 64 99 13 88 81 ## [196] 82 83 73 98 64 66 53 32 77 53 73 31 40 20 99 ## [211] 57 28 19 76 57 93 64 70 48 85 42 3 26 33 13 ## [226] 50 80 34 51 49 80 57 11 81 57 21 75 31 49 99 ## [241] 42 24 22 69 98 48 77 57 97 80 53 60 26 28 7 ## [256] 56 26 0 59 52 84 3 60 27 12 10 75 2 5 75 ## [271] 36 76 38 80 3 51 82 54 27 34 37 43 92 78 74 ## [286] 28 46 29 70 82 66 41 95 24 61 76 69 12 64 31 ## [301] 35 98 54 44 95 45 19 99 55 77 91 68 41 41 15 ## [316] 20 19 41 35 83 20 86 40 15 34 37 43 19 66 92 ## [331] 73 88 95 19 47 39 37 3 93 41 96 27 52 98 37 ## [346] 31 3 67 92 4 20 74 13 71 100 94 59 73 49 77 ## [361] 0 56 46 33 84 98 66 23 82 72 98 27 88 49 31 ## [376] 40 76 10 42 66 30 21 0 11 21 12 69 19 98 95 ## [391] 69 74 73 65 17 92 56 54 2 37 69 42 76 78 57 ## [406] 19 76 9 62 42 78 81 97 22 87 42 51 77 13 41 ## [421] 66 91 34 11 93 20 5 43 34 28 66 78 44 93 27 ## [436] 66 38 94 74 59 81 88 75 50 99 56 88 63 61 3 ## [451] 25 78 100 96 75 68 25 61 57 5 37 89 39 52 18 ## [466] 19 55 39 63 57 14 29 0 96 40 98 51 47 72 14 ## [481] 52 56 66 37 14 7 76 70 76 16 60 76 91 31 66 ## [496] 34 60 8 61 60 67 80 86 5 67 85 75 83 13 79 ## [511] 36 95 93 59 11 78 60 9 66 33 84 25 36 92 56 ## [526] 81 4 4 63 24 25 62 41 80 12 99 65 66 75 51 ## [541] 38 61 97 22 75 43 83 88 98 91 26 22 79 17 84 ## [556] 97 50 4 63 83 16 99 68 86 24 86 79 61 21 6 ## [571] 63 80 20 67 40 39 6 42 55 82 84 1 57 30 4 ## [586] 36 27 97 95 62 96 88 12 60 36 67 64 70 63 12 ## [601] 28 17 17 56 43 39 84 21 51 39 26 80 31 8 95 ## [616] 38 33 66 78 48 93 5 67 83 34 93 48 95 31 60 ## [631] 89 61 44 56 94 83 29 84 26 34 56 19 51 93 31 ## [646] 36 6 88 51 80 24 69 86 45 17 51 87 3 26 94 ## [661] 62 95 82 5 30 51 71 28 46 73 13 93 39 25 95 ## [676] 84 42 89 21 95 48 11 63 29 83 33 87 3 54 48 ## [691] 88 49 22 51 1 9 32 55 30 74 1 60 71 47 22 ## [706] 12 41 64 6 57 71 98 97 12 19 19 46 20 97 10 ## [721] 82 10 97 1 50 99 44 34 31 99 92 1 10 54 62 ## [736] 79 48 81 99 93 27 10 7 19 59 0 48 66 20 66 ## [751] 55 74 39 84 25 89 69 92 37 62 3 65 0 58 28 ## [766] 61 93 57 80 30 89 86 84 7 62 51 7 22 58 36 ## [781] 94 6 0 29 22 69 86 3 70 17 79 15 68 52 70 ## [796] 26 51 82 18 86 11 87 51 29 34 57 18 44 66 42 ## [811] 56 20 93 67 13 38 30 81 47 44 8 37 39 39 24 ## [826] 79 2 40 39 46 30 80 87 94 27 68 71 20 56 62 ## [841] 11 58 65 19 46 92 57 94 74 72 55 98 94 18 55 ## [856] 64 10 4 77 96 11 40 3 41 21 92 23 98 27 53 ## [871] 95 90 95 30 77 19 10 9 51 58 69 25 45 54 57 ## [886] 93 17 4 10 2 92 75 61 38 34 33 63 63 98 87 ## [901] 64 41 92 45 91 3 34 26 78 30 26 47 7 23 11 ## [916] 8 44 98 96 80 54 46 21 23 59 26 76 55 10 15 ## [931] 15 99 3 61 10 51 19 51 39 59 92 58 81 77 61 ## [946] 53 29 12 48 37 71 95 31 82 86 5 86 48 12 66 ## [961] 23 46 89 79 5 7 66 23 59 33 100 71 0 77 20 ## [976] 69 75 24 95 58 80 93 8 66 99 25 4 99 13 18 ## [991] 48 64 99 10 69 0 77 32 96 20 Tenerlos en una tabla de frecuencias, es una tabla que para cada valor de la variable se realiza un proceso de conteo. ## x Freq ## 1 0 9 ## 2 1 8 ## 3 2 5 ## 4 3 14 ## 5 4 12 ## 6 5 10 ## 7 6 5 ## 8 7 10 ## 9 8 8 ## 10 9 5 ## 11 10 13 ## 12 11 11 ## 13 12 14 ## 14 13 13 ## 15 14 4 ## 16 15 6 ## 17 16 5 ## 18 17 9 ## 19 18 6 ## 20 19 16 ## 21 20 15 ## 22 21 8 ## 23 22 11 ## 24 23 10 ## 25 24 9 ## 26 25 9 ## 27 26 12 ## 28 27 11 ## 29 28 11 ## 30 29 9 ## 31 30 13 ## 32 31 17 ## 33 32 8 ## 34 33 10 ## 35 34 14 ## 36 35 2 ## 37 36 8 ## 38 37 10 ## 39 38 8 ## 40 39 13 ## 41 40 7 ## 42 41 10 ## 43 42 11 ## 44 43 9 ## 45 44 9 ## 46 45 4 ## 47 46 9 ## 48 47 7 ## 49 48 14 ## 50 49 7 ## 51 50 10 ## 52 51 21 ## 53 52 6 ## 54 53 6 ## 55 54 9 ## 56 55 9 ## 57 56 14 ## 58 57 16 ## 59 58 9 ## 60 59 8 ## 61 60 12 ## 62 61 12 ## 63 62 11 ## 64 63 13 ## 65 64 11 ## 66 65 5 ## 67 66 19 ## 68 67 9 ## 69 68 6 ## 70 69 12 ## 71 70 6 ## 72 71 10 ## 73 72 4 ## 74 73 6 ## 75 74 11 ## 76 75 11 ## 77 76 13 ## 78 77 11 ## 79 78 9 ## 80 79 7 ## 81 80 15 ## 82 81 10 ## 83 82 9 ## 84 83 9 ## 85 84 12 ## 86 85 4 ## 87 86 12 ## 88 87 7 ## 89 88 9 ## 90 89 7 ## 91 90 4 ## 92 91 9 ## 93 92 14 ## 94 93 15 ## 95 94 9 ## 96 95 17 ## 97 96 9 ## 98 97 8 ## 99 98 16 ## 100 99 17 ## 101 100 4 Tener los datos en una tabla de frecuencias con intervalos de clase. ## Var1 Freq ## 1 (0,10] 90 ## 2 (10,20] 99 ## 3 (20,30] 103 ## 4 (30,40] 97 ## 5 (40,50] 90 ## 6 (50,60] 110 ## 7 (60,70] 104 ## 8 (70,80] 97 ## 9 (80,90] 83 ## 10 (90,100] 118 1.5 Medidas de tendencia central Imaginemos que tenemos los siguientes números: 2,2,3,3,3,4,4. 1.5.1 Moda (Mo) La moda es el número que aparece con mas frecuencia en la serie de datos. En los números descritos la moda es \\(Mo=3\\). Si la serie de números ahora es: 2,2,2,3,3,3,4,4. ¿Cuál es la moda?, en este caso se tienen 2 modas, el 2 y 3 (bi-modal). Nota: Si todos los números aparecen la misma cantidad de veces, no hay moda 1.5.2 Mediana (Me) La mediana corresponde al valor que se encuentra en el centro, de la serie de números ordenados. Es el número que deja la misma cantidad de información tanto a la derecha como a la izquierda. En el ejemplo: 2,2,3,3,3,4,4. La mediana es igual a \\(Me=3\\). Veamos los siguientes ejemplos: 9,5,2,6,2,4,8. Ordenando, 2, 2, 4, 5, 6, 8, 9. Así \\(Me=5\\), \\(Mo=2\\) 4,2,7,7,4,3,2,9. Ordenando, 2, 2, 3, 4, 4, 7, 7, 9. Así \\(Me=4\\), \\(Mo=2,4,7\\) 1,2,3,4,5,5,5,90. Ordenando, 1, 2, 3, 4, 5, 5, 5, 90. Así \\(Me=\\frac{4+5}{2}=4.5\\), \\(Mo=5\\). Para obtener el valor de la mediana se debe tomar el cuenta si la cantidad de datos es impar o par. Si \\(N\\) es impar: \\[Me= X_{||N/2||+1}\\] \\[Me= X_{(N+1)/2}\\] En el ejemplo: 2, 2, 4, 5, 6, 8, 9. Corresponden a este conjunto (\\(X_1,X_2,X_3,X_4,X_5,X_6,X_7\\)). Entonces \\(Me=X_{||N/2||+1}=X_{||7/2||+1}=X_{||3.5||+1}=X_{3+1}=X_4=5\\) Si \\(N\\) es par: \\[Me=\\frac{X_{N/2}+X_{N/2+1}}{2} \\] 1.5.3 Media, Promedio, Media aritmética Esta medida se caracteriza en que su construcción depende de todas las observaciones en los datos, (democrática). \\[\\bar{x}=\\frac{\\sum_{i=1}^N {x_i}}{N}=\\frac{x_1}{N}+\\frac{x_2}{N}+\\ldots+\\frac{x_N}{N}\\] Ejemplo, 9,5,2,6,2,4,8. \\(\\bar{x}=\\frac{36}{7}=5.14\\) 4,2,7,7,4,3,2,9. \\(\\bar{x}=\\frac{38}{8}=4.75\\) 1,2,3,4,5,5,5,90. \\(\\bar{x}=\\frac{115}{8}=14.38\\) Nota: La media es una medida sensible a los números atípicos. (Grandes) La media para datos agrupados: ## xi fi ## 1 2 2 ## 2 3 1 ## 3 4 2 ## 4 7 2 ## 5 9 1 Donde \\(f_i\\) se conoce como frecuencia absoluta (conteo). \\(\\sum_{i=1}^k{f_i}=N\\). Donde \\(k\\) es la cantidad de filas en la tabla de frecuencias. \\[\\bar{x}=\\frac{\\sum_{i=1}^k{x_i*f_i}}{N}\\] En el ejemplo: \\[\\bar{x}=\\frac{2*2+3*1+4*2+7*2+9*1}{8}=\\frac{38}{8}=4.75\\] 1.5.4 Propiedades de la media Sea \\(x\\) la variable de interés, y \\(a, b\\) contantes. x&lt;-c(3,3,4,6,4,6,8) sum(x)/7 ## [1] 4.857143 x+2 ## [1] 5 5 6 8 6 8 10 sum(x+2)/7 ## [1] 6.857143 \\(y=x+a\\), entonces, \\(\\bar{y}=\\bar{x}+a\\) Demostración \\[\\bar{y}=\\frac{\\sum_{i=1}^N {y_i}}{N}=\\frac{\\sum_{i=1}^N {(x_i+a)}}{N}=\\frac{\\sum {x_i}+\\sum a}{N}=\\frac{\\sum {x_i}}{N}+\\frac{N a}{N}=\\bar{x}+a\\] \\(\\bar{a}=a\\) \\(y=ax\\), entonces, \\(\\bar{y}=a\\bar{x}\\) Demostración \\[\\bar{y}=\\frac{\\sum_{i=1}^N {y_i}}{N}=\\frac{\\sum_{i=1}^N {a*x_i}}{N}=a*\\frac{\\sum_{i=1}^N {x_i}}{N}=a \\bar{x}\\] \\(y=a+bx\\), entonces, \\(\\bar{y}=a+b\\bar{x}\\) Ejemplo: En 2020 de un grupo de 30 trabajadores, existen 15 obreros que tienen un salario de 2000 Bs, 10 técnicos tienen un salario de 4000 Bs. y 5 gerentes un salario de 7000 Bs. Para 2021 se decide darles un incremento de 500 Bs a todos, más un incremento del 15% sobre su salario del 2020. ¿Cuál es el promedio de salario de estos trabajadores para la gestión 2021? Solución, \\(N=30=15+10+5=N_{obr}+N_{tec}+N_{ger}\\), definamos la variable salario \\(S\\). \\[\\bar{S}_{2020}=\\frac{\\sum_{i=1}^{30}{s_i}}{30}=\\frac{2000*15+4000*10+7000*5}{30}=\\frac{105000}{30}=3500\\] \\[\\bar{S}_{2021}=500+1.15*\\bar{S}_{2020}=500+1.15*3500=4525\\] 1.6 Medidas de dispersión Son medidas que tienen el objetivo de brindar información respecto la variabilidad de la información. s&lt;-rep(c(2000,4000,7000),c(15,10,5)) round(runif(20,10,12),0) ## [1] 12 11 10 11 12 11 11 10 12 12 11 12 10 11 11 11 11 11 11 12 round(runif(20,10,20),0) ## [1] 11 14 12 20 15 14 19 17 14 14 12 18 10 19 17 13 17 15 19 13 round(runif(20,10,100),0) ## [1] 94 33 50 74 91 56 55 14 32 81 28 89 43 34 63 25 54 97 62 81 1.6.1 Rango \\[R=X_{max}-X_{min}\\] En el ejemplo de los salarios: \\(R=7000-2000=5000\\) 1.6.2 Varianza poblacional \\[\\sigma^2_x=\\frac{\\sum_{i=1}^N{(x_i-\\bar{x})^2}}{N}\\] Para el ejemplo de salarios. \\(\\sigma_s^2=3250000\\). Nota: La varianza es una medida estadística poco informativa y nada interpretable. Por ello, existe otra medida derivada de la varianza, conocida como la desviación estándar. \\[\\sigma_x=\\sqrt{\\sigma_x^2}=\\sqrt{\\frac{\\sum_{i=1}^N{(x_i-\\bar{x})^2}}{N}}\\] Para el ejemplo, \\(\\sigma_s=\\sqrt{3250000 (Bs.^2)}=1802.78 (Bs)\\) Existe una medida relativa, para conocer la dispersión. Esta se llama el coeficiente de variación. \\[CV(x)=CV_x=\\frac{\\sigma_x}{\\bar{x}}\\] Una interpretación de esta medida se refiere al porcentaje de elementos que no se sienten representados por el promedio. (\\(\\%CV=CV_x*100\\)) En el ejemplo de los salarios, \\(CV_s=\\frac{1802.78}{3500}=0.51\\), en porcentaje es 51%. Nota: Mientras \\(\\%CV_x \\rightarrow 0\\) la información es menos dispersa, en otro caso, la información es mucho más dispersa \\(\\%CV_x \\rightarrow 100\\) 1.6.3 Varianza muestral (cuasivarianza) \\[S^2_x=\\frac{\\sum_{i=1}^N{(x_i-\\bar{x})^2}}{N-1}\\] \\[S^2_x=\\frac{\\sum_{i=1}^n{(x_i-\\bar{x})^2}}{n-1}\\] En el ejemplo de salarios, \\(S^2_s=\\frac{97500000}{29}=3362069\\). 1.7 Gráficos 1.7.1 Boxplot (Diagramas de caja) boxplot(s) boxplot(x) 1.7.2 Histograma hist(s) hist(rnorm(200,40,6)) hist(rchisq(200,4)) 1.7.3 Densidad par(mfrow=c(1,2)) plot(density(rchisq(200,4))) plot(density(rchisq(200,4))) "],
["tema-2-probabilidades.html", "2 Tema 2: Probabilidades 2.1 Introducción 2.2 Experimento Aleatorio 2.3 Espacio Muestral 2.4 Eventos (E) 2.5 Probabilidad 2.6 Probabilidad Condicional 2.7 Teorema de la Probabilidad Total 2.8 Teorema de Bayes 2.9 Ejercicios.", " 2 Tema 2: Probabilidades 2.1 Introducción Sumerios y Asirios utilizaban un hueso extraído del talón de animales como ovejas, ciervos o caballos, denominado astrágalo o talus, que tallaban para que pudieran caer en cuatro posiciones distintas, por lo que son considerados como los precursores de los dados. Por su parte, los juegos con dados se practicaron ininterrumpidamente desde los tiempos del Imperio Romano hasta el Renacimiento, aunque no se conoce apenas las reglas con las que jugaban. Uno de estos juegos, denominado “hazard”, palabra que en inglés y francés significa riesgo o peligro, fue introducido en Europa con la Tercera Cruzada. Las raíces etimológicas del término provienen de la palabra árabe “al-azar”, que significa “dado”. Posteriormente, en el “Purgatorio” de Dante el término aparece ya como “azar”. La historia de la probabilidad comienza en el siglo XVII cuando Pierre Fermat y Blaise Pascal tratan de resolver algunos problemas relacionados con los juegos de azar. Aunque algunos marcan sus inicios cuando Cardano (jugador donde los haya) escribió sobre 1520 El Libro de los Juegos de Azar (aunque no fué publicado hasta más de un siglo después, sobre 1660) no es hasta dicha fecha que comienza a elaborarse una teoría aceptable sobre los juegos. Pierre Fermat Blaise Pascal Durante el siglo XVIII, debido muy particularmente a la popularidad de los juegos de azar, el cálculo de probabilidades tuvo un notable desarrollo sobre la base de la anterior definición de probabilidad. Destacan en 1713 el teorema de Bernoulli y la distribución binomial, y en 1738 el primer caso particular estudiado por De Moivre, del teorema central del límite. En 1809 Gauss inició el estudio de la teoría de errores y en 1810 Laplace, que había considerado anteriormente el tema, completó el desarrollo de esta teoría. En 1812 Pierre Laplace publicó Théorie analytique des probabilités en el que expone un análisis matemático sobre los juegos de azar. Daniel Bernoulli Gauss Pierre Laplace 2.2 Experimento Aleatorio Definición de experimento: Proceso mediante el cual se obtiene un resultdo de una observación. Definición de experimento aleatorio: Cuando los resultados de la observacion no s epuede predecir con exactitud antes de realizar el experimento. 2.2.1 Ejemplos Lanzar una moneda Lanzar un dado, lanzar un tetraedro Una competencia de 6 caballos, quien es el caballo ganador Un partido de futbol entre el equipo A y el equipo B El clima de mañana El resultado de una votación con 3 candidatos El tiempo de entrega de una pizza El tiempo de atención en la caja recaudadora de la universidad en un dia particular 2.3 Espacio Muestral Definición de espacio muestral: Es la colección (conjunto) de todos los resultados posibles de un experimento aleatorio. Denotado por… \\[\\Omega\\] 2.3.1 Ejemplos El espacio muestra de los anteriores ejemplos \\(\\Omega=\\{Cara,Cruz\\}\\) \\(\\Omega=\\{1,2,3,4,5,6\\}\\), para el tetraedro \\(\\Omega=\\{1,2,3,4\\}\\) Sean los caballos a,b,c,d,e y f, \\(\\Omega=\\{a,b,c,d,e,f\\}\\) \\(\\Omega=\\{ganaA, ganaB, empate\\}\\) \\(\\Omega=\\{soleado, lluvia,nublado \\}\\) Sean los candidatos x, y, z \\(\\Omega=\\{x,y,z\\}\\) Sea \\(x\\) el tiempo, \\(\\Omega=\\{x &gt; 0\\}\\) 7a. Sea \\(x\\) el tiempo en horas, \\(\\Omega=\\{ 0&lt;x&lt;24 \\}\\) Sea \\(x\\) el tiempo en horas, \\(\\Omega=\\{ 0&lt;x&lt;8 \\}\\) Nota: el tamaño de \\(\\Omega\\) lo denotaremos por: \\[\\#\\Omega\\] El espacio muestral de un experimento, puede ser: Finito numerables Infinito no numerables Infinito numerables + Los dias hasta que suceda un terremoto en la ciudad \\(x\\) Ejemplo, sean los siguientes experimentos aleatorios: El estado de animo de una persona. \\(\\Omega=\\{feliz, triste, enojada, asustada, \\ldots\\}\\) es finito y es numerable. Donde \\(\\# \\Omega=\\) la cantidad de estados de animo que definamos estudiar. El número de veces necesario al lanzar una moneda hasta sacar cara. \\(\\Omega=\\{1,2,3,4, \\ldots, \\infty \\}\\) es infinito y numerable. \\(\\# \\Omega=\\infty\\). Duración de un artefacto electrónico. \\(\\Omega=\\{w\\in IR, w \\geq 0 \\}\\) es infinito y no numerable. \\(\\# \\Omega=\\infty\\). 2.3.2 Otros ejemplos Exp: Lanzar dos dados y observar las caras superiores de ambos dados, \\(\\Omega= \\{(1,1),(1,2),(1,3), (1,4),...,(6,6) \\}\\), \\(\\Omega= \\{(i,j); i=1:6,j=1:6 \\}\\), \\(\\#\\Omega=36\\) El experimento: determinar el sexo de un niño/a recién nacido. \\(\\Omega=\\{Femenino, Masculino\\}\\) En una competencia de caballos, con 7 caballos, el experimento: ordenar todas las posibles llegadas de estos 7 caballos. (a,b,c,d,e,f,g), \\(\\#\\Omega=7!=5040\\) \\[\\Omega=\\{\\text{Todas las 7! permutaciones de } (a,b,c,d,e,f,g) \\}\\] El experimento es medir el tiempo de vida de un componente electrónico de un aparato (horas). \\[\\Omega=\\{x \\in IR: x \\geq 0 \\}\\] par(mfrow=c(1,2)) plot(1:10,rep(0,10),type=&quot;l&quot;,xlab=&quot;t&quot;,ylab=&quot;&quot;) plot(1:10,rep(0,10),type=&quot;b&quot;,xlab=&quot;t&quot;,ylab=&quot;&quot;) El experimento es: Seleccionar 3 personas de un grupo de 50 personas, describir el espacio muestral y el tamaño de este. \\(\\# \\Omega= C_3^{50}=\\binom{50}{3}=19600\\) \\(\\Omega=\\{(i,j,k); i,j,k \\in 1:50, i\\neq j \\neq k \\}\\) 2.3.3 Ejercicios Cuatro profesores se distribuyen al azar en 4 oficinas numeradas del 1 al 4. Si los profesores pueden estar en la misma oficina. Describir \\(\\Omega\\) \\[\\#\\Omega=4!+4+4\\binom{4}{2}+\\binom{4}{2}\\binom{4}{3}+\\binom{4}{2}\\binom{4}{2}\\] Se lanza una moneda y un dado simultaneamente. Describir \\(\\Omega\\), \\(\\#\\Omega=12\\) \\[\\Omega=\\{(i,j); i=\\{cruz,cara\\},j=1:6 \\}\\] Cinco trabajadores, de los cuales 3 pertenecen a un grupo minoritario se asignan a 5 empleos netamente distintos. Describir \\(\\Omega\\), Ignorar al grupo minoritario, \\(\\# \\Omega=5!\\), sean los trabajdores a,b,c,d,e,f \\(\\Omega=\\{5!; a,b,c,d,e\\}\\) Solo con los 3 trabajadores minoritarios: Sea los trabajadores minoritarios \\(a,b,c\\) y numerámos los empleos de \\(1:5\\) \\(\\Omega=\\{(a=i,b=j,c=k); i,j,k=1:5, i \\neq j \\neq k\\}\\), \\(\\# \\Omega= CR_{5,3}=\\binom{7}{3}=35\\) Dos personas A y B se distribuyen al azar en tres oficinas numeradas 1,2 y 3 .Si las dos personas pueden estar en la misma oficina ,defina un espacio muestral adecuado \\[\\Omega=\\{(1A,1B),(2A,2B),(3A,3B),(1A,2B),(1A,3B),(2A,3B),(1B,2A),(1B,3A),(2B,3A) \\}\\] 5. En un profesor toma un examen con 5 preguntas de falso/verdadero, describa el espacio muestral asociado a este experimento aleatorio, relacionado a las respuestas del estudiante. Resp. \\(\\# \\Omega=2*2*2*2*2=2^5=32\\), \\(\\Omega=\\{(VVVVV),(VFVFV),\\ldots,(FFFFF)\\}\\) En un profesor toma un examen con 5 preguntas de opción múltiple (5 opciones por pregunta, con una sola opción correcta), describa el espacio muestral asociado a este experimento aleatorio, relacionado a las respuestas del estudiante. Resp. $# =55555=5^5=3125 $, Supongamos que las alternativas en las opciones son \\((a,b,c,d,e)\\) \\(\\Omega=\\{(aaaaa),(aaaab),\\ldots ,(eeeee)\\}\\) 2.4 Eventos (E) Sea \\(E\\) un evento, este se define como: \\[E \\subset \\Omega\\] 2.4.1 Ejemplos En el ejemplo del nacimiento de niños/as, el experimento trataba de determinar el sexo del niño/a. Sea el evento \\(E\\) nace una niña, \\(E=\\{Femenino \\}\\), otro evento puede ser \\(E2=\\{masculino\\}\\) Sea el experimento lanzar un dado (de 6 caras). Sean los eventos \\(A\\) el resultado es par. \\(A=\\{2,4,6 \\}\\) \\(B\\) el resultado es mayor a 5. \\(B=\\{6\\}\\) \\(C\\) el resultado es un número primo. \\(C=\\{1,2,3,5\\}\\), \\(C=\\{2,3,5\\}\\) \\(D\\) el resultado es mayor a 6. \\(D=\\emptyset\\) \\(E\\) el resultado mayor a 0. \\(E=\\Omega\\) Nota: recordar que \\(\\emptyset \\subset \\Omega\\), \\(\\Omega \\subset \\Omega\\). En una competencia de caballos, con 7 caballos, el experimento: ordenar todas las posibles llegadas de estos 7 caballos. \\((a,b,c,d,e,f,g)\\). Sea el evento \\(E\\) el caballo \\(c\\) gana la competencia, describa el evento o el tamaño de este evento. Recordar que \\(\\# \\Omega= 7!\\) \\[\\# E = 1 * 6*5*4*3*2*1=6!= 720\\] \\[E = \\{(c,a,b,d,e,f,g),(c,a,b,d,e,g,f),(c,f,b,d,e,a,g),\\ldots \\}\\] \\[E = \\{ \\text{Son las permutaciones de 6! de tal forma que c es primero: } (a,b,d,e,f,g) \\}\\] Se lanza dos dados y se suman ambas caras. Defina los eventos: \\[\\Omega=\\{2,3,4,5,6,7,8,9,10,11,12 \\}\\] la suma es par, \\(A=\\{2,4,6,8,10,12 \\}\\) la suma es múltiplo de 7 \\(B=\\{7\\}\\) la suma es 1, \\(C=\\{\\emptyset\\}\\) En el ejemplo del componente electrónico, sea el evento \\(E\\) el componente dura al menos 5 horas. \\[E=\\{x: x\\geq 5 \\}\\] En el ejemplo del componente electrónico, sea el evento \\(E\\) el componente dura a lo sumo 5 horas. \\[E=\\{x: x\\leq 5 \\}\\] 7. Una pareja inicia la planificación familiar, ellos quieren tener 4 hijos/as. Esta pareja esta interesada en los siguientes eventos: \\(A:\\) todos del mismo sexo \\(B:\\) exactamente un varón \\(C:\\) Por lo menos dos varones \\(D:\\) exactamente 1 mujer Listar los elementos vinculados a estos eventos. Solución, El experimento aleatorio es: el sexo de los 4 hijos/hijas de esta pareja \\((h1,h2,h3,h4)\\). \\(\\# \\Omega= 2*2*2*2=16\\) El espacio muestral es \\(\\Omega:\\) (mmmm) | (hmmm) | (mhmm) | (mmhm) | (mmmh) | (hhmm) | (mhhm) | (hmhm) | (mhmh) | (hmmh) | (mmhh) | (hhhm) | (hhmh) | (hmhh) | (mhhh) | (hhhh) | Ahora sobre los eventos: \\(A=\\{(mmmm),(hhhh) \\}\\), \\(\\# A=2\\) \\(B=\\{(hmmm),(mhmm),(mmhm),(mmmh) \\}\\), \\(\\# B=4\\) \\(C=\\{ (hhmm),(mhhm),(hmhm),(mhmh),(hmmh),(mmhh),(hhhm),(hhmh),(hmhh),(mhhh),(hhhh)\\}\\), \\(\\# C= 11\\) \\(D=\\{ (hhhm),(hhmh),(hmhh),(mhhh)\\}\\) 2.4.2 Evento simple Un evento simple, es el elemento más pequeño (suelto) dentro de otro evento. También, un evento simple tiene correspondencia única con los posibles resultados de \\(\\Omega\\). Sea \\(\\Omega=\\{w_1,w_2,\\ldots,w_i,\\ldots\\}\\), los resultados \\(w_i\\) son conocidos como los eventos simple. En el fondo un evento es la colección de algunos eventos simples, según la definición del evento 2.4.3 Operaciones con los eventos Sean \\(A\\), \\(B\\) y \\(C\\) eventos. Eventos simples: son eventos que contienen un solo elemento, tienen correspondencia con los resultados del espacio muestral. Sea \\(w\\) un evento simple de un \\(\\Omega\\) “numerable”. Evento vacio \\(\\emptyset\\) El complemento de un evento \\[A^c=\\{ w \\in \\Omega \\wedge w\\notin A\\}\\] La unión de eventos \\[A \\cup B = \\{w \\in \\Omega: w \\in A \\text{ ó } w\\in B \\}\\] La intersección de eventos \\[A \\cap B= \\{w \\in \\Omega: w \\in A \\wedge w \\in B \\}\\] Dos eventos son mutuamente excluyentes (No tienen elementos en común) si: \\[A \\cap B = \\emptyset\\] * Inclusión de eventos \\[A \\subset B =\\{w \\in \\Omega : w \\in A \\rightarrow w \\in B \\}\\] Ejemplo: En el lanzamiento de 2 dados y la suma de sus resultados, sean los eventos \\(A:\\) La suma es par \\(B:\\) La suma es impar \\(C:\\) La suma es un número primo \\(D:\\) La suma es mayor a 3 Describir los eventos y luego encontrar $A C={2,3,4,5,6,7,8,10,11,12} $ \\(B \\cap D=\\{5,7,9,11 \\}\\) \\(C \\cup D^c= D^c \\subset C= C\\) \\(A \\cap (B\\cup C )=\\) \\(A \\cup (B\\cap C)=\\) El espacio muestral \\(\\Omega=\\{2,3,4,5,6,7,8,9,10,11,12\\}\\) Los eventos \\(A=\\{2,4,6,8,10,12\\}\\) \\(B=\\{3,5,7,9,11 \\}\\) \\(C=\\{2,3,5,7,11 \\}\\) \\(D=\\{4,5,6,7,8,9,10,11,12\\}\\) \\(D^C=\\{2,3\\}\\) \\(C \\subset B\\), entonces \\(C\\cup B=B\\), \\(C \\cap B=C\\) 2.4.4 Algunas propiedades sobre las operaciones en eventos Sean \\(A\\), \\(B\\), \\(C\\) y \\(D\\) eventos, \\(A \\cup B= B \\cup A\\), \\(A \\cap B= B \\cap A\\) Conmutativa \\((A \\cup B) \\cup C= A \\cup (B \\cup C)\\) , \\((A \\cap B) \\cap C= A \\cap (B \\cap C)\\) Asociativa \\(A \\cup (B \\cap C)= (A \\cup B) \\cap (A \\cup C)\\) Distributiva $A (B C)=(AB) (AC) $ Distributiva \\((A \\cup B)^c= A^c \\cap B^c\\) \\((A \\cap B)^c= A^c \\cup B^c\\) Ley de Morgan, sea \\(E_1, E_2, E_3, \\ldots, E_n\\), \\(n\\) eventos de algun experimento aleatorio \\[ (\\cup_{i=1}^{n}\\{E_i\\})^c = \\cap_{i=1}^{n}\\{E_i ^c\\}\\] \\[ (\\cap_{i=1}^{n}\\{E_i\\})^c = \\cup_{i=1}^{n}\\{E_i ^c\\}\\] \\((A^c)^c=A\\) 2.4.5 Algebra de Eventos Definición: Sea \\(A\\) un evento, Sea \\(\\Sigma\\) una clase de subconjuntos de \\(\\Omega\\) Esta es un algebra de eventos si: \\(\\Omega \\in \\Sigma\\) Si \\(A\\in \\Sigma\\Rightarrow A^C \\in \\Sigma\\) Si \\(A,B \\in \\Sigma \\Rightarrow A \\cup B \\in \\Sigma\\) Ejemplo: El experimento es lanzar un dado y observar el resultado de la cara \\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\(\\# \\Omega=6\\), \\(\\Omega \\cup \\emptyset=\\Omega\\) \\[\\Sigma=\\{\\Omega,\\emptyset \\}\\] Sera que la siguiente clase es un algebra de eventos: \\[\\Sigma=\\{\\Omega, \\emptyset, 1, (2,3,4,5,6) \\}\\] \\[\\Sigma=\\{\\Omega, \\emptyset, 1, (2,3,4,5,6), 2, (1,3,4,5,6),(1,2),(3,4,5,6) \\}\\] Nota: El algebra de eventos no es único Definición: Se dice que \\(\\Sigma\\) es un \\(\\sigma-algebra\\) \\(\\Omega \\in \\Sigma\\) Si \\(A\\in \\Sigma\\Rightarrow A^C \\in \\Sigma\\) Si \\(A_i \\in \\Sigma\\) para \\(i=1,2, \\ldots\\) \\(\\Rightarrow \\cup_{i=1}^\\infty A_i \\in \\Sigma\\) Ejemplo: El experimento es lanzar un dado y observar el resultado de la cara \\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\(\\# \\Omega=6\\), \\(\\Omega \\cup \\emptyset=\\Omega\\) \\[\\Sigma=\\{\\Omega,\\emptyset \\}\\] \\[\\Sigma=\\{\\Omega,\\emptyset,1,(2,3,4,5,6) \\}\\] Existe un \\(\\sigma -algebra\\) que contiene todas las combinaciones posibles contiene en particular todos los eventos simples de \\(\\Omega\\). \\[\\Sigma=\\{\\Omega,\\emptyset,1,2,3,4,5,6,(2,3,4,5,6),(1,3,4,5,6),(1,2,4,5,6),(1,2,3,5,6),(1,2,3,4,6),(1,2,3,4,5),(1,2),(1,3),...,(1,2,3),(1,2,4),...(1,2,3,4),(1,2,3,5),...\\}\\] \\[\\#\\Sigma=2^{\\# \\Omega}\\] \\[\\#\\Sigma=2^6=64\\] Ejemplo al lanzar una moneda dos veces y observar los resultados \\(\\Omega=\\{CC,SC,CS,SS\\}\\) si armamos un \\(\\sigma-algebra\\) donde incluyamos todos los eventos simples, entonces, \\(\\#\\Sigma=2^4=16\\). \\[\\Sigma=\\{\\Omega,\\emptyset,CC,SC,CS,SS,(CC,SC),(CC,CS),(CC,SS),(SC,CS),(SC,SS),(CS,SS),(CC,SC,CS),(CC,SC,SS),(CC,CS,SS),(SC,CS,SS)\\}\\] 2.5 Probabilidad Medida de incertidumbre entre 0 y 1 asociado a un experimento aleatorio Probabilidad teórica: (asume que los eventos simples son igualmente probables) los casos posibles sobre los casos totales \\[P(A)= \\frac{\\text{Casos posibles}}{\\text{Casos totales}}=\\frac{\\#A}{\\# \\Omega}\\] Ejemplo: El lanzamiento de un dado, \\(\\Omega=\\{1,2,3,4,5,6\\}\\), si el evento es \\(A=6\\), \\(B=PAR\\) \\(P(A)=\\frac{1}{6}\\), \\(P(B)=\\frac{3}{6}=1/2\\) Probabilidad frecuentista: \\[P(A)=lim_{n \\rightarrow \\infty} \\frac{n(A)}{n} =lim_{n \\rightarrow \\infty} \\frac{\\# A_n}{n}\\] #0=cara, 1=escudo set.seed(999) aux&lt;-rbinom(1000,1,0.5) aux ## [1] 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 ## [31] 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 1 ## [61] 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 ## [91] 1 0 0 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 ## [121] 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 ## [151] 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 0 ## [181] 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 ## [211] 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 ## [241] 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 ## [271] 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 0 ## [301] 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 ## [331] 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 ## [361] 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 ## [391] 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 0 ## [421] 1 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 ## [451] 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 ## [481] 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 1 ## [511] 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 1 1 0 1 ## [541] 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 ## [571] 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 1 ## [601] 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 1 ## [631] 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 1 ## [661] 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 ## [691] 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 ## [721] 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 ## [751] 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 0 1 ## [781] 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 ## [811] 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 ## [841] 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 ## [871] 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 0 ## [901] 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 ## [931] 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 1 ## [961] 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 ## [991] 0 0 1 1 1 0 1 0 1 1 sum(aux) ## [1] 496 \\(P(escudo)=\\frac{496}{1000}=0.496\\) Probabilidad subjetiva (experiencia) (apriori) \\[P(escudo)=1/3\\] \\[P(llueva_{hoy})=0.99\\] 2.5.1 Probabilidad de un evento Definición: Una medida de probabilidad \\(P\\) es una función, tal que: \\[ P:\\begin{array} &amp;&amp; \\Sigma &amp; \\rightarrow &amp; [0,1]\\\\ &amp; \\downarrow &amp; &amp; \\downarrow \\\\ &amp; A &amp; \\rightarrow &amp; P(A) \\end{array} \\] 2.5.2 Axíomas básicos de la probabilidad \\(P(A) \\in [0,1]\\), \\(0 \\leq P(A) \\leq 1\\), Para todo \\(A\\in \\Sigma\\), \\(A\\in\\Omega\\) \\(P(\\Omega)=1\\) Axioma aditividad finita, Si \\(A_1,A_2, \\ldots,A_n \\in \\Sigma\\), Estos son eventos disjuntos 2 a 2 (mutuamente excluyentes). \\(A_i \\cap A_j=\\emptyset\\) para todo \\(i\\neq j\\) \\[P(\\cup_{i=1}^n{A_i})=\\sum_{i=1}^n{P(A_i)}\\] Observación: Si \\(A \\cap B=\\emptyset\\) entonces, \\(P(A\\cup B)=P(A)+P(B)\\) Ejemplo, En el lanzamiento de un dado, sean los eventos, A=sale Par, B=Sale Impar. Calcular la probabilidad de \\(P(A\\cup B)\\). \\(A=\\{2,4, 6\\}\\), \\(B=\\{1,3,5\\}\\), Notar que \\(A \\cap B= \\emptyset\\). Por el axioma 2. \\[P(A \\cup B)=P(\\Omega)=1\\] Por el axioma 3. \\[P(A \\cup B)=P(A)+P(B)=\\frac{3}{6}+\\frac{3}{6}=1\\] 2.5.3 Propiedades \\(P(\\emptyset)=0\\) Demostración: sea \\(A\\) un evento, \\(A\\cap \\emptyset=\\emptyset\\) \\(A=A\\cup \\emptyset\\) \\[P(A)=P(A\\cup \\emptyset)=P(A)+P(\\emptyset)\\] \\[P(A)=P(A)+P(\\emptyset)\\] \\[P(\\emptyset)=0\\] \\(P(A^c)=1-P(A)\\) \\(A\\cap A^c=\\emptyset\\), entonces son eventos disjuntos \\(A \\cup A^c= \\Omega\\), entonces, \\(P(A\\cup A^c)=P(\\Omega)=1\\) Ax2. \\[1=P(\\Omega)=P(A \\cup A^c)=P(A)+P(A^c)\\] Así, \\[P(A^c)=1-P(A)\\] Ejercicios, demostrar: \\(P(A \\cup B)=P(A)+P(B)-P(A\\cap B)\\), para cualesquiera eventos \\(A\\), \\(B\\) 2.5.4 Espacios equiprobables Sea \\(\\Omega\\) un espacio muestral finito de tamaño \\(n\\), \\[\\Omega=\\{w_1,w_2,\\ldots,w_n\\}\\] Definición: Es una función que asigna las mismas probabilidades a todos los resultados del espacio muestral, es decir, todos los eventos simples tienen la misma probabilidad de ocurrencia. \\[P(w_1)=P(w_2)=\\ldots=P(w_n)=\\frac{1}{n}\\] Nota, tener en cuenta que \\(w_i \\cap w_j=\\emptyset\\) para \\(i\\neq j\\) dado que los \\(w_i\\) son eventos simples \\[P(w_1 \\cup w_2\\cup \\ldots \\cup w_n)=P(\\Omega)=1\\] \\[P(w_1 \\cup w_2\\cup \\ldots \\cup w_n)=P(w_1)+P(w_2)+\\ldots+P(w_n)=1\\] Ejemplo, el lanzamiento de un dado legal genera un espacio muestral equiprobable. \\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\(P(1)=P(2)=\\ldots=P(6)=\\frac{1}{6}\\) Ejemplo 1. En un hipódromo 4 caballos, \\(A\\),\\(B\\),\\(C\\) y \\(D\\) compiten. Suponiendo que todos los caballos tienen la misma probabilidad de ganar (espacio equiprobable), calcular: Probabilidad que gane el caballo \\(A\\). Resp. \\(P(ganaA)=1/4\\) Probabilidad que gane el caballo \\(A\\) o el caballo \\(D\\). Resp. el evento de interés es \\(ganaA \\cup ganaD\\), notar que \\(ganarA \\cap ganaD=\\emptyset\\) \\[P(ganaA\\cup ganaD)=P(ganaA)+P(ganaD)=1/4+1/4=1/2\\] Ejemplo 2. Tomemos ahora lo siguiente: \\(A\\) tiene 2 veces más probabilidades de ganar que \\(B\\); \\(B\\) tiene 2 veces más probabilidad de ganar que \\(C\\) y \\(C\\) tiene 2 veces más probabilidades de ganar que \\(D\\). (espacio no equiprobable) Probabilidad que gane el caballo \\(A\\) Probabilidad que gane el caballo \\(A\\) o el caballo \\(D\\). Sean los eventos simples, \\(w_1=gA=GanaA\\), \\(w_2=gB=GanaB\\), \\(w_3=gC=GanaC\\) y \\(w_4=gD=GanaD\\) Sabemos que: \\(P(gA)=2*P(gB)=2*2*P(gC)=2*2*2*P(gD)=8*P(gD)\\) \\[P(gA)+P(gB)+P(gC)+P(gD)=1\\] \\[8*P(gD)+4*P(gD)+2*P(gD)+P(gD)=1\\] \\[P(gD)(8+4+2+1)=1\\] \\[P(gD)=\\frac{1}{15}\\] Asi, \\(P(gD)=1/15\\), \\(P(gC)=2/15\\), \\(P(gB)=4/15\\), \\(P(gA)=8/15\\) \\(P(gA)=8/15\\) \\(P(gA\\cup gD)=P(gA)+P(gD)=8/15+1/15=9/15\\) Ejemplo. Se lanza un par de dados legales simultaneamente, encontrar las probabilidades: La suma sea menor que 4 La suma sea 9 El resultado del primer dado sea mayor que el segundo \\(\\#\\Omega=36\\), \\(P(d1=i,d2=j)=1/36\\) para \\(i,j=1:6\\) Resp. \\[P((1,1)\\cup (1,2)\\cup (2,1))=P(1,1)+P(1,2)+P(2,1)=1/36+1/36,1/36=3/36=1/12\\] Resp. \\[P(suma=9)=\\frac{4}{36}\\] Resp. \\[P(d1&gt;d2)=\\frac{15}{36}=\\frac{5}{12}\\] Ejercicio (7, pg243). Un lote continene 10 piezas buenas, 4 con defectos menores y 2 con defectos mayores. Se extraen 2 piezas al azar. Calcular: 1. Calcular el tamaño del espacio muestral $\\#\\Omega=\\binom{16}{2}=120$ 2. Probabilidad que ambas sean perfectas \\[P(2perf)=\\frac{\\binom{10}{2}}{\\binom{16}{2}}=\\frac{45}{120}=\\frac{15}{40}=\\frac{3}{8}\\] 3. Probabilidad que por lo menos una sea perfecta \\[P(1perf \\cup 2perf)=P(1perf)+P(2perf)=\\frac{\\binom{10}{1}\\binom{6}{1}}{\\binom{16}{2}}+\\frac{3}{8}=\\frac{60}{120}+\\frac{3}{8}=\\frac{1}{2}+\\frac{3}{8}=\\frac{7}{8}\\] 4. Probabilidad que ninguna tenga un defecto mayorjihj 5. Probabilidad que ninguna sea perfecta Ejercicio (14, pg-244). Sea un dado, tal que la probabilidad de las distintas caras es proporcional al número de puntos inscritos en ellos. Hallar la probabilidad de obtener con este dado, un número par. \\[\\Omega=\\{1,2,3,4,5,6\\}\\] #relativar px&lt;-(1:6)/sum(1:6) sum(px[c(2,4,6)]) ## [1] 0.5714286 \\[P(2,4,6)=P(2 \\cup 4 \\cup 6 )=P(2)+P(4)+P(6)=0.095+0.19+0.286=0.571\\] Ejercicio (11, pg-244). Sea \\(\\Omega=\\{x \\in Z/ 1 \\leq x \\leq 200 \\}\\), donde \\(Z\\) es el conjunto de los números enteros. Encuentre las probabilidades de los siguiente eventos. + \\(A=\\{x \\in \\Omega / x \\text{ es divisible por }7 \\}\\) + \\(B=\\{x \\in \\Omega / x=3n+10, n\\in Z^+ \\}\\) + \\(C=\\{x \\in \\Omega / x^2+1\\leq 375 \\}\\) Para \\(P(A)\\) sum((1:200 %% 7)==0) ## [1] 28 \\[P(A)=\\frac{\\# A}{\\# \\Omega}=\\frac{28}{200}=0.14\\] Para \\(P(B)\\) n&lt;-1:100 sum((3*n+10)&lt;=200) ## [1] 63 \\[P(B)=\\frac{\\# B}{\\# \\Omega}=\\frac{63}{200}=0.315\\] \\[P(C)=\\frac{\\# C}{\\# \\Omega}=\\frac{19}{200}=0.095\\] 2.6 Probabilidad Condicional Evaluamos dos eventos o más Conocer como se altera o cambia la probabilidad de un evento a partir de la ocurrencia de otro Ejemplo con las notas de una materia. Sea el experimento la nota de que obtiene un estudiante al inscribirse en una materia. Sea el evento A: el estudiante aprueba la materia. ¿Cuál es el probabilidad de A (suponiendo un espacio muestral equiprobable)? \\(\\Omega=\\{0,1,2,\\ldots,100 \\}\\), \\(\\# \\Omega= 101\\), \\(P(i)=\\frac{1}{101}\\) \\(P(A)=P(51\\cup 52 \\cup \\ldots \\cup 100)=P(51)+P(52)+\\ldots+P(100)=\\frac{50}{101}=0.495\\) \\(P(A^c)=1-P(A)=1-\\frac{50}{101}=\\frac{51}{101}=0.505\\) Sea el evento B= el estudiante dio 2 parciales cada uno con un valor de 30, obteniendo el estudiante una nota sumada de los 2 de 27 puntos. ¿Cuál sera ahora la probabilidad de que el estudiante apruebe la materia? Podemos notar que la ocurrencia de \\(B\\) esta alterando el experimento y por ende la probabilidad de aprobar. Pensando en esto, ¿cómo se altera el espacio muestral? \\(\\Omega_{ocurrioB}=\\{27,28,29,\\ldots, 67\\}\\), \\(\\#Omega=41\\) \\(P(A/B)=\\frac{17}{41}=0.415\\) Ejemplos. ¿Cuál es la probabilidad de aprobar la materia X dado que se tiene una nota de 20/30 en el primer parcial? Se lanza una moneda y después se lanza un dado , ¿Cuál es la probabilidad de obtener un 5 en el dado, si salió cara en la moneda? Una urna contiene 3 bolas rojas y 3 bolas blancas, se realiza una selección de 2 bolas de manera consecutiva y sin reemplazo ¿Cuál es la probabilidad de que la segunda bola sea roja, sabiendo que la primera bola fue blanca? Definición: Sean dos eventos \\(A\\) y \\(B\\), tal que \\(P(B)&gt;0\\), la probabilidad condicional de que ocurra el evento \\(A\\), dado que ha ocurrido el evento \\(B\\), se define por: \\[P(A/B)=\\frac{P(A \\cap B)}{P(B)}\\] Nota: Cualquier condición que se de entre las probabilidades, afecta directamente el espacio muestral, esto depende de la relación entre los eventos. Ejemplo: En la carrera de Informática van a existir elecciones para el director de carrera, existen 3 frentes y estos son \\(A\\), \\(B\\), \\(C\\), la carrera esta compuesta por 3 grupos de estudiantes, los políticos, los académicos y el resto, la estructura de votación según un sondeo aleatorio a 200 estudiantes es: Los políticos (50), 20 votan por A, 20 votan por B y 10 votan por C Los académicos que son 40, 10 votan por A, 10 votan por B y 20 votan por C El resto (110), 30 votan por A, 50 votan por B y el resto vota por C A&lt;-rbind(c(20,20,10),c(10,10,20),c(30,50,30)) colnames(A)&lt;-c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;) rownames(A)&lt;-c(&quot;POL&quot;,&quot;ACA&quot;,&quot;RES&quot;) knitr::kable(addmargins(A)) A B C Sum POL 20 20 10 50 ACA 10 10 20 40 RES 30 50 30 110 Sum 60 80 60 200 Encuentre ¿Cuál es la probabilidad de que un estudiante académico vote por C? \\[P(\\text{vote C}/academico)=\\frac{P(\\text{vote C} \\cap academico)}{P(academico)}=\\frac{\\frac{20}{200}}{\\frac{40}{200}}=\\frac{20}{40}=0.5\\] ¿Cuál es la probabilidad de que un estudiante político vote por A? \\[P(\\text{vote A}/politico)=\\frac{20}{50}=0.4\\] ¿Cuál es la probabilidad de que gane el candidato B en estudiantes? \\[P(\\text{gane B})=\\frac{80}{200}=0.4\\] ¿Cuál es la probabilidad que un estudiante seleccionado al azar sea académico dado que votara por el candidato A? \\[P(academico/\\text{vote A})=\\frac{10}{60}=\\frac{1}{6}\\] Ejercicios: ¿Cuál es la probabilidad de aprobar la materia \\(X\\) dado que se tiene una nota de 20/30 en el primer parcial? Se lanza una moneda y después se lanza un dado , ¿Cuál es la probabilidad de obtener un 5 en el dado, si salió cara en la moneda? Solución, Sean los eventos C: Sale cara en la moneda, S: Sale sello en la moneda, y los eventos D1, D2, … , D6 sale el número en el dado. \\[P(D5/C)=\\frac{P(D5 \\cap C)}{P(C)}=\\frac{\\frac{1}{12}}{\\frac{6}{12}}=\\frac{1}{6}\\] Notar algo: \\(P(D5)=\\frac{1}{6}=P(D5/C)=P(D5/S)\\). Si la condición no afecta la probabilidad del evento que busca calcular, podemos afirmar que los eventos son independientes. La ocurrencia de un evento, no altera a otro, a eso le llamamos independencia. Si los eventos A y B son independientes, entonces: \\[P(A \\cap B)= P(A)*P(B)\\] \\[P(A/B)=\\frac{P(A\\cap B)}{P(B)}=\\frac{P(A) P(B)}{P(B)}=P(A)\\] Una urna contiene 3 bolas rojas y 3 bolas blancas, se realiza una selección de 2 bolas de manera consecutiva y sin reemplazo ¿Cuál es la probabilidad de que la segunda bola sea roja, sabiendo que la primera bola fue blanca? Solución, \\(P(R/B)=3/5\\) Ejemplo Se tiene la tabla de admisión de 356 estudiantes de la UMSA, de acuerdo a la carrera y su municipio de procedencia A&lt;-rbind(c(100,40,50,20),c(20,60,50,10),c(5,0,1,0)) colnames(A)&lt;-c(&quot;ING&quot;,&quot;ECO&quot;,&quot;INF&quot;,&quot;DER&quot;) rownames(A)&lt;-c(&quot;LAPAZ&quot;,&quot;ELALTO&quot;,&quot;VIACHA&quot;) knitr::kable(addmargins(A)) ING ECO INF DER Sum LAPAZ 100 40 50 20 210 ELALTO 20 60 50 10 140 VIACHA 5 0 1 0 6 Sum 125 100 101 30 356 Sea el experimento seleccionar a un estudiante al azar del grupo de 356. ¿Cuál es la probabilidad que el estudiantes sea de la carrera de economía, sabiendo que vive en El Alto? \\[P(ECO/ELALTO)=\\frac{60}{140}\\] ¿Cuál es la probabilidad que el estudiantes sea de la carrera de informática, sabiendo que vive en La Paz? \\[P(INF/LAPAZ)=\\frac{50}{210}\\] ¿Cuál es la probabilidad que el estudiantes sea de Viacha, sabiendo que esta en la carrera de ingenieria? \\[P(VIACHA/ING)=\\frac{5}{125}\\] ¿Cuál es la probabilidad que el estudiantes sea de Viacha ó de La Paz, sabiendo que esta en la carrera de ingenieria.? \\[P(VIACHA\\cup LAPAZ /ING)=\\frac{P((VIACHA\\cup LAPAZ)\\cap ING)}{P(ING)}=\\frac{P((VIACHA\\cap ING)\\cup (LAPAZ\\cap ING))}{P(ING)}\\] \\[P(VIACHA\\cup LAPAZ /ING)=\\frac{P(VIACHA\\cap ING)+P(LAPAZ\\cap ING)}{P(ING)}\\] \\[P(VIACHA\\cup LAPAZ /ING)=P(VIACHA/ING)+P(LAPAZ/ING)=5/125+100/125=\\frac{105}{125}\\] Por el principio de que Viacha y La Paz son eventos mutuamente excluyentes (axioma 3) 2.6.1 Regla de la multiplicación \\[P(A/B)=\\frac{P(A\\cap B)}{P(B)}\\] \\[P(B/A)=\\frac{P(B\\cap A)}{P(A)}\\] \\[P(A \\cap B)=P(B)P(A/B)=P(A)P(B/A)\\] Teorema: La regla de la multiplicación Sean \\(A_1,A_2,\\ldots,A_k\\) eventos, de tal forma que: \\[P(A_1\\cap A_2 \\cap \\ldots \\cap A_{k-1})&gt;0\\] Entonces: \\[P(A_1\\cap A_2 \\cap \\ldots \\cap A_{k})=P(A_1)P(A_2/A_1)P(A_3/A_1\\cap A_2)\\ldots P(A_k/A_1 \\cap A_2 \\cap \\ldots A_{k-1}) \\] Ejemplo 1, demostrar: \\[P(A \\cap B \\cap C)=P(A)P(B/A)P(C/A\\cap B)\\] \\[P(A)P(B/A)P(C/A\\cap B)=P(A)*\\frac{P(A \\cap B)}{P(A)}*\\frac{P(C\\cap A \\cap B)}{P(A \\cap B)}=P(A \\cap B \\cap C)\\] 2.6.2 Independencia de Eventos Definición: Sean los eventos A y B, estos son independientes si la ocurrencia de A no interfiere la ocurrencia de B y viceversa. Si A y B son independientes, \\[P(A\\cap B)=P(A)*P(B)\\] Ejemplo. Se lanza una moneda y después se lanza un dado , ¿Cuál es la probabilidad de obtener un 5 en el dado, si salió cara en la moneda? \\[P(D=5/C)=\\frac{P(D=5 \\cap C)}{P(C)}=\\frac{P(D=5)P(C)}{P(C)}=P(D=5)=1/6\\] Nota: Si A y B son independientes, entonces: \\[P(A/B)=P(A)\\] \\[P(B/A)=P(B)\\] Ejemplos, Dado que \\(P(A)=1/2\\), \\(P(B)=1/3\\), \\(P(A\\cap B)=1/4\\) \\(P(A \\cup B)=P(A)+P(B)-P(A\\cap B)=1/2+1/3-1/4=7/12\\) \\(P(A/B)=\\frac{P(A \\cap B)}{P(B)}=\\frac{1/4}{1/3}=3/4\\) \\(P(B/A)=\\frac{P(B\\cap A)}{P(A)}=\\frac{1/4}{1/2}=1/2\\) \\(P(B^C/A^C)=\\frac{P(B^C\\cap A^c)}{P(A^c)}=\\frac{P((A\\cup B)^c)}{1-P(A)}=\\frac{1-P(A\\cup B)}{1-P(A)}=\\frac{1-7/12}{1-1/2}=5/6\\) Ejercicio (5, pg 287). Un restaurante ofrece dos tipos de comida, ensalada o plato de carne. 20% de los clientes hombres prefieren la ensalada, 30% de las mujeres escogen carne, el 75% de los clientes son hombres. Considere los siguientes eventos. H: es hombre, M: es mujer, E: prefiere la ensalda, C: Prefiere Carne. Se pide calcular: \\(P(E/H)\\), \\(P(C/M)\\) \\(P(E \\cap H)\\), \\(P(C \\cap M)\\) \\(P(M/E)\\) Tarea 2: Resolver el ejercicio 6 de la página 287 del libro. Tarea 3: Leer del libro el desde el apartado 5.6.3 (Teorema de la probabilidad total y el teorema de bayes) hasta la página 267. 2.7 Teorema de la Probabilidad Total Probabilidad Total Sea \\(A_1,A_2,\\ldots ,A_n\\) un partición del espacio muestral, de tal forma que: \\(P(A_i)&gt;0\\) para todo \\(i=1, \\ldots,n\\). La partición representa que \\(U_{i=1}^n A_i=\\Omega\\) y \\(A_i \\cap A_j =\\emptyset\\) para todo \\(i\\neq j\\). Para cualquier evento \\(B \\in \\Omega\\). \\[P(B)=\\sum_{i=1}^n{P(A_i \\cap B)}=\\sum_{i=1}^n{P(A_i)P(B/A_i )}\\] Ejemplo: Suponer que la población del departamento de la Paz esta conformado por 55% de mujeres y 45 % de hombres. Supongamos que el 30% de los hombres y el 20% de las mujeres fuman. Determinar la probabilidad de que una persona fume en el departamento de La Paz. Solución: Sean los eventos: H: es hombre (\\(M^c\\)) M: es mujer (\\(H^c\\)) F: Fuma \\(F^c\\): No fuma Además, \\(P(M)=0.55\\), \\(P(H)=P(M^C)=0.45\\), \\(P(F/H)=0.3\\) y \\(P(F/M)=0.2\\), \\(P(F)=?\\). \\[P(F)=P(H)P(F/H)+P(M)P(F/M)=0.45*0.3+0.55*0.2=0.245\\] ¿Cuál es la probabilidad de no fumar en esta población? \\(P(F^c)=1-P(F)=1-0.245=0.755\\) Ejercicio, Para la elección del gobernador en el departamento de La Paz, se realizó una encuesta en 3 dominios de estudio: Municipio de La Paz, El Alto y el resto de los municipios, se sabe que La Paz ocupa el 35% de votantes, El Alto el 40% y los demás el resto de municipios. Los resultados por dominio respecto el apoyo al candidato “Z” es el siguiente: La Paz: 39% El Alto: 49% Resto: 65% Según la encuesta, ¿cuál es la probabilidad que el candidato Z sea gobernador? Solución, Sea la partición LP: La Paz, EA: El Alto, R: el resto, y el evento Z: Apoyo al candidato Z. Se pide \\(P(Z)\\). Como información, tenemos \\(P(LP)=0.35\\), \\(P(EA)=0.4\\), \\(P(R)=0.25\\), \\(P(Z/LP)=0.39\\), \\(P(Z/EA)=0.49\\) y \\(P(Z/R)=0.65\\). Así, \\[P(Z)=P(LP)*P(Z/LP)+P(EA)*P(Z/EA)+P(R)*P(Z/R)=0.35*0.39+0.4*0.49+0.25*0.65=0.495\\] 2.8 Teorema de Bayes Sea \\(A_1,A_2,\\ldots ,A_n\\) un partición del espacio muestral, de tal forma que: \\(P(A_i)&gt;0\\) para todo \\(i=1, \\ldots,n\\). Sea \\(B \\in \\Omega\\) un evento tal que todas las \\(P(B/A_i)\\) son conocidas. Entonces para cada \\(A_i\\) tenemos: \\[P(A_i/B)=\\frac{P(A_i)P(B/A_i)}{\\sum_{j=1}^n{P(A_j)P(B/A_j )}}\\] Demostración, \\[P(A_i/B)=\\frac{P(A_i \\cap B)}{P(B)}=\\frac{P(A_i)*P(B/A_i)}{\\sum_{j=1}^n{P(B\\cap A_j)}}=\\frac{P(A_i)*P(B/A_i)}{\\sum_{j=1}^n{P(A_j)P(B/A_j)}}\\] Dentro del teorema de Bayes, se conoce a \\(P(A_i)\\) como probabilidades a priori, a \\(P(B/A_i)\\) se llama la verosimilitud (información), finalmente a \\(P(A_i/B)\\) se le llama probabilidad a posteriori. Forma simple: \\[P(A/B)=\\frac{P(A)P(B/A)}{P(B)}\\] Demostración, \\[P(A/B)=\\frac{P(A\\cap B)}{P(B)}=\\frac{P(A)P(B/A)}{P(B)}\\] Ejemplo: Un análisis de sangre de laboratorio es \\(95\\) por ciento efectivo en la detección de una determinada enfermedad, cuando de hecho está presente. Sin embargo, la prueba también arroja un resultado “falso positivo” para el 1 por ciento de las personas sanas evaluadas. (Es decir, si se evalúa a una persona sana, entonces, con una probabilidad de \\(0.01\\), el resultado de la prueba implicará que él o ella tiene la enfermedad). Si el \\(0.5\\) por ciento de la población realmente tiene la enfermedad, ¿cuál es la probabilidad de que una persona tenga la enfermedad dado que el resultado de la prueba es positivo? Solución: vamos a identificar los siguientes eventos: E: Se tiene la enfermedad \\(E^c\\): No se tiene la enfermedad T+: La prueba da positiva a la enfermedad T-: La prueba da negativa a la enfermedad Como dato tenemos: \\(P(E)=0.5/100=0.005\\), \\(P(E^c)=1-P(E)=0.995\\), tener o no la enfermedad es la partición dentro del problema. \\(P(T+/E)=0.95\\), \\(P(T+/E^C)=0.01\\). \\(P(E/T+)=¿?\\). \\[P(E/T+)=\\frac{P(E \\cap T+)}{P(T+)}=\\frac{P(E)P(T+/E)}{P(E)P(T+/E)+P(E^C)P(T+/E^C)}\\] \\[P(E/T+)=\\frac{0.005*0.95}{0.005*0.95+0.995*0.01}=0.3231\\] El 32.31% de los pacientes que son diagnosticados con la enfermedad en realidad si están enfermos. Calcular: \\(P(T-/E^c)\\), \\(P(E/T-)\\) \\[P(T-/E^c)=0.99\\] \\[P(E/T-)=0,000253\\] 2.9 Ejercicios. (Pg, 290. Ej: 22). Una de cada 10 personas de una población tiene tuberculosis. De las personas que tienen tuberculosis, el 80% reacciona positivamente a la prueba Y, mientras que el 30% de los que no tienen tuberculosis reaccionan positivamente. Una persona de la población es seleccionada aleatoriamente y la prueba Y es aplicada. ¿Cuál es la probabilidad de que esa persona tenga tuberculosis, si reacciono positivamente a la prueba? Solución, sean los siguientes eventos: \\(Y+\\) La prueba da positivo a Tuberculosis \\(Y-\\) La prueba da negativo a Tuberculosis \\(T\\) La persona tiene tuberculosis \\(T^c\\) La persona no tiene tuberculosis La información dada es: \\(P(T)=0.1\\), \\(P(T^c)=0.9\\), \\(P(Y+/T)=0.8\\), \\(P(Y+/T^C)=0.3\\), \\(P(T/Y+)=?\\) \\[P(T/Y+)=\\frac{P(T)P(Y+/T)}{P(Y+)}=\\frac{P(T)P(Y+/T)}{P(T)*P(Y+/T)+P(T^C)*P(Y+/T^C)}\\] \\[P(T/Y+)=\\frac{0.1*0.8}{0.1*0.8+0.9*0.3}=\\frac{0.08}{0.35}=0.2286\\] Repasar, Monty Hall "],
["tema-3-variables-aleatorias.html", "3 Tema 3: Variables aleatorias 3.1 Introducción a variable aleatoria 3.2 Función de probabilidad (densidad) 3.3 Función de distribución (acumulada) 3.4 Variables aleatorias discretas 3.5 Variables aleatorias continuas 3.6 Esperanza matemática 3.7 Varianza 3.8 Teorema de Markov 3.9 Desigualdad de Chebyshev 3.10 Función Generatriz de Momentos", " 3 Tema 3: Variables aleatorias El objetivo de este tema es aproximarnos a modelos probabilísticos con sus respectivos parámetros, esto nos ayudara a adaptar diversos problemas reales. 3.1 Introducción a variable aleatoria Definión: Sea \\(E\\) un experimento y \\(\\Omega\\) el espacio muestral asociado a este experimento. Una función \\(X: \\Omega \\rightarrow IR\\), de tal forma que a cada elemento \\(w \\in \\Omega\\) le asocia un número real \\(x=X(w)\\) se denomina variable aleatoria. Nota 1: En el fondo estamos implicando que ahora vamos a trabajar exclusivamente con números en la recta real, donde estos números tienen asociado una probabilidad de ocurrencia. Nota 2: Debemos distinguir dos aspectos respecto trabajar sobre la recta real, (1) se pueden definir valores discretos (2) se pueden definir valores continuos. \\(X\\) es la variable aleatoria (va), el dominio de \\(X\\) es todo \\(\\Omega\\), y el rango es un sub conjunto de la recta real, el rango lo vamo a denotar como \\(Rx\\). \\(Rx \\in IR\\) Ejemplo 1: Establecer la variable aleatoria detrás del experimento de lanzar dos dados y obtener la suma de las caras. Solución, \\(\\#\\Omega=36\\) \\[\\Omega=\\{(1,1),(1,2),(1,3),(1,4),\\ldots,(6,6)\\}\\] \\[X: \\{X(1,1)=2,X(1,2)=3,\\ldots,X(6,6)=12\\}\\] El recorrido de \\(X\\), \\(Rx=\\{2, 3, \\ldots,12 \\}\\) Ejemplo 2: Sea el experimento lanzar 3 monedas y observar el resultado y definir la variable aleatoria como la cantidad de caras que salen en los lanzamientos. Solución, sean los eventos \\(C=cara\\), \\(S=Sello\\) \\[\\Omega=\\{(CCC),(CCS),(CSC),(SCC),(CSS),(SCS),(SSC),(SSS) \\}\\] \\[X: \\{X(CCC)=3,X(CCS)=2,X(CSC)=2,\\ldots,X(SSS)=0 \\}\\] A partir de esto, \\(Rx=\\{0,1,2,3\\}\\) 3.2 Función de probabilidad (densidad) Definión: Sea \\(X: \\Omega \\rightarrow IR\\), una va que toma los valores \\(x_1,x_2, \\ldots\\),. Se dice que \\(P(x_i)\\) es una función de probabilidad o distribución de probabilidad de la variable aleatoria \\(X\\). Si a cada valor de \\(x_i\\) se le asigna una probabilidad de ocurrencia. \\[P(x_i)=P(X=x_i)=P(w\\in \\Omega/X(w)=x_i)\\] Ejemplo 1: Para el ejemplo de las monedas, podemos calcular lo siguiente: \\[\\begin{array} &amp; &amp; P(X=0)=\\frac{1}{8}\\\\ &amp; P(X=1)=\\frac{3}{8}\\\\ &amp; P(X=2)=\\frac{3}{8}\\\\ &amp; P(X=3)=\\frac{1}{8}\\\\ \\end{array} \\] X 0 1 2 3 \\(P(X=x)\\) 1/8 3/8 3/8 1/8 Tomar en cuenta que: \\[\\sum_{Rx}P(X=x_i)=1\\] Ejercicio: Construir la distribución de probabilidad para el ejemplo del lanzamiento de los 2 dados. X 2 3 4 5 6 7 8 9 10 11 12 \\(P(X=x)\\) 1/36 2/36 3/36 4/36 5/36 6/36 5/36 4/36 3/36 2/36 1/36 1 A partir de la tabla calcular las siguientes probabilidad: \\(P(X\\leq 6)=P(X=2)+P(X=3)+P(X=4)+P(X=5)+P(X=6)=15/36\\) \\(P(X\\leq 7)=21/36\\) \\(P(X\\geq 7)=1-P(X&lt;7)=1-P(X\\leq 6)=1-\\frac{15}{36}=21/36\\) \\(P(X\\leq 2)=P(X=2)=1/36\\) \\(P(X &gt; 2)=1-P(X \\leq 2)=1-\\frac{1}{36}=\\frac{35}{36}\\) 3.3 Función de distribución (acumulada) Nota: Es muy similar a lo que se vio en la parte de estadística descriptiva cuando se calculo las frecuencias relativas/absolutas acumuladas. Definición: La función de distribución acumulada de una va \\(X\\), denotada por \\(F(X)\\), es una función: \\(F: IR \\rightarrow [0,1]\\), esta esta definida como: \\[F(X)=P(X\\leq x)\\] Propiedades de \\(F(X)\\) Es una función no decreciente, si \\(x_i&lt;x_j\\), entonces \\(F(x_i)&lt;F(x_j)\\), \\(i\\neq j\\) \\(F(x)\\) es una función continua por la derecha \\[lim+_{x\\rightarrow x_0} F(x)=F(x_0) \\] * \\(lim_{x\\rightarrow -\\infty} F(x)=0\\), \\(lim_{x\\rightarrow +\\infty} F(x)=1\\), \\(F(-\\infty)=0\\), \\(F(+\\infty)=1\\) Ejemplo: Para el caso de los dados X 2 3 4 5 6 7 8 9 10 11 12 \\(P(X=x)\\) 1/36 2/36 3/36 4/36 5/36 6/36 5/36 4/36 3/36 2/36 1/36 1 \\(F(x)=P(X\\leq x)\\) 1/36 3/36 6/36 10/36 15/36 21/36 26/36 30/36 33/36 35/36 1 Ejercicios, Página 315 del libro, resolver los ejercicios 1 y 2. Propiedades, si existe un \\(a&lt;b\\) Caso discreto \\[P(X\\leq a) = F(a)\\] \\(P(a&lt; X \\leq b )=F(b)-F(a)\\) \\(P(a\\leq X \\leq b )=F(b)-F(a)+P(X=a)\\) \\(P(a &lt; X &lt; b )=F(b)-F(a)-P(X=b)\\) \\(P(X&gt;b)=1-P(X\\leq b)=1-F(b)\\) En el ejemplo de los dados, calcular: \\[P(4&lt;X\\leq 7)=F(7)-F(4)=21/36-6/36=15/36\\] \\[P(4&lt;X\\leq 7)=P(X=5)+P(X=6)+P(X=7)=4/36+5/36+6/36= 15/36\\] Ejercicio 1 pg-315, \\(Rx=\\{-2,0,1,4\\}\\), \\(P(X=-2)=0.4\\), \\(P(X=0)=0.1\\), \\(P(X=1)=0.3\\) y \\(P(X=4)=0.2\\). Encontrar a \\(F(X)\\) X -2 0 1 4 TOTAL P(X=x) 0.4 0.1 0.3 0.2 1 P(X&lt;=x)=F(X) 0.4 0.5 0.8 1 \\(P(X&gt;0)=P(X=1)+P(X=4)=0.5\\), \\(P(X&gt;0)=1-P(X\\leq 0)=1-F(0)=1-0.5=0.5\\) \\(P(0&lt;X&lt;1)=0\\), \\(P(0&lt;X&lt;1)=F(1)-F(0)-P(X=1)=0.8-0.5-0.3=0\\) \\(P(0\\le X \\leq 1)=F(1)-F(0)+P(X=0)=0.8-0.5+0.1=0.4\\) Ejercio 2 pg 315. Una moneda es lanzada repetidamente hasta obtener cara por primera vez, Sea \\(X\\) la va que denota el número de lanzamientos que son necesarios para obtener cara por primera vez. \\(F(X)\\) Solución, definir el \\(Rx=\\{1,2, \\ldots , \\infty\\}\\) X 1 2 3 4 5 6 … i P(X=x) 0.5 0.25 0.125 0.5^4 0.5^5 0.5^6 … 0.5^i F(X)=P(X&lt;=x) 0.5 0.75 0.875 \\(P(C)=0.5\\), \\(P(S_1\\cap C_2)=P(S_1)*P(C_2/S_1)=0.5*0.5=0.25\\), \\(P(S_1\\cap S_2 \\cap C_3)=0.5*0.5*0.5=0.125\\), Asi, \\[P(X=x)=0.5^x\\] \\[\\sum_{Rx}{P(X=x)}=1, \\sum_{x=1}^\\infty{0.5^x}=1 \\] \\[F(X)=P(X\\leq x)=P(X \\leq t)=\\sum_{Rx}^t{P(X=x)}=\\sum_{x=1}^t{0.5^x}=TAREA\\] 3.4 Variables aleatorias discretas El recorrido es discreto, numerable \\(\\sum_{Rx}P(X=x)=1\\) Distribución acumulada: \\[F(t)=P(X\\leq t)=\\sum_{min Rx}^t{P(X=x)}\\] 3.5 Variables aleatorias continuas El recorrido es continuo, no numerable Sea \\(f(x)\\) una función continua definida en \\(Rx\\), esta es una función de probabilidad (densidad), si cumple: \\[\\int_{Rx}f(x)dx=1\\] Distribución acumulada \\[F(t)=P(X\\leq t)= \\int_{-\\infty,minRx}^t{f(x)dx} \\] Sea \\(c\\) una constante cualquiera, \\(P(X=c)=0\\) sea \\(a&lt;b\\), \\(P(a&lt;X&lt;b)=F(b)-F(a)\\), támbien: \\[P(a&lt;x&lt;b)=\\int_a^b f(x)dx\\] \\(f(x)= \\frac{d F(X)}{dx}=F&#39;(x)\\) Ejemplo, Sea \\(X\\) una va con función de densidad dada por: \\[f(x)=c (6x-2x^2), x\\in [0,2]\\] Encontrar el valor de \\(c\\) para que la función sea una función de probabilidad. Solución, \\[\\int_0^2 f(x)dx=1\\] $$ \\begin{array} &amp; _0^2 c (6x-2x^2)dx &amp; = c (_0^2 6x dx-_0^2 2x^2 dx )\\ &amp; = c ( 6 /_0^2- 2 /_0^2 )\\ &amp; = c ( 3 x^2/_0^2- /_0^2 )\\ &amp; = c ( 3 x^2- )/_0^2\\ &amp; = c (12-16/3 )\\ &amp; = c =1\\ \\end{array} $$ Entonces, \\(C=3/20\\). \\[f(x)=\\frac{3}{20} (6x-2x^2), x\\in [0,2]\\] \\[P(1&lt;X&lt;1.5)=\\int_{1}^{1.5} \\frac{3}{20} (6x-2x^2) dx= \\frac{3}{20} \\left(3x^2-\\frac{2x^3}{3} \\right)/_1^{1.5}=\\frac{3}{20}\\left (3*1.5^2-\\frac{2*1.5^3}{3} - 3*1^2+\\frac{2*1^3}{3} \\right)=0.325\\] \\[P(X \\leq 1.7)=\\int_0^{1.7} f(x) dx=F(1.7)=0.8092\\] \\[P(X &gt; 0.2)=1-P(X\\leq0.2)=1-F(0.2)=1-0.0172=0.9828\\] \\[F(t)=\\int_0^t \\frac{3}{20} (6x-2x^2) dx = \\frac{3}{20} \\left(3x^2-\\frac{2x^3}{3} \\right)/_0^{t}=\\frac{3}{20} \\left(3t^2-\\frac{2t^3}{3} \\right)\\] \\[F(x)=\\frac{3}{20} \\left(3x^2-\\frac{2x^3}{3} \\right)\\] Para el primer ejercicio, \\[P(1&lt;X&lt;1.5)=F(1.5)-F(1)=0.675-0.35=0.325\\] Nota Caso continuo \\[P(a&lt;X&lt;b)=P(a\\leq X \\leq b)=P(a\\le X &lt;b)=F(b)-F(a)\\] \\[P(X&lt;a)=P(X\\leq a)=F(a)\\] \\[P(X&gt;a)=P(X\\geq a)= 1-P(X&lt;a)=1-F(a)\\] Tarea: Realizar los ejercicios 1, 2 y 3 de la pg 345 del libro guía. 3.6 Esperanza matemática Es el valor esperado detrás de la variable aleatoria. Nota: vamos a introducir al operador Esperanza (E) Caso Discreto \\[E[X]=\\sum_{Rx}xP(X=x)\\] El operador esperanza funciona: \\[E[g(x)]=\\sum_{Rx}{g(x)*P(X=x)}\\] Calcule \\(E[X^2]\\), \\[E[X^2]=\\sum_{Rx}{X^2*P(X=x)}\\] Ejemplos: Para el caso de la suma del lanzamiento de dos dados \\[E[X]=2*\\frac{1}{36}+3*\\frac{2}{36}+\\ldots+12*\\frac{1}{36}=7\\] Caso Continuo \\[E[X]=\\int_{Rx} xf(x)dx\\] El operador esperanza: \\[E[g(x)]=\\int_{Rx}g(x)f(x)dx\\] \\[E[X^2]=\\int_{Rx}{x^2 f(x)dx}\\] Ejemplo, encontrar la esperanza matemática de la última función continua vista. \\[f(x)=\\frac{3}{20} (6x-2x^2), x\\in [0,2]\\] La esperanza matemática esta dada por: \\[E[X]=\\int_0^2{x\\frac{3}{20} (6x-2x^2)dx}=\\] \\[E[X]=\\frac{3}{20}\\int_0^2{6x^2-2x^3dx}=\\frac{3}{20}\\left( 2x^3-\\frac{x^4}{2} \\right)_0^2=\\frac{3}{20}(16-8)=\\frac{24}{20}=\\frac{6}{5}\\] fx&lt;-function(x){ y&lt;-(3/20)*(6*x-2*x^2) return(y) } curve(fx,xlim=c(0,2)) abline(v=c(6/5),col=&quot;red&quot;) 3.6.1 Propiedades Sean \\(a\\), \\(b\\), \\(c\\) constantes \\(E[0]=0\\) \\(E[a]=a\\) \\[E[a]=\\sum_{Rx}{a*P(X=x)}=a\\sum_{Rx}P(X=x)=a*1=a\\] \\(E[aX]=aE[X]\\) \\[E[aX]=\\sum_{Rx}{ax*P(X=x)}=a \\sum_{Rx}{x*P(X=x)}=a * E[X]\\] \\(E[h(x)+g(x)]=E[h(x)]+E[g(x)]\\) La esperanza se distribuye en la suma \\[E[h(x)+g(x)]=\\int_{Rx}[h(x)+g(x)]*f(x)dx=\\int_{Rx}h(x)f(x)dx+\\int_{Rx}g(x)f(x)dx=E[h(x)]+E[g(x)]\\] \\(E[X+Y]=E[X]+E[Y]\\) \\(E[aX+bY]=aE[X]+bE[Y]\\) \\(E[g(x)*h(x)] \\neq E[g(x)]*E[h(x)]\\) \\(E[X*Y] \\neq E[X]*E[Y]\\) 3.7 Varianza La varianza de define a partir del operador esperanza como: \\[V(X)=E[ \\left( X-E[X] \\right)^2]\\] Caso discreto \\[V(X)=E[ \\left( X-E[X] \\right)^2]=\\sum_{Rx} \\left( x-E[X] \\right)^2 * P(X=x)\\] Caso continuo \\[V(X)=E[ \\left( X-E[X] \\right)^2]=\\int_{Rx} \\left( x-E[X] \\right)^2 * f(x)dx\\] Forma corta para el calculo de la varianza: \\[V(X)=E[X^2]-E[X]^2\\] Demostración: \\[V(X)=E[ \\left( X-E[X] \\right)^2]=E[X^2-2XE[X]+E[X]^2]=E[X^2]-2E[X]E[X]+E[X]^2=\\] \\[= E[X^2]-2E[X]^2+E[X]^2=E[X^2]-E[X]^2\\] Ejercicio: calcular la varianza para el caso continuo visto anteriormente. \\[E[X^2]=\\int_0^2{x^2 f(x)dx}\\] 3.7.1 Propiedades Sean \\(a\\), \\(b\\) y \\(c\\) contantes \\(V(a)=0\\) \\[V(a)=E[a^2]-E[a]^2=a^2-a^2=0\\] \\(V(aX)=a^2V(X)\\) \\[V(aX)=E[(aX)^2]-E[aX]^2=a^2E[X^2]-(aE[X])^2=a^2E[X^2]-a^2 E[X]^2=a^2(E[X^2]-E[X]^2)=a^2 V(X)\\] \\(V(a+X)=V(X)\\) \\[V(a+X)=E[(a+X-E[a+X])^2]=E[(a+X-a-E[X])^2]=E[(X-E[X])^2]=V(X)\\] \\(V(a+bX)=b^2 V(X)\\) Tarea Ejemplo, sea la función de densidad dada por: \\[f(x)=\\frac{3}{20} (6x-2x^2), x\\in [0,2]\\] Sabemos que \\(E[X]=6/5\\). Encontrar la varianza. Sea, \\(V(X)=E[X^2]-E[X]^2\\) nos falta encontrar a \\(E[X^2]\\). \\[E[X^2]=\\int_0^2 x^2 \\frac{3}{20} (6x-2x^2)dx=\\frac{3}{20} \\int_0^2 6x^3-2x^4 dx=\\frac{3}{20}\\left(\\frac{3x^4}{2}-\\frac{2x^5}{5} \\right)_0^2=\\frac{3}{20}\\left(24 - \\frac{64}{5} \\right)=1.68 \\] \\[V(X)=1.68-(6/5)^2=0.24=6/25\\] 3.8 Teorema de Markov Si \\(X\\) es una va, tal que \\(X\\geq 0\\), \\(P(X\\geq 0)=1\\), entonces, para cualquier constante \\(a&gt;0\\). Se tiene: \\[P(X \\geq a) \\leq \\frac{E[X]}{a}\\] Demostración \\[E[X]=\\int_{Rx}xf(x)dx=\\int_0^{\\infty}{xf(x)}dx=\\int_0^a{xf(x)dx}+\\int_a^{\\infty}{xf(x)dx} \\geq \\int_a^{\\infty}{xf(x)dx}\\] \\[E[X]\\geq\\int_a^{\\infty}{xf(x)dx} \\geq \\int_a^{\\infty}{a f(x)dx} = a \\int_a^{\\infty}{ f(x)dx} = a P(X\\geq a)\\] \\[E[X]\\geq a P(X\\geq a)\\] \\[P(X\\geq a) \\leq \\frac{E[X]}{a}\\] Ejemplo, en una clase de Estadística el promedio de notas de un anterior semestre fue 57 puntos. Si asumimos que este promedio sera muy similar este semestre, ¿Cuál será la probabilidad que un estudiante obtenga 51 o más?. Sea \\(X\\) el rendimiento de los estudiantes, \\(E[X]=57\\). \\(P(X\\geq 51)\\). \\[P(X\\geq 51)\\leq \\frac{E[X]}{a}=\\frac{57}{51}=1.11\\approx 1\\] \\[P(X\\geq 90)\\leq \\frac{57}{90}=0.63\\] \\[P(X\\geq 99)\\leq \\frac{57}{99}=0.576\\] 3.9 Desigualdad de Chebyshev Si \\(X\\) es una va con media \\(E[X]=\\mu\\) (finita) y varianza \\(V(X)=\\sigma^2\\) (finita), entonces para cualquier número \\(k&gt;0\\) se cumple: \\[P(|X-\\mu|\\geq k) \\leq \\frac{V(x)}{k^2}\\] \\[P(|X-\\mu|\\geq k \\sigma) \\leq \\frac{1}{k^2}\\] Demostración \\[P(|X-\\mu|\\geq k)=P((X-\\mu)^2\\geq k^2)\\leq \\frac{E[(X-\\mu) ^2]}{k^2}=\\frac{E[(X-E[X]) ^2]}{k^2}=\\frac{V(X)}{k^2}\\] Ejermplos. Se conoce en base al curso de verano pasado de la materia de estadística I, que el promedio de notas fue de 65 puntos. Si suponemos un rendimiento similar en este semestre de los estudiantes inscritos. ¿Cuál es la probabilidad que un estudiante obtenga una nota mayor a 75? (Al menos la probabilidad máxima) Solución. \\(X:\\) La nota de los estudiantes de la materia de Estadística I en este semestre, el recorrido de \\(X\\) es \\(X\\geq 0\\). \\(E[X]=65\\) \\[P(X \\geq 75) =\\int_{75}^{\\infty}{f(x)dx}=\\sum_{x=75}^{100}{P(X=x)}\\] Dado que no conocemos \\(f(x)\\) o \\(P(X=x)\\) para \\(x\\geq0\\), recurrimo a el teorema de Markov \\[P(X\\geq 75) \\leq \\frac{E[X]}{a}=\\frac{65}{75}=0.867\\] La probabilidad que un estudiantes obtenga una nota mayor o igual a 75, necesariamente es menor a 0.867. Cuál sera la probabilidad que un estudiantes obtenga una nota mayor o igual a 90 puntos. \\[P(X\\geq90)\\leq \\frac{65}{90}=0.7222\\] Se sabe también que la varianza alcanzada en el curso de verano fue de 36, ¿Qué puede decirse de la probabilidad de que un estudiante tenga un puntaje entre 55 y 75? Solucion, La varianza de \\(X\\), es \\(V(X)=36\\) \\[P(55 \\leq X \\leq 75)=P(55-65\\leq X-\\mu \\leq75-65)=P(-10 \\leq X-\\mu \\leq 10)=P(|X-\\mu|\\leq10)\\] \\[P(|X-\\mu|\\leq10)=1-P(|X-\\mu|&gt;10)=1-P(|X-\\mu|\\geq10)\\] Suponiendo que \\(X\\) es continua \\[P(|X-\\mu|\\geq10) \\leq \\frac{36}{10^2}=0.36\\] \\[P(55 \\leq X \\leq 75)=P(|X-\\mu|\\leq10)\\leq 1-0.36=0.64 \\] Ejercicio 1, Supongamos que X es un va con media y varianza ambos iguales a 20. ¿Qué puede decirse acerca de \\(P(0\\leq X\\leq40)\\)? Solución, \\(E[X]=V(X)=20\\) \\[P(0\\leq X\\leq40)=P(0-20 \\leq X -\\mu\\leq40-20)=P(-20 \\leq X-\\mu\\leq20)=P(|X-\\mu|\\leq 20)\\] \\[P(|X-\\mu|\\leq 20)=1-P(|X-\\mu|&gt;20)\\] Asumamos que \\(X\\) es continua, \\[P(|X-\\mu|\\geq 20)\\leq \\frac{20}{20^2}=\\frac{1}{20}\\] Así, \\[P(0\\leq X\\leq40)=P(|X-\\mu|\\leq 20)=1-P(|X-\\mu|\\geq20) \\geq 1-\\frac{1}{20}=\\frac{19}{20} \\] Ejercicio 2, Suponga que X es una va para el cual: \\(P(X\\geq 0)=1\\) y \\(P(X\\geq 10)=1/5\\). Probar que \\(E[X]\\geq 2\\). \\[P(X\\geq a)\\leq \\frac{E[X]}{a}\\] \\[\\frac{1}{5}=P(X\\geq 10)\\leq \\frac{E[X]}{10}\\] \\[\\frac{1}{5}\\leq \\frac{E[X]}{10}\\] \\[E[X]\\geq 2\\] 3.10 Función Generatriz de Momentos Definimos a los momentos respecto el origen de un va \\(X\\), como: \\[E[X^n]\\] Se conoce como el momento \\(n\\). \\(E[X]\\) es el primer momento. La varianza de \\(X\\), \\(V(X)=E[X^2]-E[X]^2\\) se construye a partir del momento 1 y 2. 3.10.1 Definición \\[M_X(t)=E[ e^{tx}]\\] Caso continuo, \\[M_X(t)=E[ e^{tx}]=\\int_{Rx} e^{tx}f(x)dx\\] Caso discreto, \\[M_X(t)=E[ e^{tx}]=\\sum_{Rx} e^{tx}P(X=x)dx\\] La propiedad principal de \\(M_X(t)\\) \\[M_X^{(n)}(t=0)= \\left\\{ \\frac{\\partial^n}{\\partial t^n} E[ e^{tx}] \\right\\}_{t=0}=E[x^n] \\] "],
["tema-4-distribuciones-discretas.html", "4 Tema 4: Distribuciones Discretas 4.1 Bernoulli 4.2 Binomial 4.3 Geométrica 4.4 Binomial Negativa 4.5 Hipergeométrica 4.6 Poisson", " 4 Tema 4: Distribuciones Discretas 4.1 Bernoulli Sea \\(X\\) una v.a, se dice que \\(X\\sim Bernoulli(p)\\) si su función de probabilidad es: \\[p(x)=P(X=x)= p^x (1-p)^{1-x} \\hspace{0.5cm}; x=\\{0,1\\}\\] Probabilidad de éxito: \\[P(X=1)=p^1(1-p)^{1-1}=p\\] Probabilidad de fracaso: \\[P(X=0)=p^0(1-p)^{1-0}=1-p\\] Ejemplo 1, Sea el experimento lanzar una moneda y la variable aleatoria \\(X\\), sale cara \\(X=1\\), \\(X=0\\) cuando no salga cara, si suponemos que la moneda es legal, \\(p=0.5\\). \\(X\\sim Bernoulli(p=0.5)\\) Ejemplo 2, Sea el experimento lanzar dos dados y sumar el resultados de las caras, si definimos la variable aleatoria como \\(X=1\\) cuando la suma es 12 y \\(X=0\\) en otro caso, si asumimos que los dos dados son legales, en este caso el valor de \\(p=1/36\\), \\(X\\sim Bernoulli(p=1/36)\\) Ejemplo 3, En el juego del cacho la mejor jugada es cuando todos los dados tienen el mismo número, normalmente se juega con 5 dados. (1,1,1,1,1), (2,2,2,2,2), …, (6,6,6,6,6). Modele la variable aleatoria y defina la distribución. Sea \\(X\\) la va, \\(X=1\\) cuando todos los dados son iguales y \\(X=0\\) en otro caso. Si suponemos que los dados son legales, el valor de \\(p=\\frac{6}{7776}=\\frac{3}{3888}=\\frac{1}{1296}\\), \\(X\\sim Bernoulli(p=1/1296)\\) Donde; \\[E[x]=p\\] Demostración: \\[E(X)=\\sum_{Rx}xP(X=x)= 0*(1-p)+1*p=p\\] \\[V[x]=p*(1-p)\\] \\[E[X^2]=\\sum_{Rx}x^2P(X=x)=0^2 (1-p)+1^2p=p\\] \\[V(X)=E[X^2]-E[X]^2=p-p^2=p(1-p)\\] 4.1.1 Usos Bernoulli \\(X\\) representa éxito (\\(X=1\\)) o fracaso (\\(X=0\\)) en la realización de un proceso al azar. Con \\(p\\) la probabilidad de éxito \\(0&lt;p&lt;1\\). 4.2 Binomial Sea \\(X\\) una v.a, se dice que \\(X\\sim Binomial(n,p)\\) si su función de probabilidad es: \\[p(x)=P(X=x)= {n \\choose x} p^x (1-p)^{n-x} \\hspace{0.5cm}; x=\\{0,1,\\ldots,n\\}\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =n*p\\\\ V[x] &amp; =n*p*(1-p)\\\\ M_X(t) &amp; =(p*e^t+(1-p))^n \\end{array} \\] Demostración, Sea \\(X_1, X_2,\\ldots,X_n\\) \\(n\\) variables aleatorias independientes entre ellas e idénticamente distribuidas, \\(X_i \\sim Bernoulli(p)\\) para todo \\(i=1, \\ldots, n\\). Sea \\(X\\) una variable aleatoria, tal que \\(X=X_1+X_2+\\ldots+X_n\\), se dice que \\(X \\sim Binomial(n,p)\\), en ese sentido: \\[E[X]=E[X_1+X_2+\\ldots+X_n]=E[X_1]+\\ldots+E[X_n]=p+p+\\ldots+p=np\\] Nota 1. Si tengo dos variables \\(X\\) e \\(Y\\) y estas son independientes, entonces: \\[V(X+Y)=V(X)+V(Y)\\] Caso contrario, si no son independientes \\[V(X+Y)=V(X)+V(Y)+2*COV(X,Y)\\] \\[V(X)=V(X_1+X_2+\\ldots+X_n)=V(X_1)+V(X_2)+\\ldots+V(X_n)=p*(1-p)+p(1-p)+\\ldots+p(1-p)\\] \\[V(X)=np(1-p)\\] 4.2.1 Usos Binomial \\(X\\) representa el número de éxitos en \\(n\\) ensayos independientes Bernoullis. Con \\(p\\) la probabilidad de éxito \\(0&lt;p&lt;1\\) en un ensayo bernoulli. 4.2.2 Ejemplos Un estudiante rinde un examen con 10 preguntas de opción múltiple, donde cada pregunta contiene hasta 5 alternativas de respuesta, donde solo una es correcta. Si el estudiante responde las preguntas al azar, defina la distribución de probabilidad que modela el problema y calcula la probabilidad que el estudiante; Conteste todas las preguntas de forma incorrecta Conteste todas las preguntas de forma correcta Obtenga más de la mitad de las respuestas correctas Respuesta, El experimento Bernoulli es responder una pregunta al azar con probabilidad de exito de \\(p=1/5\\) \\(X\\): El número de preguntas respondidas de forma correcta, \\(X\\sim Binomial(n=10,p=1/5)\\) \\[P(X=x)= {10 \\choose x} 0.2^x 0.8^{10-x} \\hspace{0.5cm}; x=\\{0,1,\\ldots,10\\}\\] \\[P(X=0)={n \\choose x} p^x (1-p)^{n-x}={10 \\choose 0} 0.2^0 (1-0.2)^{10-0}=0.107\\] \\[P(X=10)={n \\choose x} p^x (1-p)^{n-x}={10 \\choose 10} 0.2^{10} (1-0.2)^{10-10}=0.0000001024\\] \\[P(X&gt;5)=P(X=6)+P(X=7)+P(X=8)+P(X=9)+P(X=10)=\\sum_{x=6}^{10}{P(X=x)}=0.0064\\] d) ¿Cuál es la probabilidad que el estudiante responde entre 4 a 6 preguntas de forma correcta? \\[P(4\\leq X \\leq 6)=P(X=4)+P(X=5)+P(X=6)={10 \\choose 4} 0.2^4 0.8^{10-4}+{10 \\choose 5} 0.2^5 0.8^{10-5}+{10 \\choose 6} 0.2^6 0.8^{10-6}\\] \\[P(4\\leq X \\leq 6)=0.088+0.026+0.005=0.119\\] La \\(E[X]=np=10*0.2=2\\), \\(V(X)=np(1-p)=npq=10*0.2*0.8=1.6\\), \\(\\sqrt{V(X)}=\\sqrt{1.6}=1.26\\) barplot(dbinom(0:10,10,0.2),names.arg = 0:10) Nota: Sea \\(X_1,X_2,\\ldots,X_n\\), donde \\(X_i \\sim Bernoulli(p)\\) para todo \\(i=1:n\\), si definimos a \\(Y=X_1+X_2+\\ldots+X_n\\), \\(Y\\sim Binomial(n,p)\\). \\[E[Y]=E[X_1+X_2+\\ldots+X_n]=E[X_1]+E[X_2]+\\ldots+E[X_n]=p+p+\\ldots+p=np\\] Ejercicio, Supongamos que un jugador de basketball tiene una probabilidad de 7/9 de encestar un tiro libro y sus tiros son independientes. Si el consigue 5 tiros libres en un juego en particular. ¿Cuál es la probabilidad de que él enceste 2 o más tiros?. Solución: X: Número de tiros correctos, \\(X\\sim Binomial(n=5,p=7/9)\\), \\(Rx=\\{0,1,2,3,4,5\\}\\) \\[P(X\\geq 2)=\\sum_{x=2}^{x=5}{P(X=x)}=P(X=2)+P(X=3)+P(X=4)+P(X=5)\\] \\[P(X\\geq 2)=1-P(X&lt;2)=1-[P(X=0)+P(X=1)]=1- \\left( {5 \\choose 0} (7/9)^0 (1-7/9)^{5-0}+{5 \\choose 1} (7/9)^1 (1-7/9)^{5-1} \\right)\\] \\[P(X\\geq2)=1-(0.00054+0.00948)=0.98997\\] 4.3 Geométrica Sea \\(X\\) una v.a, se dice que \\(X\\sim G(p)\\) si su función de probabilidad es: \\[p(x)=P(X=x)= p (1-p)^{x} \\hspace{0.5cm}; x=\\{0,1,\\ldots\\}\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =\\frac{(1-p)}{p}\\\\ V[x] &amp; =\\frac{(1-p)}{p^2}\\\\ M_X(t) &amp; = \\frac{p}{1-(1-p)*e^t} \\hspace{0.5cm} \\end{array} \\] Miremos algunas probabilidades, \\[P(X=0)=p(1-p)^0=p\\] \\[P(X=1)=p(1-p)^1\\] \\[P(X=2)=p(1-p)^2\\] \\[P(X=2)=P(F_1 \\cap F_2 \\cap E_3)=P(F_1)*P(F_2)*P(E_1)=(1-p)*(1-p)*p=(1-p)^2p\\] Tarea, Demostrar que la distribución geométrica es una distribución de probabilidad. \\[\\sum_{Rx} P(X=x)=1 \\] \\[\\sum_{x=0}^\\infty p (1-p)^x=\\frac{p}{1-(1-p)}=1\\] Resolver, \\[F(t)=P(X\\leq t)=\\sum_{x=0}^t p (1-p)^x\\] 4.3.1 Usos Geométrica \\(X\\) representa el número de fracasos antes de obtener el primer éxito en ensayos sucesivos Bernoullis. Con \\(p\\) la probabilidad de éxito \\(0&lt;p&lt;1\\). 4.3.2 Ejemplos Se realiza el lanzamiento de una moneda legal, Sea X una va, donde X: El número de fracasos antes de sacar Cara por primera vez. Calcular la probabilidad de \\(X=10\\), \\(X=0\\), \\(X=5\\). Solución, \\(X\\sim G(p=0.5)\\). \\(P(X=10)=p (1-p)^x=0.5*0.5^{10}=0.00049\\) \\(P(X=0)=p (1-p)^x=0.5*0.5^0=0.5\\) \\(P(X=5)=0.5*0.5^5=0.0156=P(S_1\\cap S_2\\cap S_3\\cap S_4 \\cap S_5 \\cap C_6)=P(S)^5*P(C)\\) Una persona se compra un boleto de lotería cada mes, se conoce que en cada sorteo participan 100,000 boletos de lotería, 1) modele el problema, 2) calcule la probabilidad que esta persona gane la lotería el primer mes, 3) la probabilidad que gane la lotería en el mes 13, 4) La probabilidad que gane la lotería el primer año. 5) ¿Cuántos meses se espera hasta que esta persona gane la lotería? Solución, X: El número de meses antes de ganar la lotería, \\(X\\sim G(p=1/100000)\\) \\(P(X=0)=p(1-p)^x=p(1-p)^0=p=\\frac{1}{100000}\\) \\(P(X=12)=p(1-p)^{12}=1/100000*(1-1/100000)^{12}=0.000009998\\) \\(P(X=0)+P(X=1)+P(X=2)+\\ldots+P(X=11)=P(X&lt;12)=P(X\\leq11)=TAREA\\) \\(E[X]=\\frac{(1-p)}{p}=\\frac{1-1/100000}{1/100000}=99999\\), \\(V(X)=\\frac{1-p}{p^2}=9999900000\\), \\(\\sqrt{V(x)}=99999.5\\) Imaginemos que la persona compra 15 boletos de lotería cada mes, con este cambio, en cuantos años se espera que la persona pueda ganar la lotería. (TAREA) 4.4 Binomial Negativa Sea \\(X\\) una v.a, se dice que \\(X\\sim BN(r,p)\\) si su función de probabilidad es: \\[p(x)=P(X=x)= {r+x-1 \\choose x} p^r (1-p)^{x} \\hspace{0.5cm}; x=\\{0,1,\\ldots\\}\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =\\frac{r*(1-p)}{p}\\\\ V[x] &amp; =\\frac{r*(1-p)}{p^2}\\\\ M_X(t) &amp; = \\left(\\frac{p}{1-(1-p)*e^t} \\right)^r \\hspace{0.5cm} ;t&lt;ln(1/(1-p)) \\end{array} \\] 4.4.1 Usos Binomial Negativa \\(X\\) representa el número de fracasos antes de obtener \\(r\\) éxitos en ensayos sucesivos Bernoullis. Con \\(p\\) la probabilidad de éxito \\(0&lt;p&lt;1\\). 4.4.2 Ejemplo, (pg 471, 3). Una moneda correcta es lanzada sucesivamente hasta que aparezca cara por décima vez. Sea X la va que denota el número de sellos que ocurren. Hallar la función de probabilidad de \\(X\\). Solución, \\(X\\sim BN(r=10,p=0.5)\\) \\[P(X=x)= {9+x \\choose x} 0.5^{10} 0.5^x \\] Supongamos que una sucesión de lanzamientos independientes es hecho con una moneda, cuya probabilidad de obtener cara en cualquiera de los lanzamientos es de \\(1/30\\) ¿Cuál es la esperanza del número de sellos que se pueden obtener antes de que se obtengan 5 caras? ¿Cuál es la varianza del número de sellos que se pueden obtener antes de que se obtengan 5 caras? Solución, \\(X\\sim BN(r=5,p=1/30)\\), X: El número de sellos antes de obtener 5 caras \\(E[X]=\\frac{r*(1-p)}{p}=\\frac{5*(29/30)}{1/30}=145\\) \\(V(X)=\\frac{r*(1-p)}{p^2}=\\frac{5*(29/30)}{(1/30)^2}=4350\\), \\(\\sqrt{V(X)}=65\\) Tarea 1, Tres personas tiran monedas al aire y el disparejo paga el café. Si los tres resultados son iguales, las monedas se tiran nuevamente. Encuentre la probabilidad de que se necesitan menos de 4 intentos. (Pg: 476, 30) Nota: BN(r=1, p) = G(p) Tarea 2, Para la distribución geométrica, demostrar: \\[E[X]=\\frac{(1-p)}{p}\\] \\[E[X]=\\sum_{Rx}{x*P(X=x)}=\\sum_0^{\\infty}{xp(1-p)^x}=\\frac{(1-p)}{p}\\] 4.5 Hipergeométrica Sea \\(X\\) una v.a, se dice que \\(X\\sim H(N,n,r)\\) si su función de probabilidad es: \\[p(x)=P(X=x)= \\frac{{N-r \\choose n-x}{r \\choose x}}{{N \\choose n}} \\hspace{0.5cm}; max\\{0,n-N+r\\} \\leq x \\leq min\\{r,n\\}\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =n*\\frac{r}{N}\\\\ V[x] &amp; =n * \\frac{r}{N} * \\frac{N-r}{N} * \\frac{N-n}{N-1}\\\\ \\end{array} \\] 4.5.1 Usos Hipergeométrica \\(X\\) denota el número de elementos que poseen la característica \\(A\\) en una muestra aleatoria de tamaño \\(n\\) seleccionado de una población de \\(N\\) elementos de los cuales \\(r\\) tienen característica \\(A\\) y \\(N-r\\) característica \\(B\\). 4.5.2 Ejemplo En una urna con 30 bolas de colores (10 negras, 5 blancas, 15 verdes). Se seleccionan 7 bolas de forma aleatoria y sin reposición. Si el interés es calcular la probabilidad de obtener bolas negras: Modelar la distribución que se ajusta al problema Calcular la probabilidad que se seleccionen; 0 bolas negras, todas negras, al menos 2 bolas negras. Solución, \\(X\\sim H(N=30,n=7,r=10)\\), \\(max(0,7-30+10) \\leq x \\leq min(10,7)\\), \\(0 \\leq x \\leq 7\\) \\[P(X=0)=\\frac{{20 \\choose 7-x}{10 \\choose x}}{{30 \\choose 7}}=\\frac{{20 \\choose 7}{10 \\choose 0}}{{30 \\choose 7}}=\\frac{77520*1}{2035800}=\\frac{77520}{2035800}=0.038\\] \\[P(X=7)==\\frac{{20 \\choose 0}{10 \\choose 7}}{{30 \\choose 7}}=\\frac{120}{2035800}=0.000059\\] \\[P(X\\geq 2)=P(X=2)+P(X=3)+...+P(X=7)\\] \\[P(X\\geq 2)=1-P(X&lt;2)=1-[P(X=0)+P(X=1)]=1-0.038-\\frac{{20 \\choose 6}{10 \\choose 1}}{{30 \\choose 7}}=1-0.038-0.19=0.772\\] ¿Cuál es la probabilidad de obtener 3 negras, 3 verdes y una blanca? \\[P(3N \\cap 3V \\cap 1B)=\\frac{{10 \\choose 3}{15 \\choose 3}{5 \\choose 1}}{{30 \\choose 7}}\\] Tarea (Pg 459, Ej 8) 4.6 Poisson Sea \\(X\\) una v.a, se dice que \\(X\\sim P(\\lambda)\\), (\\(\\lambda&gt;0\\)) si su función de probabilidad es: \\[p(x)=P(X=x)= \\frac{e^{-\\lambda} \\lambda^x}{x!} \\hspace{0.5cm}; x=\\{0,1,2, \\ldots \\}\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =\\lambda\\\\ V[x] &amp; =\\lambda\\\\ M_X(t) &amp; =e^{\\lambda (e^t -1)} \\end{array} \\] 4.6.1 Usos Poisson \\(X\\) representa el número de eventos de cierto tipo, que ocurren en un intervalo de tiempo, o en una región, o en un volumen. Fallas de un computador en un día de operación Número de clientes que entran a un banco en un día dado Nota: Si \\(X \\sim binomial(n,p)\\), si \\(n \\rightarrow \\infty\\) , \\(p \\rightarrow 0\\) y \\(\\lambda=n*p\\) permanece constante. Entonces se puede aproximar con \\(X \\sim Poisson(\\lambda = n*p)\\). \\(n \\geq 50\\), \\(p\\leq 0.1\\). ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000 2.000 3.000 3.001 4.000 14.000 ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000 2.000 3.000 3.002 4.000 16.000 Ejercicios, Verificar si efectivamente la distribución de Poisson es una distribución de probabilidad. \\[1=\\sum_{Rx} P(X=x)=\\sum_{x=0}^\\infty {\\frac{e^{-\\lambda} \\lambda^x}{x!}}=e^{-\\lambda}\\sum_{x=0}^\\infty {\\frac{\\lambda^x}{x!}}= e^{-\\lambda} e^\\lambda =e^0=1 \\] Esto recordando que: \\[e^y=\\sum_{x=0}^\\infty {\\frac{y^x}{x!}}\\] 2. Demostrar que si \\(X\\sim P(\\lambda)\\) la \\(E[X]=\\lambda\\), \\[\\lambda=E[X]=\\sum_{Rx}x P(X=x)=\\sum_{x=0}^\\infty {\\frac{x e^{-\\lambda} \\lambda^x}{x!}}=e^{-\\lambda}\\lambda \\sum_{x=0}^\\infty {\\frac{x \\lambda^x}{x! \\lambda}}=e^{-\\lambda}\\lambda \\sum_{x=0}^\\infty {\\frac{x \\lambda^{x-1}}{x! }}=\\] \\[=e^{-\\lambda}\\lambda \\sum_{x=1}^\\infty {\\frac{x \\lambda^{x-1}}{x (x-1)! }}=e^{-\\lambda}\\lambda \\sum_{x-1=0}^\\infty {\\frac{ \\lambda^{x-1}}{(x-1)! }}=e^{-\\lambda}\\lambda \\sum_{y=0}^\\infty {\\frac{ \\lambda^{y}}{y! }}=\\lambda e^{-\\lambda}e^\\lambda=\\lambda\\] 4.6.2 Ejemplos Cierta oficina de bomberos recibe en promedio 3 llamadas por día, calcular la probabilidad de que: Reciba 4 llamadas en un día Solución, X: Número de llamadas que recibe la oficina de bomberos en un día, tener en cuenta que el promedio o la media puede ser tomada como un sinónimo de la esperanza matemática \\(E[X]\\). Así, la información dada es \\(E[X]=3=\\lambda\\), entonces, \\(X\\sim P(\\lambda=3)\\) \\[P(X=4)=\\frac{e^{-\\lambda} \\lambda^x}{x!}=\\frac{e^{-3}3^4}{4!}=\\frac{4.0327}{24}=0.168\\] Reciba 3 o más llamadas en un día Solución, \\(X\\sim P(\\lambda=3)\\) \\[P(X\\geq 3)=1-P(X&lt;3)=1-[P(X=0)+P(X=1)+P(X=2)]=\\ldots\\] Reciba 10 llamadas en una semana (7 días) Solución, X: el número de llamadas a la oficina de bomberos durante 7 días. La idea es aplicar una regla de tres para re escalar la información, sabemos que en promedio se reciben 3 llamadas por día, en 7 días se espera en promedio que se reciban \\(3*7=21=E[X]=\\lambda\\). Entonces, \\(X\\sim P(\\lambda=3*7=21)\\) \\[P(X=10)=\\frac{e^{-21}21^{10}}{10!}=0.00348\\] ¿Cuántas llamadas en promedio se espera tener durante un año (365 días)? Solución: 3*365=1095 Suponga que hay en promedio 2 suicidios por año en una población de 50 mil habitantes. En una ciudad de 100 mil habitantes. Encuentre la probabilidad de que en un año dado haya: Un suicidio 2 o más suicidios Solución, X: Número de suicidios por año en ciudad de 100 mil habitantes, \\(X\\sim P(\\lambda=4)\\). \\[P(X=1)=\\frac{e^{-4}4^1}{1!}=0.0733\\] \\[P(X\\geq 2)=1-P(X&lt;2)=1-[P(X=0)+P(X=1)]=1-\\frac{e^{-4}4^0}{0!}-\\frac{e^{-4}4^1}{1!}=0.908\\] #######################################3 \\[P(X=8)= \\frac{{100 \\choose 2}{30 \\choose 8}}{{130 \\choose 10}} \\hspace{0.5cm}\\] "],
["tema-5-distribuciones-continuas.html", "5 Tema 5: Distribuciones Continuas 5.1 Uniforme 5.2 Exponencial 5.3 Distribución Gamma 5.4 Normal 5.5 Normal Estándar", " 5 Tema 5: Distribuciones Continuas 5.1 Uniforme Sea \\(X\\) una v.a, se dice que \\(X\\sim U(a,b)\\), con \\(a&lt;b\\). Si su función de densidad es: \\[f(x)=\\frac{1}{b-a} \\hspace{0.5cm}; x \\in [a,b]\\] Ejemplo, Sea \\(X\\) una va, donde \\(X\\sim U(a=2,b=4)\\). Dibuje la función y encuentre las probabilidades de: \\(P(2&lt;X&lt;3)\\) \\(P(3&lt;X&lt;4)\\) \\(P(X&lt;2.5)\\) Solución, \\[f(x)=\\frac{1}{4-2}=\\frac{1}{2}=0.5\\] \\[\\int_{Rx} f(x)dx=\\int_2^40.5 dx=0.5 x/_2^4=0.5*(4-2)=0.5*2=1\\] \\(P(2&lt;X&lt;3)=0.5\\) \\[P(2&lt;X&lt;3)=\\int_2^3 0.5dx=0.5*(3-2)=0.5\\] \\(P(3&lt;X&lt;4)=0.5\\) \\[P(3&lt;X&lt;4)=\\int_3^4 0.5dx=0.5*(4-3)=0.5\\] \\(P(X&lt;2.5)=0.25\\) \\[P(X&lt;2.5)=\\int_2^{2.5} 0.5dx=0.5*(2.5-2)=0.5*0.5=0.25\\] Donde; \\[\\begin{array}{ll} F(x) &amp; =\\frac{x-a}{b-a} \\\\ E[x] &amp; =\\frac{a+b}{2} \\\\ V[x] &amp; =\\frac{(b-a)^2}{12}\\\\ M_X(t) &amp; = \\frac{e^{bt}-e^{at}}{(b-a)*t} \\end{array} \\] Demostración, \\[F(t)=P(X&lt;t)=P(X\\leq t)=\\int_a^t \\frac{1}{b-a} dx=\\frac{1}{b-a}*x/_a^t=\\frac{t-a}{b-a}\\] Para una \\(x\\): \\[F(x)=\\frac{x-a}{b-a}\\] \\[P(X&lt;2.5)=F(2.5)=\\frac{2.5-2}{4-2}=\\frac{0.5}{2}=0.25\\] \\[E[X]=\\int_a^b x \\frac{1}{b-a} dx=\\frac{1}{b-a} \\frac{x^2}{2}/_a^b=\\frac{b^2-a^2}{2(b-a)}=\\frac{(b+a)(b-a)}{2(b-a)}=\\frac{a+b}{2}\\] Para la varianza, \\[V(X)=E[X^2]-E[X]^2\\] \\[E[X^2]=\\int_{Rx} x^2 f(x)dx=\\int_a^b x^2 \\frac{1}{b-a}dx=\\frac{1}{b-a} \\frac{x^3}{3}/_a^b=\\frac{b^3-a^3}{3(b-a)}=\\frac{(b-a)(b^2+ba+a^2)}{3(b-a)}=\\frac{b^2+ab+a^2}{3}\\] \\[V(X)=\\frac{b^2+ab+a^2}{3}-\\frac{(a+b)^2}{2^2}=\\frac{4b^2+4ab+4a^2-3a^2-6ab-3b^2 }{12}=\\frac{b^2-2ab+a^2}{12}=\\frac{(b-a)^2}{12}\\] Tarea, demostrar la función generatriz de momentos. Ejemplo, Un punto es escogido al azar en el segmento de recta \\([1,4]\\). Calcular: La probabilidad de que el punto escogido esté entre 2 y 3 la probabilidad de que sea igual a 2 (\\(P(X=2)=0\\)) la media (esperanza) y la varianza Solución, sea X una va, \\(X\\sim U(a=1,b=4)\\). \\(f(x)=\\frac{1}{b-a}=\\frac{1}{3}\\) \\[P(2&lt;X&lt;3)=F(3)-F(2)=\\int_2^3\\frac{1}{3}dx=\\frac{1}{3}\\] \\[P(X=2)=0\\] \\(E[X]=\\frac{a+b}{2}=5/2=2.5\\), \\(V(X)=\\frac{(b-a)^2}{12}=\\frac{(4-1)^2}{12}=9/12=3/4\\) (TAREA) La clase de un profesor esta programada para comenzar a las 10:00 am; pero él comienza su clase en un tiempo \\(X\\) que tiene distribución uniforme en el intervalo de 9:55 am. a 10:05 am. ¿Cuál es la probabilidad de que él comience su clase: hasta 2 minutos más temprano? hasta 2 minutos más tarde? Solución, X: El inicio de la clase, \\(X_1\\sim U (0,10)\\), \\(X_2\\sim U(-5,5)\\) hasta 2 minutos más temprano? A lo sumo 2 minutos más temprano? \\[P(-2&lt;X_2&lt;0)\\] \\[P(-5&lt;X_2&lt;2)\\] 5.2 Exponencial Sea \\(X\\) una v.a, se dice que \\(X\\sim exp(\\lambda)\\), con \\(\\lambda&gt;0\\) . Si su función de densidad es: \\[f(x)= \\lambda e^{-\\lambda x} \\hspace{0.5cm}; x&gt;0\\] Donde; \\[\\begin{array}{ll} F(x) &amp; = 1- e^{-\\lambda x} \\\\ E[x] &amp; =\\frac{1}{\\lambda}\\\\ V[x] &amp; =\\frac{1}{\\lambda^2}\\\\ M_X(t) &amp; = \\frac{\\lambda}{\\lambda-t} \\hspace{0.5cm}; t&lt;\\lambda \\end{array} \\] Demostrando algunas propiedades, \\[\\int_{Rx}f(x)dx=\\int_0^{\\infty}\\lambda*e^{-\\lambda x}dx=\\lambda \\int_0^{\\infty}e^{-\\lambda x}dx=\\lambda \\left(- \\frac{e^{-\\lambda x}}{\\lambda} \\right)/_0^{\\infty}=-e^{-\\infty}+e^0=-0+1=1\\] \\[M_X(t)=E[e^{tx}]=\\int_0^{\\infty} e^{tx}\\lambda e^{-\\lambda x}dx=\\lambda \\int_0^{\\infty} e^{-x(\\lambda-t)} dx=\\lambda \\left( -\\frac{e^{-x(\\lambda-t)}}{(\\lambda-t)} \\right)_0^{\\infty}=\\frac{\\lambda}{(\\lambda-t)}*(-e^{-\\infty (\\lambda-t)}+e^0)=\\frac{\\lambda}{\\lambda-t}\\] Esto se da, siempre y cuando \\(\\lambda-t&gt;0\\), \\(\\lambda&gt;t\\) A partir de la función generatriz de momentos, encontrar a \\(E[X]\\). \\[E[X]=M&#39;_X(t=0)=\\left(\\frac{\\lambda}{\\lambda-t}\\right)_{(t=0)}&#39;= \\frac{\\lambda}{(\\lambda-t)^2}=_{(t=0)} \\frac{1}{\\lambda}\\] \\[E[X]=\\int_0^\\infty x \\lambda e^{-\\lambda x }dx \\] \\[E[X^2]=\\int_0^\\infty x^2 \\lambda e^{-\\lambda x }dx \\] Tarea, demostrar la \\(V(X)\\) a partir de la función generatriz de momentos. 5.2.1 Ejercicios, (pg525, 2) Suponga que un mecanismo eléctrico tiene un tiempo de vida \\(X\\) (en unidades de 1000 horas) que es considerado como una v.a. continua con función de densidad exponencial (\\(\\lambda=1\\)). Suponga que el costo de fabricación de un item es 2 Bs. y el precio de venta es 5 Bs. El fabricante garantiza la total devolución si \\(x\\leq 0.9\\) ¿Cuál es la ganancia esperada por item?. Solución, \\(X\\sim exp(\\lambda=1)\\). \\[P(devolucion)=P(X\\leq 0.9)=F(0.9)=1-e^{-0.9}=0.5935\\] \\[P(\\sim devolucion)=1-P(X\\leq 0.9)=0.4065\\] Imaginemos las ganancias: \\[Ganancia=PrecioVenta-CostoProduccion=5-2=3\\] Dado que existe una garantía de devolución asociada al comportamiento del tiempo de vida del mecanismo electrónico y este es una variable aleatoria, entonces las ganancias también son aleatorias. \\[GananciaEsperada_{item}=5*Pr(\\sim devolucion)-2=5*0.4065-2=0.0325 Bs.\\] Se planea vender 3500 items de este mecanismo electrónico, ¿Cuál sera la ganancia esperada de este lote de 3500 items?. Resp. la ganancia esperada será de \\(3500*0.0325=113.75\\) (pg525, 1) La duración de una lampara se distribuye exponencial con parámetro \\(\\lambda=1/100\\) (horas). Determinar: La probabilidad de que se queme antes de las 1000 horas La probabilidad de que se queme después de la duración media ¿Cuál es la desviación estándar de la distribución? Solución, sea \\(X\\) la va, que denota la duración en horas. \\(X\\sim exp(\\lambda=1/100)\\). \\[f(x)=\\frac{1}{100}e^{-\\frac{1}{100}x}; \\text{ } x&gt;0\\] \\[F(x) =P(X&lt;x) = 1- e^{-\\frac{1}{100} x}\\] La probabilidad de que se queme antes de las 1000 horas \\[P(X&lt;1000)=F(1000)=1-e^{-1000/100}=1-e^{-10}=0.9999546\\] La probabilidad de que se queme después de la duración media. \\[E[X]=\\frac{1}{\\lambda}=\\frac{1}{\\frac{1}{100}}=100\\] \\[P(X&gt;E[X])=P(X&gt;100)=1-P(X\\leq 100)=1-F(100)=1-(1-e^{-100/100})=\\] \\[=1-1+e^{-1}=e^{-1}=0.3679\\] ¿Cuál es la desviación estándar de la distribución? \\(\\sqrt{V(X)}\\) \\[\\sqrt{V(X)}=\\sqrt{\\frac{1}{\\lambda^2}}=1/\\lambda=100\\] Supongamos que el número de kilómetros que un carro puede recorrer antes que su batería se consuma, está exponencialmente distribuida con un promedio de 15000 kilómetros. Si una persona desea hacer una excursión de 10000 kilómetros. ¿Cuál es la probabilidad de que la persona complete la excursión sin que tenga que cambiar de batería del carro?. Solución, sea \\(X\\) la duración de la batería en kilómetros. \\(X\\sim exp(\\lambda=1/15000)\\). \\(E[X]=15000=1/\\lambda\\), entonces, \\(\\lambda=1/15000\\). \\[P(X&gt;10000)=tarea\\] 5.3 Distribución Gamma Función Gamma (\\(\\Gamma\\)) \\[\\Gamma(\\alpha)=\\int_0^\\infty x^{\\alpha-1} e^{-x}dx\\] Esta función Gamma \\(\\Gamma(.)\\) es finita cuando \\(\\alpha&gt;0\\). Propiedades de la función Gamma \\(\\Gamma(1)=\\int_0^\\infty e^{-x}dx=1\\) Si tenemos \\(n=1,2,\\ldots\\). Así \\(\\Gamma(n)=(n-1)!\\) \\(\\Gamma(1/2)=\\sqrt{\\pi}\\) Ejemplos \\(\\Gamma(2)=(2-1)!=1!=1\\) \\(\\Gamma(3)=(3-1)!=2!=2\\) \\(\\Gamma(10)=(10-1)!=9!=362880\\) Se dice que la va \\(X\\) tiene una distribución gamma \\(X\\sim Gamma(\\alpha,\\beta)\\), con \\(\\alpha&gt;0\\), \\(\\beta&gt;0\\). Si su función de densidad esta dada por: \\[f(x)=\\frac{\\beta^\\alpha x^{\\alpha-1}}{\\Gamma(\\alpha)} e^{-\\beta x}\\] Para \\(x&gt;0\\). Nota, con \\(\\alpha=1\\) la función queda como: \\[f(x)=\\beta e^{-\\beta x}\\] Así \\(Gamma(\\alpha=1,\\beta)=exp(\\lambda=\\beta)\\) Recordar que para la exponencial, la variable aleatoria \\(X\\) era el tiempo de espera de Un suceso con tasa de espera \\(\\lambda\\), la distribución Gamma es una generalización donde \\(X\\) se puede entender como el tiempo de espera de varios \\(n\\) sucesos. En esta idea \\(\\beta\\) es similar a \\(\\lambda\\) con el objetivo de modelar la tasa de espera, \\(\\alpha\\) modela el número de sucesos (n). Veamos si es una función de probabilidad, \\[\\int_{0}^\\infty \\frac{\\beta^\\alpha x^{\\alpha-1}}{\\Gamma(\\alpha)} e^{-\\beta x} dx=\\frac{\\beta^\\alpha }{\\Gamma(\\alpha)} \\int_{0}^\\infty x^{\\alpha-1} e^{-\\beta x} dx= \\] Aplicando un cambio de variable \\(y=\\beta x\\), \\(\\frac{dy}{dx}=\\beta\\), \\(x=y/\\beta\\) \\[=\\frac{\\beta^\\alpha }{\\Gamma(\\alpha)} \\int_0^\\infty \\left(\\frac{y}{\\beta}\\right)^{\\alpha-1} e^{^-y}\\frac{dy}{\\beta}=\\frac{\\beta^\\alpha }{\\Gamma(\\alpha) \\beta^\\alpha} \\int_0^\\infty y^{\\alpha-1}e^{-y}dy = \\frac{\\beta^\\alpha \\Gamma(\\alpha)}{\\Gamma(\\alpha) \\beta^\\alpha}=1\\] Propiedades, si \\(X\\sim Gamma(\\alpha, \\beta)\\), entonces: \\(E[X]=\\frac{\\alpha}{\\beta}\\) \\(V(X)=\\frac{\\alpha}{\\beta^2}\\) \\(M_X(t)=\\left(\\frac{\\beta}{\\beta-t}\\right)^\\alpha\\), para \\(t&lt;\\beta\\) Si las variables aleatorias \\(X_1, X_2, \\ldots, X_k\\) son independientes y si cada \\(X_i\\sim exp(\\lambda)\\), entonces, la suma \\(X_1+X_2+_\\ldots+X_k \\sim Gamma(\\alpha=k,\\beta=\\lambda)\\). Ejercicio, Supongamos que la vida en años de hombres residentes en un país dado tiene distribución gamma con parámetros \\(\\alpha=2\\) y \\(\\beta=0.02\\). ¿Qué proporción de hombres residentes de dicho país vivirán más de 50 años? Solución, \\(X\\sim Gamma(\\alpha=2,\\beta=0.02)\\), se pide \\(P(X&gt;50)\\), la función de probabilidad es: \\[f(x)=\\frac{0.02^2 x}{\\Gamma(2)} e^{-0.02 x}=0.0004 x e^{-0.02x} \\] \\[P(X&gt;50)=\\int_{50}^\\infty 0.0004 x e^{-0.02x} dx=0.7358 \\] \\[P(X&gt;50)=1-P(X\\leq 50)=1-\\int_{0}^{50} 0.0004 x e^{-0.02x} dx= 1-0.2642=0.7358 \\] Encontrar el valor esperado y la desviación estandar \\[E[X]=\\frac{2}{0.02}=100\\] \\[V(X)=\\frac{2}{0.0004}=5000\\] Asi, \\(\\sqrt{V(X)}=70.71\\) 5.4 Normal Sea \\(X\\) una v.a, se dice que \\(X\\sim N(\\mu,\\sigma^2)\\), \\(\\sigma&gt;0\\), si su función de densidad es: \\[f(x)=\\frac{1}{\\sqrt{2\\pi} * \\sigma} e^{-\\frac{1}{2} \\left( \\frac{x-\\mu}{ \\sigma}\\right)^2 } \\hspace{0.5cm}; -\\infty \\leq x \\leq \\infty\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =\\mu\\\\ V[x] &amp; =\\sigma^2\\\\ M_X(t) &amp; = e^{\\mu t +\\frac{1}{2} \\sigma^2 t^2} \\end{array} \\] ## [1] 49.354 ## [1] 50.3 ## [1] 67 26 46 48 27 30 31 34 22 27 ## [1] 35.8 Comentarios, El 68.2% de la probabilidad se concentra en: \\[P(\\mu-\\sigma&lt;X&lt;\\mu+\\sigma)=0.682\\] \\[P(\\mu-2\\sigma&lt;X&lt;\\mu+2\\sigma)=0.954\\] \\[P(\\mu-3\\sigma&lt;X&lt;\\mu+3\\sigma)=0.997\\] Nota: La distribución normal es una de las más importantes en la estadística, sin embargo, la forma de la distribución es compleja al momento de querer obtener las probabilidad de forma formal, esto debido a problemas de integración. Ejemplo, sea \\(X\\sim N(\\mu=0,\\sigma=1)\\), encontrar, \\(P(X&gt;0.5)\\). \\[f(x)=\\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} x^2 } \\hspace{0.5cm}; -\\infty \\leq x \\leq \\infty\\] \\[P(X&gt;0.5)=\\int_{0.5}^\\infty \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} x^2 } dx=\\frac{1}{\\sqrt{2\\pi}} \\int_{0.5}^\\infty e^{-\\frac{1}{2} x^2 } dx \\] 5.4.1 Estandarización de las variables (transformación) La estandarización de una variable aleatoria \\(X\\) parte por una transformación que incluye su esperanzan y su varianza, sea \\(z\\) una variable aleatoria, resultante de aplicar la estadanrización a la variable \\(x\\), \\(z\\) esta definida como: \\[z_i=\\frac{x_i-E[X]}{\\sqrt{V(x)}}\\] \\[z_i=\\frac{x_i-\\bar{x}}{\\sigma_x}\\] Propiedades de \\(z\\): \\(E[Z]=0\\) \\(V(Z)=1\\) 5.5 Normal Estándar Sea \\(x \\sim N(\\mu, \\sigma^2)\\), entonces \\(z=\\frac{x-\\mu}{\\sigma}\\) es una v.a, y se dice que \\(Z\\sim N(0,1)\\) es una normal estándar, si su función de densidad es: \\[f(z)=\\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} z^2 } \\hspace{0.5cm}; -\\infty \\leq z \\leq \\infty\\] Donde; \\[\\begin{array}{ll} E[z] &amp; =0\\\\ V[z] &amp; =1\\\\ M_Z(t) &amp; = e^{\\frac{1}{2} t^2} \\end{array} \\] ### Ejercicios \\[P(0&lt;Z&lt;1)=0.3413\\] \\[P(Z\\leq t)=P(Z&lt;t)=F(t)=\\phi(t)\\] ### Propiedades \\(P(a&lt;Z&lt;b)=F(b)-F(a)=\\phi(b)-\\phi(a)\\), \\(a&lt;b\\) \\(P(Z&gt;a)=1-P(Z\\le a)=1-F(a)=1-\\phi(a)\\) \\(P(Z&lt;b)=F(b)=\\phi(b)\\) 5.5.1 Otros ejemplos Sea \\(Z\\sim N(0,1)\\), calcular: \\(P(Z&gt;0)=0.5\\) \\(P(Z&gt;3)=1-\\phi(3)=1-0.9987=0.0013\\) \\(P(Z&lt;2)=\\phi(2)=0.9772\\) \\(P(Z&lt;-2)=\\phi(-2)=0.028\\) \\(P(-1.5&lt;Z&lt;0)=\\phi(0)-\\phi(-1.5)=0.5-0.0668=0.4332\\) Si \\(Z\\) en una va. \\(Z\\sim N(0,1)\\), calcular: \\(P(0&lt;Z&lt;1.44)=F(1.44)-F(0)=\\phi(1.44)-\\phi(0)=0.9251-0.5=0.4251\\) \\(P(-0.85&lt;Z&lt;0)=\\phi(0)-\\phi(-0.85)=0.5-0.1977=0.3023\\) \\(P(-1.48&lt;Z&lt;2.05)=\\phi(2.05)-\\phi(-1.48)=0.9798-0.0694=0.9104\\) \\(P(Z&lt;1.08)=F(1.08)=\\phi(1.08)=0.8599\\) \\(P(Z&gt;-0.66)=1-P(Z\\leq -0.66)=1-\\phi(-0.66)=1-0.2566=0.7434\\) Tarea: Revisar los ejercicios a partir de la página 511 5.5.2 Otro propiedad \\[P(-1&lt;Z&lt;1)=0.682\\] \\[P(-2&lt;Z&lt;2)=0.954\\] \\[P(-3&lt;Z&lt;3)=0.997\\] 2. Si \\(X\\sim N(\\mu=54,\\sigma=10)\\), calcular: \\(P(X&gt;54)=P(\\frac{X-\\mu}{\\sigma} &gt; \\frac{54-54}{10})=P(Z&gt;0)=1-\\phi(0)=1-0.5=0.5\\) \\(P(X&gt;60)=P(\\frac{X-\\mu}{\\sigma}&gt;\\frac{60-54}{10})=P(Z&gt;0.6)=1-\\phi(0.6)=1-0.7257=0.2743\\) \\(P(X&lt;45)=P(Z&lt;\\frac{45-54}{10})=P(Z&lt;-0.9)=\\phi(-0.9)=0.1841\\) \\(P(47&lt;X&lt;62)=P(\\frac{47-54}{10}&lt;\\frac{X-\\mu}{\\sigma}&lt;\\frac{62-54}{10})=P(-0.7&lt;Z&lt;0.8)\\) \\(P(-0.7&lt;Z&lt;0.8)=\\phi(0.8)-\\phi(-0.7)=0.7881-0.2420=0.5461\\) Si \\(X\\sim N(\\mu=1,\\sigma^2=4)\\). Calcular: \\(P(X\\leq 3)=P(\\frac{X-\\mu}{\\sigma} \\leq \\frac{3-1}{2})=P(Z\\leq 1)=F(1)=\\phi(1)=0.8413\\) \\(P(X&gt;1.5)=P(\\frac{X-\\mu}{\\sigma}&gt;\\frac{1.5-1}{2})=P(Z&gt;0.25)=1-P(Z\\leq 0.25)\\) \\(=1-P(Z\\leq0.25)=1-\\phi(0.25)=1-0.5987=0.4013\\) \\(P(2&lt;X&lt;5)=P(\\frac{2-1}{2}&lt;Z&lt;\\frac{5-1}{2})=P(0.5&lt;Z&lt;2)=\\phi(2)-\\phi(0.5)=0.9772-0.6915=0.2857\\) \\(P(-1&lt;X&lt;0.5)=P(\\frac{-1-1}{2}&lt;Z&lt; \\frac{ 0.5-1}{2})=P(-1&lt;Z&lt;-0.25)\\) \\(=\\phi(-0.25)-\\phi(-1)=0.4013-0.1587=0.2426\\) Los pesos de 600 estudiantes están normalmente distribuidos con media 65.3 Kg y desviación estándar de 5.51 Kg. Encuentre el número de alumnos que pesan: entre 60 y 70 kg más de 63.2 entre 55 y 60 Kg Solución, \\(X\\sim N(\\mu=65.3,\\sigma=5.51)\\) \\(P(60&lt;X&lt;70)=P(-0.962&lt;Z&lt;0.853)=\\phi(0.85)-\\phi(-0.96)=0.8023-0.1685=0.6338\\) Dado que hay 600 estudiantes de estos la probabilidad que pesen entre 60 y 70 es de 0.6338 que representa a \\(600*0.6338=380\\) estudiantes. \\(P(X&gt;63.2)=P(Z&gt;-0.38)=1-P(Z\\leq -0.38)=1-\\phi(-0.38)=1-0.3520=0.648\\) En personas esto equivale a \\(600*0.648=389\\) \\(P(55&lt;X&lt;60)=P(-1.87&lt;Z&lt;-0.96)=\\phi(-0.96)-\\phi(-1.87)=0.1685-0.0307=0.1378\\) En personas esto equivale a \\(600*0.1378=83\\) 5.5.3 Propiedades sobre la normal Teorema de la suma de normales independientes Sea \\(X_1, X_2, \\ldots ,X_k\\) va independientes y que cada una de ellas \\(X_i\\sim N(\\mu_i,\\sigma^2_i)\\). Entonces la suma de estas \\(k\\) variables también se distribuye normal. \\[X_1+X_2+\\ldots+X_k=Y\\sim N \\left(\\mu_y=\\mu_1+\\mu_2+\\ldots+\\mu_k,\\sigma^2_y=\\sum_{i=1}^k{\\sigma_i^2} \\right) \\] &gt; Teorema del limite central Si \\(X_1, X_2, \\ldots,X_n,\\ldots\\) es una sucesión de va independientes e idénticamente distribuidas (iid). Cada una con media \\(E[X_i]=\\mu\\) y varianza \\(V(X_i)=\\sigma^2\\) (finita). Entonces para cualquier número fijo \\(x\\) se tiene: \\[lim_{(n\\rightarrow +\\infty)} P\\left(\\frac{\\bar{X_n}-\\mu}{\\sigma/\\sqrt{n}}\\leq x \\right)=P(Z_n&lt;x)=\\phi(x)\\] \\[Z_n\\sim N(0,1)\\] Donde, \\[\\bar{X}_n=\\frac{\\sum_{i=1}^n X_i}{n}\\] Ejemplo (Pg 518, ej 41.). Un fabricante de papel de embalar requiere resistencia mínima de 20 kilos por centímetro cuadrado. Para verificar la calidad del papel, cada hora se selecciona una muestra de 10 piezas de papel y se mide la resistencia de cada una de ellas. Se identifica que el promedio de la resistencia es de 21 kilos por centímetro cuadrado y la desviación estándar es de 2 kilos por cm2. ¿Cuál es la distribución aproximadamente de la media muestral de las \\(n=10\\) piezas de papel. ¿Cuál es la probabilidad de que para una muestra aleatoria de \\(n=10\\) piezas de papel sea \\(\\bar{X}&lt;20\\)? Solución, Sea \\(X_i\\): Resistencia del papel \\(i\\) una va para \\(i=1, 2, \\ldots\\). \\(X_i \\sim .(\\mu=21,\\sigma=2)\\) La distribución de la media muestral se la puede aproximar mediante la distribución normal por el teorema del limite central. \\[\\bar{X}_{10}\\sim N(\\mu=21,\\sigma=2/\\sqrt{10})=N(\\mu=21,\\sigma=0.63)\\] b) \\(P(\\bar{X}&lt;20)=P(Z_{10}&lt;\\frac{20-21}{0.63})=P(Z&lt;-1.58)=\\phi(-1.58)=0.0571\\) "]
]
