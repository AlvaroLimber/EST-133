[
["index.html", "Estadística I EST-133 Prefacio Audiencia Estructura del libro Software y acuerdos", " Estadística I EST-133 Alvaro Chirino Gutierrez 2020-07-09 Prefacio Este documento de Alvaro Chirino esta bajo la licencia de Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Audiencia El libro fue diseñado originalmente para los estudiantes de la materia de Estadística I, de la carrera de Informática de la Universidad Mayor de San Andres. Estructura del libro El libro inluye 5 capitulos, estos son: Estadística Descriptiva Probabilidades Variable Aleatoria Distribuciones discretas Distribuciones continuas Software y acuerdos El sofware de apoyo que se emplea es R, para la instalación y otros tutoriales se recomienda ver acá sessionInfo() ## R version 4.0.2 (2020-06-22) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 18363) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Spanish_Bolivia.1252 ## [2] LC_CTYPE=Spanish_Bolivia.1252 ## [3] LC_MONETARY=Spanish_Bolivia.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=Spanish_Bolivia.1252 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets ## [6] methods base ## ## loaded via a namespace (and not attached): ## [1] Rcpp_1.0.4.6 bookdown_0.18 packrat_0.5.0 ## [4] digest_0.6.25 magrittr_1.5 evaluate_0.14 ## [7] rlang_0.4.6 stringi_1.4.6 rstudioapi_0.11 ## [10] rmarkdown_2.3 tools_4.0.2 stringr_1.4.0 ## [13] xfun_0.13 yaml_2.2.1 rsconnect_0.8.16 ## [16] compiler_4.0.2 htmltools_0.4.0 knitr_1.28 "],
["tema-1-estadística-descriptiva.html", "1 Tema 1: Estadística Descriptiva 1.1 Introducción 1.2 Tipos de datos 1.3 Visualización 1.4 Medidas de tendencia central 1.5 Medidas de dispersión 1.6 Medidas de forma", " 1 Tema 1: Estadística Descriptiva 1.1 Introducción El arte de contar una historia con datos \\(X=\\{2,3,4,5,6,71,3,5,7 \\}\\) 1.2 Tipos de datos Cualitativos (cualidades). Nominales, ordinales Cuantitativos (cantidad) 1.3 Visualización 1.4 Medidas de tendencia central x&lt;-runif(100,40,90) sum(x)/100 ## [1] 64.5668 x[order(x)] ## [1] 40.38771 40.73989 41.25613 41.52584 41.66411 ## [6] 42.64533 42.91709 43.01271 43.13811 43.51144 ## [11] 43.78633 45.01312 45.02532 45.44013 45.69445 ## [16] 46.61364 46.73244 46.77350 46.80500 47.73621 ## [21] 47.88872 48.41216 48.52924 49.59969 50.79467 ## [26] 51.82060 52.62721 52.87038 52.98397 53.04562 ## [31] 53.29447 54.33310 54.34499 54.58181 56.92970 ## [36] 58.64711 58.81911 58.82950 60.38963 60.62705 ## [41] 60.76242 60.82594 61.27764 61.69565 62.22156 ## [46] 62.80714 63.08024 63.81858 64.58090 65.21012 ## [51] 65.94146 67.17304 67.59380 68.31008 68.50043 ## [56] 69.66069 69.73999 70.07384 70.08371 70.15393 ## [61] 70.30029 70.68319 71.36460 71.40809 71.74246 ## [66] 72.25131 72.47547 72.67341 72.79054 76.07060 ## [71] 76.17471 76.20486 76.24072 76.79994 76.90084 ## [76] 77.11101 77.84725 78.71458 79.88494 80.01840 ## [81] 80.12589 80.16450 80.26751 80.31486 80.38473 ## [86] 80.82880 81.75155 82.45180 82.64392 84.26996 ## [91] 84.49765 84.64044 84.92484 85.78361 87.42851 ## [96] 88.19187 88.43971 88.67263 89.94628 89.99536 median(x) ## [1] 65.57579 hist(x) 1.5 Medidas de dispersión y&lt;-rnorm(100,60,5) hist(y) sd(x) ## [1] 14.79465 sd(y) ## [1] 5.341436 1.6 Medidas de forma Asimetría plot(density(y)) plot(density(c(0,y))) plot(density(c(y,200))) plot(density(rnorm(100000))) Kurtosis par(mfrow=c(1,3)) plot(density(rnorm(100000,sd=0.5)),xlim=c(-5,5),ylim=c(0,0.8)) plot(density(rnorm(100000)),xlim=c(-5,5),ylim=c(0,0.8)) plot(density(runif(100000))) "],
["tema-2-probabilidades.html", "2 Tema 2: Probabilidades 2.1 Introducción 2.2 Experimento Aleatorio 2.3 Espacio Muestral 2.4 Eventos (E) 2.5 Probabilidad 2.6 Probabilidad Condicional 2.7 Teorema de la Probabilidad Total 2.8 Teorema de Bayes 2.9 Ejercicios.", " 2 Tema 2: Probabilidades 2.1 Introducción Sumerios y Asirios utilizaban un hueso extraído del talón de animales como ovejas, ciervos o caballos, denominado astrágalo o talus, que tallaban para que pudieran caer en cuatro posiciones distintas, por lo que son considerados como los precursores de los dados. Por su parte, los juegos con dados se practicaron ininterrumpidamente desde los tiempos del Imperio Romano hasta el Renacimiento, aunque no se conoce apenas las reglas con las que jugaban. Uno de estos juegos, denominado “hazard”, palabra que en inglés y francés significa riesgo o peligro, fue introducido en Europa con la Tercera Cruzada. Las raíces etimológicas del término provienen de la palabra árabe “al-azar”, que significa “dado”. Posteriormente, en el “Purgatorio” de Dante el término aparece ya como “azar”. La historia de la probabilidad comienza en el siglo XVII cuando Pierre Fermat y Blaise Pascal tratan de resolver algunos problemas relacionados con los juegos de azar. Aunque algunos marcan sus inicios cuando Cardano (jugador donde los haya) escribió sobre 1520 El Libro de los Juegos de Azar (aunque no fué publicado hasta más de un siglo después, sobre 1660) no es hasta dicha fecha que comienza a elaborarse una teoría aceptable sobre los juegos. Pierre Fermat Blaise Pascal Durante el siglo XVIII, debido muy particularmente a la popularidad de los juegos de azar, el cálculo de probabilidades tuvo un notable desarrollo sobre la base de la anterior definición de probabilidad. Destacan en 1713 el teorema de Bernoulli y la distribución binomial, y en 1738 el primer caso particular estudiado por De Moivre, del teorema central del límite. En 1809 Gauss inició el estudio de la teoría de errores y en 1810 Laplace, que había considerado anteriormente el tema, completó el desarrollo de esta teoría. En 1812 Pierre Laplace publicó Théorie analytique des probabilités en el que expone un análisis matemático sobre los juegos de azar. Daniel Bernoulli Gauss Pierre Laplace 2.2 Experimento Aleatorio Definición de experimento: Proceso mediante el cual se obtiene un resultdo de una observación. Definición de experimento aleatorio: Cuando los resultados de la observacion no s epuede predecir con exactitud antes de realizar el experimento. 2.2.1 Ejemplos Lanzar una moneda Lanzar un dado, lanzar un tetraedro Una competencia de 6 caballos, quien es el caballo ganador Un partido de futbol entre el equipo A y el equipo B El clima de mañana El resultado de una votación con 3 candidatos El tiempo de entrega de una pizza El tiempo de atención en la caja recaudadora de la universidad en un dia particular 2.3 Espacio Muestral Definición de espacio muestral: Es la colección (conjunto) de todos los resultados posibles de un experimento aleatorio. Denotado por… \\[\\Omega\\] 2.3.1 Ejemplos El espacio muestra de los anteriores ejemplos \\(\\Omega=\\{Cara,Cruz\\}\\) \\(\\Omega=\\{1,2,3,4,5,6\\}\\), para el tetraedro \\(\\Omega=\\{1,2,3,4\\}\\) Sean los caballos a,b,c,d,e y f, \\(\\Omega=\\{a,b,c,d,e,f\\}\\) \\(\\Omega=\\{ganaA, ganaB, empate\\}\\) \\(\\Omega=\\{soleado, lluvia,nublado \\}\\) Sean los candidatos x, y, z \\(\\Omega=\\{x,y,z\\}\\) Sea \\(x\\) el tiempo, \\(\\Omega=\\{x &gt; 0\\}\\) 7a. Sea \\(x\\) el tiempo en horas, \\(\\Omega=\\{ 0&lt;x&lt;24 \\}\\) Sea \\(x\\) el tiempo en horas, \\(\\Omega=\\{ 0&lt;x&lt;8 \\}\\) Nota: el tamaño de \\(\\Omega\\) lo denotaremos por: \\[\\#\\Omega\\] El espacio muestral de un experimento, puede ser: Finito numerables Infinito no numerables Infinito numerables + Los dias hasta que suceda un terremoto en la ciudad \\(x\\) 2.3.2 Otros ejemplos Exp: Lanzar dos dados y observar las caras superiores de ambos dados, \\(\\Omega= \\{(1,1),(1,2),(1,3), (1,4),...,(6,6) \\}\\), \\(\\Omega= \\{(i,j); i=1:6,j=1:6 \\}\\), \\(\\#\\Omega=36\\) El experimento: determinar el sexo de un niño/a recién nacido. \\(\\Omega=\\{Femenino, Masculino\\}\\) En una competencia de caballos, con 7 caballos, el experimento: ordenar todas las posibles llegadas de estos 7 caballos. (a,b,c,d,e,f,g), \\(\\#\\Omega=7!=5040\\) \\[\\Omega=\\{\\text{Todas las 7! permutaciones de } (a,b,c,d,e,f,g) \\}\\] El experimento es medir el tiempo de vida de un componente electrónico de un aparato (horas). \\[\\Omega=\\{x: x \\geq 0 \\}\\] plot(1:10,rep(0,10),type=&quot;b&quot;) El experimento es: Seleccionar 3 personas de un grupo de 50 personas, describir el espacio muestral y el tamaño de este. + \\(\\# \\Omega= C_3^{50}=19600\\) + \\(\\Omega=\\{(i,j,k); i,j,k \\in 1:50, i\\neq j \\neq k \\}\\) 2.3.3 Ejercicios Cuatro profesores se distribuyen al azar en 4 oficinas numeradas del 1 al 4. Si los profesores pueden estar en la misma oficina. Describir \\(\\Omega\\) \\[\\#\\Omega=4!+4+4\\binom{4}{2}+\\binom{4}{2}\\binom{4}{3}+\\binom{4}{2}\\binom{4}{2}\\] Se lanza una moneda y un dado simultaneamente. Describir \\(\\Omega\\), \\(\\#\\Omega=12\\) \\[\\Omega=\\{(i,j); i=\\{cruz,cara\\},j=1:6 \\}\\] Cinco trabajadores, de los cuales 3 pertenecen a un grupo minoritario se asignan a 5 empleos netamente distintos. Describir \\(\\Omega\\), Ignorar al grupo minoritario, \\(\\# \\Omega=5!\\), sean los trabajdores a,b,c,d,e,f \\(\\Omega=\\{5!; a,b,c,d,e\\}\\) Solo con los 3 trabajadores minoritarios: Sea los trabajadores minoritarios \\(a,b,c\\) y numerámos los empleos de \\(1:5\\) \\(\\Omega=\\{(a=i,b=j,c=k); i,j,k=1:5, i \\neq j \\neq k\\}\\), \\(\\# \\Omega= CR_{5,3}=\\binom{7}{3}=35\\) Ejercicio: Dos personas A y B se distribuyen al azar en tres oficinas numeradas 1,2 y 3 .Si las dos personas pueden estar en la misma oficina ,defina un espacio muestral adecuado \\[\\Omega=\\{(1A,1B),(2A,2B),(3A,3B),(1A,2B),(1A,3B),(2A,3B),(1B,2A),(1B,3A),(2B,3A) \\}\\] 2.4 Eventos (E) \\[E \\subset \\Omega\\] 2.4.1 Ejemplos Sea el evento \\(E\\) nace una niña, \\(E=\\{Femenino \\}\\) Se lanza un dado, sea el evento \\(A\\) sale par \\[A=\\{2,4,6 \\}\\] 3, En el ejemplo de los caballos. Sea el evento \\(E\\) el caballo \\(c\\) gana la competencia. \\[\\# E = 1 * 6*5*4*3*2*1=6!= 720\\] \\[E = \\{(c,a,b,d,e,f,g),(c,a,b,d,e,g,f),(c,f,b,d,e,a,g),\\ldots \\}\\] \\[E = \\{ \\text{Son las permutaciones de 6! de tal forma que c es primero: } (a,b,d,e,f,g) \\}\\] Se lanza dos dados y se suman ambas caras. Defina los eventos: \\[\\Omega=\\{2,3,4,5,6,7,8,9,10,11,12 \\}\\] la suma es par, \\(A=\\{2,4,6,8,10,12 \\}\\) la suma es múltiplo de 7 \\(B=\\{7\\}\\) la suma es 1, \\(C=\\{\\emptyset\\}\\) En el ejemplo del componente electrónico, sea el evento \\(E\\) el componente dura al menos 5 horas. \\[E=\\{x: x\\geq 5 \\}\\] En el ejemplo del componente electrónico, sea el evento \\(E\\) el componente dura a lo sumo 5 horas. \\[E=\\{x: x\\leq 5 \\}\\] 2.4.2 Operaciones con los eventos Sean \\(A\\), \\(B\\) y \\(C\\) eventos. Eventos simples: son eventos que contienen un solo elemento, tienen correspondencia con los resultados del espacio muestral. Sea \\(w\\) un evento simple de un \\(\\Omega\\) numerable Evento vacio \\(\\emptyset\\) El complemento de un evento \\[A^c=\\{ w \\in \\Omega \\text{ pero no pertenecen a } A\\}\\] La unión de eventos \\[A \\cup B = \\{w \\in \\Omega: w \\in A \\text{ ó } w\\in B \\}\\] La intersección de eventos \\[A \\cap B= \\{w \\in \\Omega: w \\in A \\text{ y } w \\in B \\}\\] Dos eventos son mutuamente excluyentes si: \\[A \\cap B = \\emptyset\\] Ejemplo: En el lanzamiento de 2 dados y la suma de sus resultados, sean los eventos \\(A:\\) La suma es Par, \\(B:\\) La suma es impar \\(C:\\) La suma es multiplo de 7 \\(D:\\) La suma es mayor a 5 Describir los eventos y luego encontrar \\(A \\cup C=\\{2,4,6,7,8,10,12 \\}\\) \\(B \\cap D=\\{7,9,11 \\}\\) \\(C \\cup D^c=\\{2,3,4,5,7\\}\\) $A (BC )=A B = $ \\(A \\cup (B\\cap C)=A\\cup C=\\{2,4,6,7,8,10,12 \\}\\) Los eventos \\(A=\\{2,4,6,8,10,12\\}\\) \\(B=\\{3,5,7,9,11 \\}\\) \\(C=\\{7 \\}\\) \\(D=\\{6,7,8,9,10,11,12\\}\\) \\(D^C=\\{2,3,4,5\\}\\) \\(C \\subset B\\), entonces \\(C\\cup B=B\\), \\(C \\cap B=C\\) 2.4.3 Algunas propiedades sobre las operaciones en eventos Sean \\(A\\), \\(B\\), \\(C\\) y \\(D\\) eventos, \\(A \\cup B= B \\cup A\\), \\(A \\cap B= B \\cap A\\) Conmutativa $(A B) C= A (B C) $, \\((A \\cap B) \\cap C= A \\cap (B \\cap C)\\) Asociativa \\(A \\cup (B \\cap C)= (A \\cup B) \\cap (A \\cup C)\\) Distributiva $A (B C)=(AB) (AC) $ Distributiva \\((A \\cup B)^c= A^c \\cap B^c\\) \\((A \\cap B)^c= A^c \\cup B^c\\) Ley de Morgan, sea \\(E_1, E_2, E_3, \\ldots, E_n\\), \\(n\\) eventos de algun experimento aleatorio \\[ (\\cup_{i=1}^{n}\\{E_i\\})^c = \\cap_{i=1}^{n}\\{E_i ^c\\}\\] \\[ (\\cap_{i=1}^{n}\\{E_i\\})^c = \\cup_{i=1}^{n}\\{E_i ^c\\}\\] \\((A^c)^c=A\\) 2.4.4 Algebra de Eventos Definición: Sea \\(A\\) un evento, Sea \\(\\Sigma\\) una clase de subconjuntos de \\(\\Omega\\) \\[ \\Sigma=\\{A \\in \\Omega \\} \\] Esta es un algebra de eventos si: \\(\\Omega \\in \\Sigma\\) Si \\(A\\in \\Sigma\\Rightarrow A^C \\in \\Sigma\\) Si \\(A,B \\in \\Sigma \\Rightarrow A \\cup B \\in \\Sigma\\) Ejemplo: El experimento es lanzar un dado y observar el resultado de la cara \\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\(\\# \\Omega=6\\), \\(\\Omega \\cup \\emptyset=\\Omega\\) \\[\\Sigma=\\{\\Omega,\\emptyset \\}\\] &gt; Nota: El algebra de eventos no es único Definición: Se dice que \\(\\Sigma\\) es un \\(\\sigma-algebra\\) \\(\\Omega \\in \\Sigma\\) Si \\(A\\in \\Sigma\\Rightarrow A^C \\in \\Sigma\\) Si \\(A_i \\in \\Sigma\\) para \\(i=1,2, \\ldots\\) \\(\\Rightarrow \\cup_{i=1}^\\infty A_i \\in \\Sigma\\) Ejemplo: El experimento es lanzar un dado y observar el resultado de la cara \\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\(\\# \\Omega=6\\), \\(\\Omega \\cup \\emptyset=\\Omega\\) \\[\\Sigma=\\{\\Omega,\\emptyset \\}\\] \\[\\Sigma=\\{\\Omega,\\emptyset,1,(2,3,4,5,6) \\}\\] \\[\\Sigma=\\{\\Omega,\\emptyset,1,2,3,4,5,6,(2,3,4,5,6),(1,3,4,5,6),(1,2,4,5,6),(1,2,3,5,6),(1,2,3,4,6),(1,2,3,4,5),(1,2),(1,3),...,(1,2,3),(1,2,4),...(1,2,3,4),(1,2,3,5),...\\}\\] \\[\\#\\Sigma=2^{\\# \\Omega}\\] \\[\\#\\Sigma=2^6=64\\] Ejemplo al lanzar una moneda dos veces y observar los resultados \\(\\Omega=\\{CC,SC,CS,SS\\}\\) si armamos un \\(\\sigma-algebra\\) donde incluyamos todos los eventos simples, entonces, \\(\\#\\Sigma=2^4=16\\). \\[\\Sigma=\\{\\Omega,\\emptyset,CC,SC,CS,SS,(CC,SC),(CC,CS),(CC,SS),(SC,CS),(SC,SS),(CS,SS),(CC,SC,CS),(CC,SC,SS),(CC,CS,SS),(SC,CS,SS)\\}\\] 2.5 Probabilidad Medida de incertidumbre Probabilidad teórica: los casos posibles sobre los casos totales \\[P(A)= \\frac{\\text{Casos posibles}}{\\text{Casos totales}}=\\frac{\\#A}{\\# \\Omega}\\] Ejemplo: El lanzamiento de un dado, \\(\\Omega=\\{1,2,3,4,5,6\\}\\), si el evento es \\(A=6\\), \\(B=PAR\\) \\(P(A)=\\frac{1}{6}\\), \\(P(B)=\\frac{3}{6}=1/2\\) Probabilidad frecuentista: \\[P(A)=lim_{n \\rightarrow \\infty} \\frac{n(A)}{n} =lim_{n \\rightarrow \\infty} \\frac{\\# A_n}{n}\\] #0=cara, 1=escudo set.seed(999) aux&lt;-rbinom(1000,1,0.5) aux ## [1] 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 ## [25] 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 ## [49] 0 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0 0 ## [73] 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 0 ## [97] 1 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 ## [121] 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 ## [145] 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 ## [169] 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 ## [193] 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 ## [217] 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 ## [241] 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 1 ## [265] 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 ## [289] 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 ## [313] 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 ## [337] 0 1 0 1 0 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 ## [361] 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 ## [385] 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 ## [409] 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 ## [433] 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 ## [457] 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 ## [481] 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 ## [505] 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 ## [529] 0 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 ## [553] 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 ## [577] 0 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 1 ## [601] 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 0 ## [625] 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 ## [649] 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 ## [673] 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 ## [697] 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 ## [721] 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 ## [745] 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 ## [769] 1 1 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 ## [793] 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 ## [817] 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 ## [841] 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 ## [865] 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 ## [889] 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 ## [913] 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 ## [937] 1 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 1 ## [961] 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 ## [985] 0 1 0 1 1 0 0 0 1 1 1 0 1 0 1 1 sum(aux) ## [1] 496 \\(P(escudo)=\\frac{496}{1000}=0.496\\) Prabibilidad subjetiva (experiencia) (apriori) \\[P(escudo)=1/3\\] \\[P(llueva_{hoy})=0.99\\] 2.5.1 Probabilidad de un evento Definición: Una medida de probabilidad \\(P\\) es una función, tal que: \\[ P:\\begin{array} &amp;&amp; \\Sigma &amp; \\rightarrow &amp; [0,1]\\\\ &amp; \\downarrow &amp; &amp; \\downarrow \\\\ &amp; A &amp; \\rightarrow &amp; P(A) \\end{array} \\] 2.5.2 Axiomas basicos de la probabilidad \\(P(A) \\in [0,1]\\), \\(0 \\leq P(A) \\leq 1\\), Para todo \\(A\\in \\Sigma\\), \\(A\\in\\Omega\\) \\(P(\\Omega)=1\\) Axioma aditividad finita, Si \\(A_1,A_2, \\ldots,A_n \\in \\Sigma\\), Estos son eventos disjuntos 2 a 2 (mutuamente excluyentes). \\(A_i \\cap A_j=\\emptyset\\) para todo \\(i\\neq j\\) \\[P(\\cup_{i=1}^n{A_i})=\\sum_{i=1}^n{P(A_i)}\\] Observación: Si \\(A \\cap B=\\emptyset\\) entonces, \\(P(A\\cup B)=P(A)+P(B)\\) 2.5.3 Propiedades \\(P(\\emptyset)=0\\) Demostracion: sea \\(A\\) un evento, \\(A\\cap \\emptyset=\\emptyset\\) \\(A=A\\cup \\emptyset\\) \\(P(A)=P(A\\cup \\emptyset)=P(A)+P(\\emptyset)\\) \\(P(A)=P(A)+P(\\emptyset)\\) \\(P(\\emptyset)=0\\) Ejercicios, demostrar: \\(P(A^c)=1-P(A)\\) \\(P(A \\cup B)=P(A)+P(B)-P(A\\cap B)\\), para cualesquiera eventos \\(A\\), \\(B\\) 2.5.4 Espacios equiprobables Sea \\(\\Omega\\) un espacio muestral finito de tamaño \\(n\\), \\[\\Omega=\\{w_1,w_2,\\ldots,w_n\\}\\] Definición: Es una función que asigna las mismas probabilidades a todos los resultados del espacio muestral, es decir, todos los eventos simples tienen la misma probabilidad de ocurrencia. \\[P(w_1)=P(w_2)=\\ldots=P(w_n)=\\frac{1}{n}\\] Nota, tener en cuenta que \\(w_i \\cap w_j=\\emptyset\\) para \\(i\\neq j\\) dado que los \\(w_i\\) son eventos simples \\[P(w_1 \\cup w_2\\cup \\ldots \\cup w_n)=P(\\Omega)=1\\] \\[P(w_1 \\cup w_2\\cup \\ldots \\cup w_n)=P(w_1)+P(w_2)+\\ldots+P(w_n)=1\\] Ejemplo, el lazamiento de un dado legal genera un espacio muestral equiprobable. \\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\(P(1)=P(2)=\\ldots=P(6)=\\frac{1}{6}\\) Ejemplo. En un hipódromo 4 caballos, \\(A\\),\\(B\\),\\(C\\) y \\(D\\) compiten. Suponiendo que todos los caballos tienen la misma probabilidad de ganar, calcular: Probabilidad que gane el caballo \\(A\\). Resp. \\(P(ganaA)=1/4\\) Probabilidad que gane el caballo \\(A\\) o el caballo \\(D\\). Resp. el evento de interés es \\(A \\cup D\\), \\(P(A\\cup D)=P(A)+P(D)=1/4+1/4=1/2\\) En el ejemplo anterior, tomemos ahora lo siguiente: \\(A\\) tiene 2 veces mas probabilidades de ganar que \\(B\\); \\(B\\) tiene 2 veces mas probabilidad de ganar que \\(C\\) y \\(C\\) tiene 2 veces mas probabilidades de ganar que \\(D\\). Probabilidad que gane el caballo \\(A\\) Probabilidad que gane el caballo \\(A\\) o el caballo \\(D\\). Sean los eventos simples, \\(w_1=gA=GanaA\\), \\(w_2=gB=GanaB\\), \\(w=gC=GanaC\\) y \\(w_4=gD=GanaD\\) Sabemos que: \\(P(gA)=2*P(gB)=2*2*P(gC)=2*2*2*P(gD)=8*P(gD)\\) \\[P(gA)+P(gB)+P(gC)+P(gD)=1\\] \\[8*P(gD)+4*P(gD)+2*P(gD)+P(gD)=1\\] \\[P(gD)(8+4+2+1)=1\\] \\[P(gD)=\\frac{1}{15}\\] Asi, \\(P(gD)=1/15\\), \\(P(gC)=2/15\\), \\(P(gB)=4/15\\), \\(P(gA)=8/15\\) \\(P(gA)=8/15\\) \\(P(gA\\cup gD)=P(gA)+P(gD)=8/15+1/15=9/15\\) Ejemplo. Se lanza un par de dados legales simultaneamente, encontrar las probabilidades: La suma sea menor que 4 La suma sea 9 El resultado del primer dado sea mayor que el segundo \\(\\#\\Omega=36\\), \\(P(d1=i,d2=j)=1/36\\) para \\(i,j=1:6\\) Resp. \\[P((1,1)\\cup (1,2)\\cup (2,1))=P(1,1)+P(1,2)+P(2,1)=1/36+1/36,1/36=3/36=1/12\\] Resp. \\[P(suma=9)=\\frac{4}{36}\\] Resp. \\[P(d1&gt;d2)=\\frac{15}{36}=\\frac{5}{12}\\] Ejercicio (7, pg243). Un lote continene 10 piezas buenas, 4 con defectos menores y 2 con defectos mayores. Se extraen 2 piezas al azar. Calcular: 1. Calcular el tamaño del espacio muestral $\\#\\Omega=\\binom{16}{2}=120$ 2. Probabilidad que ambas sean perfectas \\[P(2perf)=\\frac{\\binom{10}{2}}{\\binom{16}{2}}=\\frac{45}{120}=\\frac{15}{40}=\\frac{3}{8}\\] 3. Probabilidad que por lo menos una sea perfecta \\[P(1perf \\cup 2perf)=P(1perf)+P(2perf)=\\frac{\\binom{10}{1}\\binom{6}{1}}{\\binom{16}{2}}+\\frac{3}{8}=\\frac{60}{120}+\\frac{3}{8}=\\frac{1}{2}+\\frac{3}{8}=\\frac{7}{8}\\] 4. Probabilidad que ninguna tenga un defecto mayorjihj 5. Probabilidad que ninguna sea perfecta Ejercicio (14, pg-244). Sea un dado, tal que la probabilidad de las distintas caras es proporcional al número de puntos inscritos en ellos. Hallar la probabilidad de obtener con este dado, un número par. \\[\\Omega=\\{1,2,3,4,5,6\\}\\] #relativar px&lt;-(1:6)/sum(1:6) sum(px[c(2,4,6)]) ## [1] 0.5714286 \\[P(2,4,6)=P(2 \\cup 4 \\cup 6 )=P(2)+P(4)+P(6)=0.095+0.19+0.286=0.571\\] Ejercicio (11, pg-244). Sea \\(\\Omega=\\{x \\in Z/ 1 \\leq x \\leq 200 \\}\\), donde \\(Z\\) es el conjunto de los números enteros. Encuentre las probabilidades de los siguiente eventos. + \\(A=\\{x \\in \\Omega / x \\text{ es divisible por }7 \\}\\) + \\(B=\\{x \\in \\Omega / x=3n+10, n\\in Z^+ \\}\\) + \\(C=\\{x \\in \\Omega / x^2+1\\leq 375 \\}\\) Para \\(P(A)\\) sum((1:200 %% 7)==0) ## [1] 28 \\[P(A)=\\frac{\\# A}{\\# \\Omega}=\\frac{28}{200}=0.14\\] Para \\(P(B)\\) n&lt;-1:100 sum((3*n+10)&lt;=200) ## [1] 63 \\[P(B)=\\frac{\\# B}{\\# \\Omega}=\\frac{63}{200}=0.315\\] \\[P(C)=\\frac{\\# C}{\\# \\Omega}=\\frac{19}{200}=0.095\\] 2.6 Probabilidad Condicional * Evaluamos dos eventos o más * Conocer como se altera o cambia la probabilidad de un evento a partir de la ocurrencia de otro Ejemplos. * ¿Cuál es la probabilidad de aprobar la materia X dado que se tiene una nota de 20/30 en el primer parcial? * Se lanza una moneda y después se lanza un dado , ¿Cuál es la probabilidad de obtener un 5 en el dado, si salió cara en la moneda? * Una urna contine 3 bolas rojas y 3 bolas blancas, se realiza una selección de 2 bolas de manera consecutiva y sin reemplazo ¿Cuál es la probabilidad de que la segunda bola sea roja, sabiendo que la primera bola fue blanca? Definición: Sean dos eventos \\(A\\) y \\(B\\), tal que \\(P(B)&gt;0\\), la probabilidad condicional de que ocurra el evento \\(A\\), dado que ha ocurrido el evento \\(B\\), se define por: \\[P(A/B)=\\frac{P(A \\cap B)}{P(B)}\\] Nota: Cualquier condición que se de entre las probabilidades, afecta directamente el expacio muestral, esto depende de la relacion entre los eventos. Ejercicio: En la carrera de Informática van a existir elecciones para el director de carrera, existen 3 frentes y estos son \\(A\\), \\(B\\), \\(C\\), la carrera esta compuesta por 3 grupos de estudiantes, los políticos, los académicos y el resto, la estructura de votación según un sondeo a 200 estudiantes es: + Los políticos (50), 20 votan por A, 20 votan por B y 10 votan por C + Los académicos que son (40), 10 votan por A, 10 votan por B y 20 votan por C + El resto (110), 30 votan por A, 50 votan por B y el resto vota por C A&lt;-rbind(c(20,20,10),c(10,10,20),c(30,50,30)) colnames(A)&lt;-c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;) rownames(A)&lt;-c(&quot;POL&quot;,&quot;ACA&quot;,&quot;RES&quot;) knitr::kable(addmargins(A)) A B C Sum POL 20 20 10 50 ACA 10 10 20 40 RES 30 50 30 110 Sum 60 80 60 200 Encuentre * ¿Cuál es la probabilidad de que un estudiante académico vote por C? \\[P(\\text{vote C}/academico)=\\frac{P(\\text{vote C} \\cap academico)}{P(academico)}=\\frac{\\frac{20}{200}}{\\frac{40}{200}}=\\frac{20}{40}=0.5\\] * ¿Cuál es la probabilidad de que un estudiante político vote por A? \\[P(\\text{vote A}/politico)=\\frac{20}{50}=0.4\\] * ¿Cuál es la probabilidad de que gane el candidato B en estudiantes? \\[P(\\text{gane B})=\\frac{80}{200}=0.4\\] * ¿Cuál es la probabilidad que un estudiante seleccionado al azar sea académico dado que votara por el candidato A? \\[P(academico/\\text{vote A})=\\frac{10}{60}=\\frac{1}{6}\\] Ejercicios: ¿Cuál es la probabilidad de aprobar la materia \\(X\\) dado que se tiene una nota de 20/30 en el primer parcial? Se lanza una moneda y después se lanza un dado , ¿Cuál es la probabilidad de obtener un 5 en el dado, si salió cara en la moneda? Una urna contine 3 bolas rojas y 3 bolas blancas, se realiza una selección de 2 bolas de manera consecutiva y sin reemplazo ¿Cuál es la probabilidad de que la segunda bola sea roja, sabiendo que la primera bola fue blanca? Ejemplo Se tiene la tabla de admisión de 356 estudiantes de la UMSA, de acuerdo a la carrera y su municipio de procedencia A&lt;-rbind(c(100,40,50,20),c(20,60,50,10),c(5,0,1,0)) colnames(A)&lt;-c(&quot;ING&quot;,&quot;ECO&quot;,&quot;INF&quot;,&quot;DER&quot;) rownames(A)&lt;-c(&quot;LAPAZ&quot;,&quot;ELALTO&quot;,&quot;VIACHA&quot;) knitr::kable(addmargins(A)) ING ECO INF DER Sum LAPAZ 100 40 50 20 210 ELALTO 20 60 50 10 140 VIACHA 5 0 1 0 6 Sum 125 100 101 30 356 Sea el experimento seleccionar a un estudiante al azar del grupo de 356. Cuál es la probabilidad que el estudiantes sea de la carrera de economía, sabiendo que vive en El Alto \\[P(ECO/ELALTO)=\\frac{60}{140}\\] Cuál es la probabilidad que el estudiantes sea de la carrera de informática, sabiendo que vive en La Paz \\[P(INF/LAPAZ)=\\frac{50}{210}\\] Cuál es la probabilidad que el estudiantes sea de Viacha, sabiendo que esta en la carrera de ingenieria. \\[P(VIACHA/ING)=\\frac{5}{125}\\] Cuál es la probabilidad que el estudiantes sea de Viacha ó de La Paz, sabiendo que esta en la carrera de ingenieria. \\[P(VIACHA\\cup LAPAZ /ING)=\\frac{P((VIACHA\\cup LAPAZ)\\cap ING)}{P(ING)}=\\frac{P((VIACHA\\cap ING)\\cup (LAPAZ\\cap ING))}{P(ING)}\\] \\[P(VIACHA\\cup LAPAZ /ING)=\\frac{P(VIACHA\\cap ING)+P(LAPAZ\\cap ING)}{P(ING)}\\] \\[P(VIACHA\\cup LAPAZ /ING)=P(VIACHA/ING)+P(LAPAZ/ING)=5/125+100/125=\\frac{105}{125}\\] Por el principio de que Viacha y La Paz son eventos mutuamente excluyentes (axioma 3) 2.6.1 Regla de la multiplicación \\[P(B/A)=\\frac{P(B\\cap A)}{P(A)}\\] \\[P(A \\cap B)=P(B)P(A/B)=P(A)P(B/A)\\] Teorema: La regla de la multiplicación Sean \\(A_1,A_2,\\ldots,A_k\\) eventos, de tal forma que: \\[P(A_1\\cap A_2 \\cap \\ldots \\cap A_{k-1})&gt;0\\] Entonces: \\[P(A_1\\cap A_2 \\cap \\ldots \\cap A_{k})=P(A_1)P(A_2/A_1)P(A_3/A_1\\cap A_2)\\ldots P(A_k/A_1 \\cap A_2 \\cap \\ldots A_{k-1}) \\] Tarea 1, demostrar: \\[P(A \\cap B \\cap C)=P(A)P(B/A)P(C/A\\cap B)\\] 2.6.2 Independencia de Eventos Definición: Sean los eventos A y B, estos son independientes si la ocurrencia de A no interfiere la ocurrencia de B y viceversa. Si A y B son independientes, \\[P(A\\cap B)=P(A)*P(B)\\] Ejemplo. Se lanza una moneda y después se lanza un dado , ¿Cuál es la probabilidad de obtener un 5 en el dado, si salió cara en la moneda? \\[P(D=5/C)=\\frac{P(D=5 \\cap C)}{P(C)}=\\frac{P(D=5)P(C)}{P(C)}=P(D=5)=1/6\\] Nota: Si A y B son independientes, entonces: \\[P(A/B)=P(A)\\] \\[P(B/A)=P(B)\\] Ejemplos, Dado que \\(P(A)=1/2\\), \\(P(B)=1/3\\), \\(P(A\\cap B)=1/4\\) \\(P(A \\cup B)=P(A)+P(B)-P(A\\cap B)=1/2+1/3-1/4=7/12\\) \\(P(A/B)=\\frac{P(A \\cap B)}{P(B)}=\\frac{1/4}{1/3}=3/4\\) \\(P(B/A)=\\frac{P(B\\cap A)}{P(A)}=\\frac{1/4}{1/2}=1/2\\) \\(P(B^C/A^C)=\\frac{P(B^C\\cap A^c)}{P(A^c)}=\\frac{P((A\\cup B)^c)}{1-P(A)}=\\frac{1-P(A\\cup B)}{1-P(A)}=\\frac{1-7/12}{1-1/2}=5/6\\) Ejercicio (5, pg 287). Un restaurante ofrece dos tipos de comida, ensalada o plato de carne. 20% de los clientes hombres prefieren la ensalada, 30% de las mujeres escogen carne, el 75% de los clientes son hombres. Considere los siguientes eventos. H: es hombre, M: es mujer, E: prefiere la ensalda, C: Prefiere Carne. Se pide calcular: \\(P(E/H)\\), \\(P(C/M)\\) \\(P(E \\cap H)\\), \\(P(C \\cap M)\\) \\(P(M/E)\\) Tarea 2: Resolver el ejercicio 6 de la página 287 del libro. Tarea 3: Leer del libro el desde el apartado 5.6.3 (Teorema de la probabilidad total y el teorema de bayes) hasta la página 267. 2.7 Teorema de la Probabilidad Total Probabilidad Total Sea \\(A_1,A_2,\\ldots ,A_n\\) un partición del espacio muestral, de tal forma que: \\(P(A_i)&gt;0\\) para todo \\(i=1, \\ldots,n\\). La partición representa que \\(U_{i=1}^n A_i=\\Omega\\) y \\(A_i \\cap A_j =\\emptyset\\) para todo \\(i\\neq j\\). Para cualquier evento \\(B \\in \\Omega\\). \\[P(B)=\\sum_{i=1}^n{P(A_i \\cap B)}=\\sum_{i=1}^n{P(A_i)P(B/A_i )}\\] Ejemplo: Suponer que la población del departamento de la Paz esta conformado por 55% de mujeres y 45 % de hombres. Supongamos que el 30% de los hombres y el 20% de las mujeres fuman. Determinar la probabilidad de que una persona fume. Solución: Sean los eventos: H: es hombre (\\(M^c\\)) M: es mujer (\\(H^c\\)) F: Fuma \\(F^c\\): No fuma Además, \\(P(M)=0.55\\), \\(P(H)=P(M^C)=0.45\\), \\(P(F/H)=0.3\\) y \\(P(F/M)=0.2\\), \\(P(F)=?\\). \\[P(F)=P(H)P(F/H)+P(M)P(F/M)=0.45*0.3+0.55*0.2=0.245\\] ¿Cuál es la probabilidad de no fumar en esta población? \\(P(F^c)=1-P(F)=1-0.245=0.755\\) 2.8 Teorema de Bayes Sea \\(A_1,A_2,\\ldots ,A_n\\) un partición del espacio muestral, de tal forma que: \\(P(A_i)&gt;0\\) para todo \\(i=1, \\ldots,n\\). Sea \\(B \\in \\Omega\\) un evento tal que todas las \\(P(B/A_i)\\) son conocidas. Entonces para cada \\(A_i\\) tenemos: \\[P(A_i/B)=\\frac{P(A_i)P(B/A_i)}{\\sum_{i=1}^n{P(A_i)P(B/A_i )}}\\] Forma simple: \\[P(A/B)=\\frac{P(A)P(B/A)}{P(B)}\\] Ejemplo: Un análisis de sangre de laboratorio es \\(95\\) por ciento efectivo en la detección de una determinada enfermedad, cuando de hecho está presente. Sin embargo, la prueba también arroja un resultado “falso positivo” para el 1 por ciento de las personas sanas evaluadas. (Es decir, si se evalúa a una persona sana, entonces, con una probabilidad de \\(0.01\\), el resultado de la prueba implicará que él o ella tiene la enfermedad). Si el \\(0.5\\) por ciento de la población realmente tiene la enfermedad, ¿cuál es la probabilidad de que una persona tenga la enfermedad dado que el resultado de la prueba es positivo? Solución: vamos a identificar los siguientes eventos: E: Se tiene la enfermedad \\(E^c\\): No se tiene la enfermedad T+: La prueba da positiva a la enfermedad T-: La prueba da negativa a la enfermedad Como dato tenemos: \\(P(E)=0.005\\), \\(P(E^c)=1-P(E)=0.995\\), tener o no la enfermedad es la partición dentro del problema. \\(P(T+/E)=0.95\\), \\(P(T+/E^C)=0.01\\). \\(P(E/T+)=¿?\\). \\[P(E/T+)=\\frac{P(E \\cap T+)}{P(T+)}=\\frac{P(E)P(T+/E)}{P(E)P(T+/E)+P(E^C)P(T+/E^C)}=\\frac{0.005*0.95}{0.005*0.95+0.995*0.01}=0.3231\\] El 32.31% de los pacientes que son diagnosticados con la enfermedad en realidad si estan enfermos. 2.9 Ejercicios. (Pg, 290. Ej: 22). Una de cada 10 personas de una población tiene tuberculosis. De las personas que tienen tuberculosis, el 80% reacciona positivamente a la prueba Y, mientras que el 30% de los que no tienen tuberculosis reaccionan positivamente. Una persona de la población es seleccionada aleatoriamente y la prueba Y es aplicada. ¿Cuál es la probabildad de que esa persona tenga tuberculosis, si reacciono positivamente a la prueba? Para el ejemplo anterior, determinar \\(P(T-/E^c).\\) "],
["tema-3-variables-aleatorias.html", "3 Tema 3: Variables aleatorias 3.1 Introducción a variable aleatoria 3.2 Función de probabilidad (densidad) 3.3 Función de distribución (acumulada) 3.4 Variables aleatorias discretas 3.5 Variables aleatorias continuas 3.6 Esperanza matemática 3.7 Varianza 3.8 Teorema de Markov 3.9 Desigualdad de Chebyshev 3.10 Función Generatriz de Momentos", " 3 Tema 3: Variables aleatorias El objetivo de este tema es aproximarnos a modelos probabilísticos con sus respectivos parámetros, esto nos ayudara a adaptar diversos problemas reales. 3.1 Introducción a variable aleatoria Definión: Sea \\(E\\) un experimento y \\(\\Omega\\) el espacio muestral asociado a este experimento. Una función \\(X: \\Omega \\rightarrow IR\\), de tal forma que a cada elemento \\(w \\in \\Omega\\) le asocia un número real \\(x=X(w)\\) se denomina variable aleatoria. Nota 1: En el fondo estamos implicando que ahora vamos a trabajar exclusivamente con números en la recta real, donde estos números tienen asociado una probabilidad de ocurrencia. Nota 2: Debemos distinguir dos aspectos respecto trabajar sobre la recta real, (1) se pueden definir valores discretos (2) se pueden definir valores continuos. \\(X\\) es la variable aleatoria (va), el dominio de \\(X\\) es todo \\(\\Omega\\), y el rango es un sub conjunto de la recta real, el rango lo vamo a denotar como \\(Rx\\). \\(Rx \\in IR\\) Ejemplo 1: Establecer la variable aleatoria detrás del experimento de lanzar dos dados y obtener la suma de las caras. Solución, \\(\\#\\Omega=36\\) \\[\\Omega=\\{(1,1),(1,2),(1,3),(1,4),\\ldots,(6,6)\\}\\] \\[X: \\{X(1,1)=2,X(1,2)=3,\\ldots,X(6,6)=12\\}\\] El recorrido de \\(X\\), \\(Rx=\\{2, 3, \\ldots,12 \\}\\) Ejemplo 2: Sea el experimento lanzar 3 monedas y observar el resultado y definir la variable aleatoria como la cantidad de caras que salen en los lanzamientos. Solución, sean los eventos \\(C=cara\\), \\(S=Sello\\) \\[\\Omega=\\{(CCC),(CCS),(CSC),(SCC),(CSS),(SCS),(SSC),(SSS) \\}\\] \\[X: \\{X(CCC)=3,X(CCS)=2,X(CSC)=2,\\ldots,X(SSS)=0 \\}\\] A partir de esto, \\(Rx=\\{0,1,2,3\\}\\) 3.2 Función de probabilidad (densidad) Definión: Sea \\(X: \\Omega \\rightarrow IR\\), una va que toma los valores \\(x_1,x_2, \\ldots\\),. Se dice que \\(P(x_i)\\) es una función de probabilidad o distribución de probabilidad de la variable aleatoria \\(X\\). Si a cada valor de \\(x_i\\) se le asigna una probabilidad de ocurrencia. \\[P(x_i)=P(X=x_i)=P(w\\in \\Omega/X(w)=x_i)\\] Ejemplo 1: Para el ejemplo de las monedas, podemos calcular lo siguiente: \\[\\begin{array} &amp; &amp; P(X=0)=\\frac{1}{8}\\\\ &amp; P(X=1)=\\frac{3}{8}\\\\ &amp; P(X=2)=\\frac{3}{8}\\\\ &amp; P(X=3)=\\frac{1}{8}\\\\ \\end{array} \\] X 0 1 2 3 \\(P(X=x)\\) 1/8 3/8 3/8 1/8 Tomar en cuenta que: \\[\\sum_{Rx}P(X=x_i)=1\\] Ejercicio: Construir la distribución de probabilidad para el ejemplo del lanzamiento de los 2 dados. X 2 3 4 5 6 7 8 9 10 11 12 \\(P(X=x)\\) 1/36 2/36 3/36 4/36 5/36 6/36 5/36 4/36 3/36 2/36 1/36 1 A partir de la tabla calcular las siguientes probabilidad: \\(P(X\\leq 6)=P(X=2)+P(X=3)+P(X=4)+P(X=5)+P(X=6)=15/36\\) \\(P(X\\leq 7)=21/36\\) \\(P(X\\geq 7)=1-P(X&lt;7)=1-P(X\\leq 6)=1-\\frac{15}{36}=21/36\\) \\(P(X\\leq 2)=P(X=2)=1/36\\) \\(P(X &gt; 2)=1-P(X \\leq 2)=1-\\frac{1}{36}=\\frac{35}{36}\\) 3.3 Función de distribución (acumulada) Nota: Es muy similar a lo que se vio en la parte de estadística descriptiva cuando se calculo las frecuencias relativas/absolutas acumuladas. Definición: La función de distribución acumulada de una va \\(X\\), denotada por \\(F(X)\\), es una función: \\(F: IR \\rightarrow [0,1]\\), esta esta definida como: \\[F(X)=P(X\\leq x)\\] Propiedades de \\(F(X)\\) Es una función no decreciente, si \\(x_i&lt;x_j\\), entonces \\(F(x_i)&lt;F(x_j)\\), \\(i\\neq j\\) \\(F(x)\\) es una función continua por la derecha \\[lim+_{x\\rightarrow x_0} F(x)=F(x_0) \\] * \\(lim_{x\\rightarrow -\\infty} F(x)=0\\), \\(lim_{x\\rightarrow +\\infty} F(x)=1\\), \\(F(-\\infty)=0\\), \\(F(+\\infty)=1\\) Ejemplo: Para el caso de los dados X 2 3 4 5 6 7 8 9 10 11 12 \\(P(X=x)\\) 1/36 2/36 3/36 4/36 5/36 6/36 5/36 4/36 3/36 2/36 1/36 1 \\(F(x)=P(X\\leq x)\\) 1/36 3/36 6/36 10/36 15/36 21/36 26/36 30/36 33/36 35/36 1 Ejercicios, Página 315 del libro, resolver los ejercicios 1 y 2. Propiedades, si existe un \\(a&lt;b\\) Caso discreto \\(P(a&lt; X \\leq b )=F(b)-F(a)\\) \\(P(a\\leq X \\leq b )=F(b)-F(a)+P(X=a)\\) \\(P(a &lt; X &lt; b )=F(b)-F(a)-P(X=b)\\) \\(P(X&gt;b)=1-P(X\\leq b)=1-F(b)\\) Ejercicio 1 pg-315, \\(Rx=\\{-2,0,1,4\\}\\), \\(P(X=-2)=0.4\\), \\(P(X=0)=0.1\\), \\(P(X=1)=0.3\\) y \\(P(X=4)=0.2\\). Encontrar a \\(F(X)\\) X -2 0 1 4 TOTAL P(X=x) 0.4 0.1 0.3 0.2 1 P(X&lt;=x)=F(X) 0.4 0.5 0.8 1 \\(P(X&gt;0)=P(X=1)+P(X=4)=0.5\\), \\(P(X&gt;0)=1-P(X\\leq 0)=1-F(0)=1-0.5=0.5\\) \\(P(0&lt;X&lt;1)=0\\), \\(P(0&lt;X&lt;1)=F(1)-F(0)-P(X=1)=0.8-0.5-0.3=0\\) \\(P(0\\le X \\leq 1)=F(1)-F(0)+P(X=0)=0.8-0.5+0.1=0.4\\) Ejercio 2 pg 315. Una moneda es lanzada repetidamente hasta obtener cara por primera vez, Sea \\(X\\) la va que denota el número de lanzamientos que son necesarios para obtener cara por primera vez. \\(F(X)\\) Solución, definir el \\(Rx=\\{1,2, \\ldots , \\infty\\}\\) X 1 2 3 4 5 6 … i P(X=x) 0.5 0.25 0.125 0.5^4 0.5^5 0.5^6 … 0.5^i F(X)=P(X&lt;=x) 0.5 0.75 0.875 \\(P(C)=0.5\\), \\(P(S_1\\cap C_2)=P(S_1)*P(C_2/S_1)=0.5*0.5=0.25\\), \\(P(S_1\\cap S_2 \\cap C_3)=0.5*0.5*0.5=0.125\\), Asi, \\[P(X=x)=0.5^x\\] \\[\\sum_{Rx}{P(X=x)}=1, \\sum_{x=1}^\\infty{0.5^x}=1 \\] \\[F(X)=P(X\\leq x)=P(X \\leq t)=\\sum_{Rx}^t{P(X=x)}=\\sum_{x=1}^t{0.5^x}=TAREA\\] Caso continuo \\(P(a&lt;X&lt;b)=P(a\\leq X \\leq b)=P(a\\le X &lt;b)=F(b)-F(a)\\) 3.4 Variables aleatorias discretas El recorrido es discreto, numerable \\(\\sum_{Rx}P(X=x)=1\\) Distribución acumulada: \\[F(t)=P(X\\leq t)=\\sum_{min Rx}^t{P(X=x)}\\] 3.5 Variables aleatorias continuas El recorrido es continuo, no numerable Sea \\(f(x)\\) una función continua definida en \\(Rx\\), esta es una función de probabilidad (densidad), si cumple: \\[\\int_{Rx}f(x)dx=1\\] Distribución acumulada \\[F(t)=P(X\\leq t)= \\int_{-\\infty,minRx}^t{f(x)dx} \\] Sea \\(c\\) una constante cualquiera, \\(P(X=c)=0\\) sea \\(a&lt;b\\), \\(P(a&lt;X&lt;b)=F(b)-F(a)\\), támbien: \\[P(a&lt;x&lt;b)=\\int_a^b f(x)dx\\] \\(f(x)= \\frac{d F(X)}{dx}=F&#39;(x)\\) Ejemplo, Sea \\(X\\) una va con función de densidad dada por: \\[f(x)=c (6x-2x^2), x\\in [0,2]\\] Encontrar el valor de \\(c\\) para que la función se una funcion de probabilidad. Solución, \\[\\int_0^2 f(x)dx=1\\] $$ \\begin{array} &amp; _0^2 c (6x-2x^2)dx &amp; = c (_0^2 6x dx-_0^2 2x^2 dx )\\ &amp; = c ( 6 /_0^2- 2 /_0^2 )\\ &amp; = c ( 3 x^2/_0^2- /_0^2 )\\ &amp; = c ( 3 x^2- )/_0^2\\ &amp; = c (12-16/3 )\\ &amp; = c =1\\ \\end{array} $$ Entonces, \\(C=3/20\\). \\[f(x)=\\frac{3}{20} (6x-2x^2), x\\in [0,2]\\] Tarea: Realizar los ejercicios 1, 2 y 3 de la pg 345 del libro guía. 3.6 Esperanza matemática Es el valor esperado detrás de la variable aleatoria. Nota: vamos a introducir al operador Esperanza (E) Caso Discreto \\[E[X]=\\sum_{Rx}xP(X=x)\\] El operador esperanza funciona: \\[E[g(x)]=\\sum_{Rx}{g(x)*P(X=x)}\\] Calcule \\(E[X^2]\\), \\[E[X^2]=\\sum_{Rx}{X^2*P(X=x)}\\] Ejemplos: Para el caso de la suma del lanzamiento de dos dados \\[E[X]=2*\\frac{1}{36}+3*\\frac{2}{36}+\\ldots+12*\\frac{1}{36}=7\\] Caso Continuo \\[E[X]=\\int_{Rx} xf(x)dx\\] El operador esperanza: \\[E[g(x)]=\\int_{Rx}g(x)f(x)dx\\] \\[E[X^2]=\\int_{Rx}{x^2 f(x)dx}\\] Ejemplo, encontrar la esperanza matemática de la última función continua vista. \\[f(x)=\\frac{3}{20} (6x-2x^2), x\\in [0,2]\\] La esperanza matemática esta dada por: \\[E[X]=\\int_0^2{x\\frac{3}{20} (6x-2x^2)dx}=\\] \\[E[X]=\\frac{3}{20}\\int_0^2{6x^2-2x^3dx}=\\frac{3}{20}\\left( 2x^3-\\frac{x^4}{2} \\right)_0^2=\\frac{3}{20}(16-8)=\\frac{24}{20}=\\frac{6}{5}\\] fx&lt;-function(x){ y&lt;-(3/20)*(6*x-2*x^2) return(y) } curve(fx,xlim=c(0,2)) abline(v=c(6/5),col=&quot;red&quot;) \\[P(0.5&lt;X&lt;1.5)=\\int_{0.5}^{1.5}f(x)dx\\] 3.6.1 Propiedades Sean \\(a\\), \\(b\\), \\(c\\) constantes \\(E[0]=0\\) \\(E[a]=a\\) \\[E[a]=\\sum_{Rx}{a*P(X=x)}=a\\sum_{Rx}P(X=x)=a*1=a\\] \\(E[aX]=aE[X]\\) \\(E[h(x)+g(x)]=E[h(x)]+E[g(x)]\\) La esperanza se distribuye en la suma \\[E[h(x)+g(x)]=\\int_{Rx}[h(x)+g(x)]*f(x)dx=\\int_{Rx}h(x)f(x)dx+\\int_{Rx}g(x)f(x)dx=E[h(x)]+E[g(x)]\\] \\(E[X+Y]=E[X]+E[Y]\\) \\(E[aX+bY]=aE[X]+bE[Y]\\) 3.7 Varianza La varianza de define a partir del operador esperanza como: \\[V(X)=E[ \\left( X-E[X] \\right)^2]\\] Caso discreto \\[V(X)=E[ \\left( X-E[X] \\right)^2]=\\sum_{Rx} \\left( x-E[X] \\right)^2 * P(X=x)\\] Caso continuo \\[V(X)=E[ \\left( X-E[X] \\right)^2]=\\int_{Rx} \\left( x-E[X] \\right)^2 * f(x)dx\\] Forma corta para el calculo de la varianza: \\[V(X)=E[X^2]-E[X]^2\\] Demostración: \\[V(X)=E[ \\left( X-E[X] \\right)^2]=E[X^2-2XE[X]+E[X]^2]=E[X^2]-2E[X]E[X]+E[X]^2=\\] \\[= E[X^2]-2E[X]^2+E[X]^2=E[X^2]-E[X]^2\\] Ejercicio: calcular la varianza para el caso continuo visto anteriormente. \\[E[X^2]=\\int_0^2{x^2 f(x)dx}\\] 3.7.1 Propiedades Sean \\(a\\), \\(b\\) y \\(c\\) contantes \\(V(a)=0\\) \\[V(a)=E[a^2]-E[a]^2=a^2-a^2=0\\] \\(V(aX)=a^2V(X)\\) \\[V(aX)=E[(aX)^2]-E[aX]^2=a^2E[X^2]-(aE[X])^2=a^2E[X^2]-a^2 E[X]^2=a^2(E[X^2]-E[X]^2)=a^2 V(X)\\] \\(V(a+X)=V(X)\\) Tarea \\(V(a+bX)=b^2 V(X)\\) Tarea 3.8 Teorema de Markov Si \\(X\\) es una va, tal que \\(X\\geq 0\\), \\(P(X\\geq 0)=1\\), entonces, para cualquier constante \\(a&gt;0\\). Se tiene: \\[P(X \\geq a) \\leq \\frac{E[X]}{a}\\] Demostración \\[E[X]=\\int_{Rx}xf(x)dx=\\int_0^{\\infty}{xf(x)}dx=\\int_0^a{xf(x)dx}+\\int_a^{\\infty}{xf(x)dx} \\geq \\int_a^{\\infty}{xf(x)dx}\\] \\[E[X]\\geq\\int_a^{\\infty}{xf(x)dx} \\geq \\int_a^{\\infty}{a f(x)dx} = a \\int_a^{\\infty}{ f(x)dx} = a P(X\\geq a)\\] \\[E[X]\\geq a P(X\\geq a)\\] \\[P(X\\geq a) \\leq \\frac{E[X]}{a}\\] 3.9 Desigualdad de Chebyshev Si \\(X\\) es una va con media \\(E[X]=\\mu\\) (finita) y varianza \\(V(X)=\\sigma^2\\) (finita), entonces para cualquier número \\(k&gt;0\\) se cumple: \\[P(|X-\\mu|\\geq k) \\leq \\frac{V(x)}{k^2}\\] \\[P(|X-\\mu|\\geq k \\sigma) \\leq \\frac{1}{k^2}\\] Demostración \\[P(|X-\\mu|\\geq k)=P((X-\\mu)^2\\geq k^2)\\leq \\frac{E[(X-\\mu) ^2]}{k^2}=\\frac{E[(X-E[X]) ^2]}{k^2}=\\frac{V(X)}{k^2}\\] Ejermplos. Se conoce en base al curso de verano pasado de la materia de estadística I, que el promedio de notas fue de 65 puntos. Si suponemos un rendimiento similar en este semestre de los estudiantes inscritos. ¿Cuál es la probabilidad que un estudiante obtenga una nota mayor a 75? (Al menos la probabilidad máxima) Solución. \\(X:\\) La nota de los estudiantes de la materia de Estadística I en este semestre, el recorrido de \\(X\\) es \\(X\\geq 0\\). \\(E[X]=65\\) \\[P(X \\geq 75) =\\int_{75}^{\\infty}{f(x)dx}=\\sum_{x=75}^{100}{P(X=x)}\\] Dado que no conocemos \\(f(x)\\) o \\(P(X=x)\\) para \\(x\\geq0\\), recurrimo a el teorema de Markov \\[P(X\\geq 75) \\leq \\frac{E[X]}{a}=\\frac{65}{75}=0.867\\] La probabilidad que un estudiantes obtenga una nota mayor o igual a 75, necesariamente es menor a 0.867. Cuál sera la probabilidad que un estudiantes obtenga una nota mayor o igual a 90 puntos. \\[P(X\\geq90)\\leq \\frac{65}{90}=0.7222\\] Se sabe también que la varianza alcanzada en el curso de verano fue de 36, ¿Qué puede decirse de la probabilidad de que un estudiante tenga un puntaje entre 55 y 75? Solucion, La varianza de \\(X\\), es \\(V(X)=36\\) \\[P(55 \\leq X \\leq 75)=P(55-65\\leq X-\\mu \\leq75-65)=P(-10 \\leq X-\\mu \\leq 10)=P(|X-\\mu|\\leq10)\\] \\[P(|X-\\mu|\\leq10)=1-P(|X-\\mu|&gt;10)=1-P(|X-\\mu|\\geq10)\\] Suponiendo que \\(X\\) es continua \\[P(|X-\\mu|\\geq10) \\leq \\frac{36}{10^2}=0.36\\] \\[P(55 \\leq X \\leq 75)=P(|X-\\mu|\\leq10)\\leq 1-0.36=0.64 \\] 3.10 Función Generatriz de Momentos \\[M_X(t)=E[ e^{tx}]\\] \\[M_X^{(n)}(t=0)= \\left\\{ \\frac{\\partial^n}{\\partial t^n} E[ e^{tx}] \\right\\}_{t=0}=E[x^n] \\] "],
["tema-4-distribuciones-discretas.html", "4 Tema 4: Distribuciones Discretas 4.1 Bernoulli 4.2 Binomial 4.3 Geométrica 4.4 Binomial Negativa 4.5 Hipergeométrica 4.6 Poisson", " 4 Tema 4: Distribuciones Discretas 4.1 Bernoulli Sea \\(X\\) una v.a, se dice que \\(X\\sim Bernoulli(p)\\) si su función de probabilidad es: \\[p(x)=P(X=x)= p^x (1-p)^{1-x} \\hspace{0.5cm}; x=\\{0,1\\}\\] Probabilidad de exito \\(P(X=0)=p^0(1-p)^{1-0}=1-p\\), Probabilidad de fracaso \\(P(X=1)=p^1(1-p)^{1-1}=p\\). Ejemplo, Sea el experimento lanzar una moneda y la variable aleatoria X\\(=\\)Sale Cara \\(X=1\\) cuando salga cara, \\(X=0\\) cuando no salga cara, si suponemos que la moneda es legal, \\(p=0.5\\). \\(X\\sim Bernoulli(p=0.5)\\) Sea el experimento lanzar dos dados y sumar el resultados de las caras, si definimos la variable aleatoria como \\(X=1\\) cuando la suma es 12 y \\(X=0\\) en otro caso, en este caso el valor de \\(p=1/36\\), \\(X\\sim Bernoulli(p=1/36)\\) Donde; \\[E[x]=p\\] Demostración: \\[E(X)=\\sum_{Rx}xP(X=x)= 0*(1-p)+1*p=p\\] \\[V[x]=p*(1-p)\\] \\[E[X^2]=\\sum_{Rx}x^2P(X=x)=0^2 (1-p)+1^2p=p\\] \\[V(X)=E[X^2]-E[X]^2=p-p^2=p(1-p)\\] 4.1.1 Usos Bernoulli \\(X\\) representa éxito (\\(X=1\\)) o fracaso (\\(X=0\\)) en la realización de un proceso al azar. Con \\(p\\) la probabilidad de éxito \\(0&lt;p&lt;1\\). 4.2 Binomial Sea \\(X\\) una v.a, se dice que \\(X\\sim Binomial(n,p)\\) si su función de probabilidad es: \\[p(x)=P(X=x)= {n \\choose x} p^x (1-p)^{n-x} \\hspace{0.5cm}; x=\\{0,1,\\ldots,n\\}\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =n*p\\\\ V[x] &amp; =n*p*(1-p)\\\\ M_X(t) &amp; =(p*e^t+(1-p))^n \\end{array} \\] 4.2.1 Usos Binomial \\(X\\) representa el número de éxitos en \\(n\\) ensayos independientes Bernoullis. Con \\(p\\) la probabilidad de éxito \\(0&lt;p&lt;1\\) en un ensayo bernoulli. 4.2.2 Ejemplos Un estudiantes rinde un examen con 10 preguntas de opción múltiple, donde cada pregunta contiene hasta 5 alternativas de respuesta, donde solo una es correcta. Si el estudiantes responde las preguntas al azar, defina la distribución de probabilidad que modela el problema y calcula la probabilidad que el estudiante; Conteste todas las preguntas de forma incorrecta Conteste todas las preguntas de forma correcta Obtenga más de la mitad de las respuestas correctas Respuesta, X: El número de preguntas respondidas de forma correcta, \\(X\\sim Binomial(n=10,p=1/5)\\) \\[P(X=0)={n \\choose x} p^x (1-p)^{n-x}={10 \\choose 0} 0.2^0 (1-0.2)^{10-0}=0.107\\] \\[P(X=10)={n \\choose x} p^x (1-p)^{n-x}={10 \\choose 10} 0.2^{10} (1-0.2)^{10-10}=0.0000001024\\] \\[P(X&gt;5)=P(X=6)+P(X=7)+P(X=8)+P(X=9)+P(X=10)=\\sum_{x=6}^{10}{P(X=x)}=0.0064\\] Tarea La \\(E[X]=np=10*0.2=2\\), \\(V(X)=np(1-p)=npq=10*0.2*0.8=1.6\\), \\(\\sqrt{V(X)}=\\sqrt{1.6}=1.26\\) barplot(table(rbinom(100000,10,0.2))) Nota: Sea \\(X_1,X_2,\\ldots,X_n\\), donde \\(X_i \\sim Bernoulli(p)\\) para todo \\(i=1:n\\), si definimos a \\(Y=X_1+X_2+\\ldots+X_n\\), \\(Y\\sim Binomial(n,p)\\). \\[E[Y]=E[X_1+X_2+\\ldots+X_n]=E[X_1]+E[X_2]+\\ldots+E[X_n]=p+p+\\ldots+p=np\\] Para la varianza tarea Ejercicio, Supongamos que un jugador de basketball tiene una probabilidad de 7/9 de encestar un tiro libro y sus tiros son independientes. Si el consigue 5 tiros libres en un juego en particular. ¿Cuál es la probabilidad de que él enceste 2 o más tiros?. Solución: X: Número de tiros correctos, \\(X\\sim Binomial(n=5,p=7/9)\\), \\(Rx=\\{0,1,2,3,4,5\\}\\) \\[P(X\\geq 2)=\\sum_{x=2}^{x=5}{P(X=x)}=P(X=2)+P(X=3)+P(X=4)+P(X=5)\\] \\[P(X\\geq 2)=1-P(X&lt;2)=1-[P(X=0)+P(X=1)]=1- ( {5 \\choose 0} (7/9)^0 (1-7/9)^{5-0}+{5 \\choose 1} (7/9)^1 (1-7/9)^{5-1} )\\] \\[P(X\\geq2)=1-(0.00054+0.00948)=0.98997\\] 4.3 Geométrica Sea \\(X\\) una v.a, se dice que \\(X\\sim G(p)\\) si su función de probabilidad es: \\[p(x)=P(X=x)= p (1-p)^{x} \\hspace{0.5cm}; x=\\{0,1,\\ldots\\}\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =\\frac{(1-p)}{p}\\\\ V[x] &amp; =\\frac{(1-p)}{p^2}\\\\ M_X(t) &amp; = \\frac{p}{1-(1-p)*e^t} \\hspace{0.5cm} \\end{array} \\] 4.3.1 Usos Geométrica \\(X\\) representa el número de fracasos antes de obtener el primer éxito en ensayos sucesivos Bernoullis. Con \\(p\\) la probabilidad de éxito \\(0&lt;p&lt;1\\). 4.3.2 Ejemplos Se realiza el lanzamiento de una moneda legal, Sea X una va, donde X: El número de fracasos antes de sacar Cara por primera vez. Calcular la probabilidad de \\(X=10\\), \\(X=0\\), \\(X=5\\). Solución, \\(X\\sim G(p=0.5)\\). \\(P(X=10)=p (1-p)^x=0.5*0.5^{10}=0.00049\\) \\(P(X=0)=p (1-p)^x=0.5*0.5^0=0.5\\) \\(P(X=5)=0.5*0.5^5=0.0156=P(S_1\\cap S_2\\cap S_3\\cap S_4 \\cap S_5 \\cap C_6)=P(S)^5*P(C)\\) Una persona se compra un boleto de lotería cada mes, se conoce que en cada sorteo participan 100,000 boletos de lotería, 1) modele el problema, 2) calcule la probabilidad que esta persona gane la lotería el primer mes, 3) la probabilidad que gane la lotería en el mes 13, 4) La probabilidad que gane la lotería el primer año. 5) ¿Cuántos meses se espera hasta que esta persona gane la lotería? Solución, X: El número de meses antes de ganar la lotería, \\(X\\sim G(p=1/100000)\\) \\(P(X=0)=p(1-p)^x=p(1-p)^0=p=\\frac{1}{100000}\\) \\(P(X=12)=p(1-p)^{12}=1/100000*(1-1/100000)^{12}=0.000009998\\) \\(P(X=0)+P(X=1)+P(X=2)+\\ldots+P(X=11)=P(X&lt;12)=P(X\\leq11)=TAREA\\) \\(E[X]=\\frac{(1-p)}{p}=\\frac{1-1/100000}{1/100000}=99999\\), \\(V(X)=\\frac{1-p}{p^2}=9999900000\\), \\(\\sqrt{V(x)}=99999.5\\) 4.4 Binomial Negativa Sea \\(X\\) una v.a, se dice que \\(X\\sim BN(r,p)\\) si su función de probabilidad es: \\[p(x)=P(X=x)= {r+x-1 \\choose x} p^r (1-p)^{x} \\hspace{0.5cm}; x=\\{0,1,\\ldots\\}\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =\\frac{r*(1-p)}{p}\\\\ V[x] &amp; =\\frac{r*(1-p)}{p^2}\\\\ M_X(t) &amp; = \\left(\\frac{p}{1-(1-p)*e^t} \\right)^r \\hspace{0.5cm} ;t&lt;ln(1/(1-p)) \\end{array} \\] ### Usos Binomial Negativa \\(X\\) representa el número de fracasos antes de obtener \\(r\\) éxitos en ensayos sucesivos Bernoullis. Con \\(p\\) la probabilidad de éxito \\(0&lt;p&lt;1\\). 4.4.1 Ejemplo, (pg 471, 3). Una moneda correcta es lanzada sucesivamente hasta que aparezca cara por décima vez. Sea X la va que denota el número de sellos que ocurren. Hallar la función de probabilidad de \\(X\\). Solución, \\(X\\sim BN(r=10,p=0.5)\\) \\[P(X=x)= {9+x \\choose x} 0.5^{10} 0.5^x \\] Supongamos que una sucesión de lanzamientos independientes es hecho con una moneda, cuya probabilidad de obtener cara en cualquiera de los lanzamientos es de \\(1/30\\) ¿Cuál es la esperanza del número de sellos que se pueden obtener antes de que se obtengan 5 caras? ¿Cuál es la varianza del número de sellos que se pueden obtener antes de que se obtengan 5 caras? Solución, \\(X\\sim BN(r=5,p=1/30)\\), X: El número de sellos antes de obtener 5 caras \\(E[X]=\\frac{r*(1-p)}{p}=\\frac{5*(29/30)}{1/30}=145\\) \\(V(X)=\\frac{r*(1-p)}{p^2}=\\frac{5*(29/30)}{(1/30)^2}=4350\\), \\(\\sqrt{V(X)}=65\\) Tarea 1, Tres personas tiran monedas al aire y el disparejo paga el café. Si los tres resultados son iguales, las monedas se tiran nuevamente. Encuentre la probabilidad de que se necesitan menos de 4 intentos. (Pg: 476, 30) Nota: BN(r=1, p) = G(p) Tarea 2, Para la distribución geométrica, demostrar: \\[E[X]=\\frac{(1-p)}{p}\\] \\[E[X]=\\sum_{Rx}{x*P(X=x)}=\\sum_0^{\\infty}{xp(1-p)^x}=\\frac{(1-p)}{p}\\] 4.5 Hipergeométrica Sea \\(X\\) una v.a, se dice que \\(X\\sim H(N,n,r)\\) si su función de probabilidad es: \\[p(x)=P(X=x)= \\frac{{N-r \\choose n-x}{r \\choose x}}{{N \\choose n}} \\hspace{0.5cm}; max\\{0,n-N+r\\} \\leq x \\leq min\\{r,n\\}\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =n*\\frac{r}{N}\\\\ V[x] &amp; =n * \\frac{r}{N} * \\frac{N-r}{N} * \\frac{N-n}{N-1}\\\\ \\end{array} \\] 4.5.1 Usos Hipergeométrica \\(X\\) denota el número de elementos que poseen la característica \\(A\\) en una muestra aleatoria de tamaño \\(n\\) seleccionado de una población de \\(N\\) elementos de los cuales \\(r\\) tienen característica \\(A\\) y \\(N-r\\) característica \\(B\\). 4.5.2 Ejemplo En una urna con 30 bolas de colores (10 negras, 5 blancas, 15 verdes). Se seleccionan 7 bolas de forma aleatoria y sin reposición. Si el interés es calcular la probabilidad de obtener bolas negras: * Modelar la distribución que se ajusta al problema * Calcular la probabilidad que se seleccionen; 0 bolas negras, todas negras, al menos 2 bolas negras. Solución, \\(X\\sim H(N=30,n=7,r=10)\\), \\(max(0,7-30+10) \\leq x \\leq min(10,7)\\), \\(0 \\leq x \\leq 7\\) \\[P(X=0)=\\frac{{20 \\choose 7-x}{10 \\choose x}}{{30 \\choose 7}}=\\frac{{20 \\choose 7}{10 \\choose 0}}{{30 \\choose 7}}=\\frac{77520*1}{2035800}=\\frac{77520}{2035800}=0.038\\] \\[P(X=7)==\\frac{{20 \\choose 0}{10 \\choose 7}}{{30 \\choose 7}}=\\frac{120}{2035800}=0.000059\\] \\[P(X\\geq 2)=P(X=2)+P(X=3)+...+P(X=7)\\] \\[P(X\\geq 2)=1-P(X&lt;2)=1-[P(X=0)+P(X=1)]=1-0.038-\\frac{{20 \\choose 6}{10 \\choose 1}}{{30 \\choose 7}}=1-0.038-0.19=0.772\\] Tarea (Pg 459, Ej 8) 4.6 Poisson Sea \\(X\\) una v.a, se dice que \\(X\\sim P(\\lambda)\\), (\\(\\lambda&gt;0\\)) si su función de probabilidad es: \\[p(x)=P(X=x)= \\frac{e^{-\\lambda} \\lambda^x}{x!} \\hspace{0.5cm}; x=\\{0,1,2, \\ldots \\}\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =\\lambda\\\\ V[x] &amp; =\\lambda\\\\ M_X(t) &amp; =e^{\\lambda (e^t -1)} \\end{array} \\] 4.6.1 Usos Poisson \\(X\\) representa el número de eventos de cierto tipo, que ocurren en un intervalo de tiempo, o en una región, o en un volumen. Fallas de un computador en un día de operación Número de clientes que entran a un banco en un día dado Nota: Si \\(X \\sim binomial(n,p)\\), si \\(n \\rightarrow \\infty\\) , \\(p \\rightarrow 0\\) y \\(\\lambda=n*p\\) permanece constante. Entonces se puede aproximar con \\(X \\sim Poisson(\\lambda = n*p)\\). \\(n \\geq 50\\), \\(p\\leq 0.1\\). ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000 2.000 3.000 3.001 4.000 14.000 ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000 2.000 3.000 3.002 4.000 16.000 4.6.2 Ejemplos Cierta oficina de bomberos recibe en promedio 3 llamadas por día, calcular la probabilidad de que: Reciba 4 llamadas en un día Solución, X: Número de llamadas que recibe la oficina de bomberos en un día, \\(X\\sim P(\\lambda=3)\\) \\[P(X=4)=\\frac{e^{-\\lambda} \\lambda^x}{x!}=\\frac{e^{-3}3^4}{4!}=\\frac{4.0327}{24}=0.168\\] Reciba 3 o más llamadas en un día Solución, \\(X\\sim P(\\lambda=3)\\) \\[P(X\\geq 3)=1-P(X&lt;3)=1-[P(X=0)+P(X=1)+P(X=2)]=\\ldots\\] Reciba 10 llamadas en una semana (7 días) Solución, X: el número de llamadas a la oficina de bomberos durante 7 días. \\(X\\sim P(\\lambda=3*7=21)\\) \\[P(X=10)=\\frac{e^{-21}21^{10}}{10!}=0.00348\\] ¿Cuántas llamadas en promedio se espera tener durante un año (365 días)? Solución: 3*365=1095 Suponga que hay en promedio 2 suicidios por año en una población de 50 mil habitantes. En una ciudad de 100 mil habitantes. Encuentre la probabilidad de que en un año dado haya: Un suicidio 2 o más suicidios "],
["tema-5-distribuciones-continuas.html", "5 Tema 5: Distribuciones Continuas 5.1 Uniforme 5.2 Exponencial 5.3 Normal 5.4 Normal Estándar", " 5 Tema 5: Distribuciones Continuas 5.1 Uniforme Sea \\(X\\) una v.a, se dice que \\(X\\sim U(a,b)\\), con \\(a&lt;b\\). Si su función de densidad es: \\[f(x)=\\frac{1}{b-a} \\hspace{0.5cm}; x \\in [a,b]\\] Ejemplo, Sea \\(X\\) una va, donde \\(X\\sim U(a=2,b=4)\\). Dibuje la función y encuentre las probabilidades de: \\(P(2&lt;X&lt;3)\\) \\(P(3&lt;X&lt;4)\\) \\(P(X&lt;2.5)\\) Solución, \\[f(x)=\\frac{1}{4-2}=\\frac{1}{2}=0.5\\] \\[\\int_{Rx} f(x)dx=\\int_2^40.5 dx=0.5 x/_2^4=0.5*(4-2)=0.5*2=1\\] \\(P(2&lt;X&lt;3)=0.5\\) \\[P(2&lt;X&lt;3)=\\int_2^3 0.5dx=0.5*(3-2)=0.5\\] \\(P(3&lt;X&lt;4)=0.5\\) \\[P(3&lt;X&lt;4)=\\int_3^4 0.5dx=0.5*(4-3)=0.5\\] \\(P(X&lt;2.5)=0.25\\) \\[P(X&lt;2.5)=\\int_2^{2.5} 0.5dx=0.5*(2.5-2)=0.5*0.5=0.25\\] Donde; \\[\\begin{array}{ll} F(x) &amp; =\\frac{x-a}{b-a} \\\\ E[x] &amp; =\\frac{a+b}{2} \\\\ V[x] &amp; =\\frac{(b-a)^2}{12}\\\\ M_X(t) &amp; = \\frac{e^{bt}-e^{at}}{(b-a)*t} \\end{array} \\] Demostración, \\[F(t)=P(X&lt;t)=P(X\\leq t)=\\int_a^t \\frac{1}{b-a} dx=\\frac{1}{b-a}*x/_a^t=\\frac{t-a}{b-a}\\] Para una \\(x\\): \\[F(x)=\\frac{x-a}{b-a}\\] \\[P(X&lt;2.5)=F(2.5)=\\frac{2.5-2}{4-2}=\\frac{0.5}{2}=0.25\\] \\[E[X]=\\int_a^b x \\frac{1}{b-a} dx=\\frac{1}{b-a} \\frac{x^2}{2}/_a^b=\\frac{b^2-a^2}{2(b-a)}=\\frac{(b+a)(b-a)}{2(b-a)}=\\frac{a+b}{2}\\] Tarea, demostrar la varianza y la función generatriz de momentos. Un punto escogido al azar en el segmento de recta \\([1,4]\\). Calcular: * La probabilidad de que el punto escogido esté entre 2 y 3 * la probabilidad de que sea igual a 2 * la media y la varianza Solución, sea X una va, \\(X\\sim U(1,4)\\). \\(f(x)=\\frac{1}{3}\\) \\[P(2&lt;X&lt;3)=F(3)-F(2)=\\int_2^3\\frac{1}{3}dx=\\frac{1}{3}\\] \\[P(X=2)=0\\] \\(E[X]=\\frac{a+b}{2}=5/2=2.5\\), \\(V(X)=\\frac{(b-a)^2}{12}=\\frac{(4-1)^2}{12}=9/12=3/4\\) (TAREA) La clase de un profesor esta programada para comenzar a las 10:00 am; pero él comienza su clase en un tiempo \\(X\\) que tiene distribución uniforme en el intervalo de 9:55 am. a 10:05 am. ¿Cuál es la probabilidad de que él comience su clase: * 2 minutos más temprano? * 2 minutos más tarde? 5.2 Exponencial Sea \\(X\\) una v.a, se dice que \\(X\\sim exp(\\lambda)\\), con \\(\\lambda&gt;0\\) . Si su función de densidad es: \\[f(x)= \\lambda e^{-\\lambda x} \\hspace{0.5cm}; x&gt;0\\] Donde; \\[\\begin{array}{ll} F(x) &amp; = 1- e^{-\\lambda x} \\\\ E[x] &amp; =\\frac{1}{\\lambda}\\\\ V[x] &amp; =\\frac{1}{\\lambda^2}\\\\ M_X(t) &amp; = \\frac{\\lambda}{\\lambda-t} \\hspace{0.5cm}; t&lt;\\lambda \\end{array} \\] Demostrando algunas propiedades, \\[\\int_{Rx}f(x)dx=\\int_0^{\\infty}\\lambda*e^{-\\lambda x}dx=\\lambda \\int_0^{\\infty}e^{-\\lambda x}dx=\\lambda \\left(- \\frac{e^{-\\lambda x}}{\\lambda} \\right)/_0^{\\infty}=-e^{-\\infty}+e^0=-0+1=1\\] \\[M_X(t)=E[e^{tx}]=\\int_0^{\\infty} e^{tx}\\lambda e^{-\\lambda x}dx=\\lambda \\int_0^{\\infty} e^{-x(\\lambda-t)} dx=\\lambda \\left( -\\frac{e^{-x(\\lambda-t)}}{(\\lambda-t)} \\right)_0^{\\infty}=\\frac{\\lambda}{(\\lambda-t)}*(-e^{-\\infty (\\lambda-t)}+e^0)=\\frac{\\lambda}{\\lambda-t}\\] Esto se da, siempre y cuando \\(\\lambda-t&gt;0\\), \\(\\lambda&gt;t\\) Tarea, demostrar la \\(E[X]\\) y la \\(V(X)\\) a partir de la función generatriz de momentos. 5.2.1 Ejercicios, (pg525, 1) La duración de una lampara se distribuye exponencial con parámetro \\(\\lambda=1/100\\) (horas). Determinar: La probabilidad de que se queme antes de las 1000 horas La probabilidad de que se queme después de la duración media ¿Cuál es la desviación estándar de la distribución? Solución, sea \\(X\\) la va, que denota la duración en horas. \\(X\\sim exp(\\lambda=1/100)\\). \\[f(x)=\\frac{1}{100}e^{-\\frac{1}{100}x}; \\text{ } x&gt;0\\] \\[F(x) =P(X&lt;x) = 1- e^{-\\frac{1}{100} x}\\] La probabilidad de que se queme antes de las 1000 horas \\[P(X&lt;1000)=F(1000)=1-e^{-1000/100}=1-e^{-10}=0.9999546\\] La probabilidad de que se queme después de la duración media. \\[E[X]=\\frac{1}{\\lambda}=\\frac{1}{\\frac{1}{100}}=100\\] \\[P(X&gt;E[X])=P(X&gt;100)=1-P(X\\leq 100)=1-F(100)=1-(1-e^{-100/100})=\\] \\[=1-1+e^{-1}=e^{-1}=0.3679\\] ¿Cuál es la desviación estándar de la distribución? \\(\\sqrt{V(X)}\\) \\(\\sqrt{V(X)}=\\sqrt{\\frac{1}{\\lambda^2}}=1/\\lambda=100\\) Supongamos que el número de kilómetros que un carro puede recorrer antes que su batería se consuma, está exponencialmente distribuida con un promedio de 15000 kilómetros. Si una persona desea hacer una excursión de 10000 kilómetros. ¿Cuál es la probabilidad de que la persona complete la excursión sin que tenga que cambiar de batería del carro?. Solución, sea \\(X\\) la duración de la batería en kilómetros. \\(X\\sim exp(\\lambda=1/15000)\\). \\(E[X]=15000=1/\\lambda\\), entonces, \\(\\lambda=1/15000\\). \\[P(X&gt;10000)=tarea\\] 5.3 Normal Sea \\(X\\) una v.a, se dice que \\(X\\sim N(\\mu,\\sigma^2)\\) si su función de densidad es: \\[f(x)=\\frac{1}{\\sqrt{2\\pi} * \\sigma} e^{-\\frac{1}{2} \\left( \\frac{x-\\mu}{ \\sigma}\\right)^2 } \\hspace{0.5cm}; -\\infty \\leq x \\leq \\infty\\] Donde; \\[\\begin{array}{ll} E[x] &amp; =\\mu\\\\ V[x] &amp; =\\sigma^2\\\\ M_X(t) &amp; = e^{\\mu t +\\frac{1}{2} \\sigma^2 t^2} \\end{array} \\] 5.4 Normal Estándar Sea \\(x \\sim N(\\mu, \\sigma^2)\\), entonces \\(z=\\frac{x-\\mu}{\\sigma}\\) es una v.a, y se dice que \\(Z\\sim N(0,1)\\) es una normal estándar, si su función de densidad es: \\[f(x)=\\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} z^2 } \\hspace{0.5cm}; -\\infty \\leq z \\leq \\infty\\] Donde; \\[\\begin{array}{ll} E[z] &amp; =0\\\\ V[z] &amp; =1\\\\ M_Z(t) &amp; = e^{\\frac{1}{2} t^2} \\end{array} \\] ### Ejercicios \\[P(Z\\leq t)=P(Z&lt;t)=F(t)=\\phi(t)\\] Si \\(Z\\) en una va. \\(Z\\sim N(0,1)\\), calcular: \\(P(0&lt;Z&lt;1.44)=F(1.44)-F(0)=\\phi(1.44)-\\phi(0)=0.9251-0.5=0.4251\\) \\(P(-0.85&lt;Z&lt;0)=\\phi(0)-\\phi(-0.85)=0.5-0.1977=0.3023\\) \\(P(-1.48&lt;Z&lt;2.05)=\\phi(2.05)-\\phi(-1.48)=0.9798-0.0694=0.9104\\) \\(P(Z&lt;1.08)=F(1.08)=\\phi(1.08)=0.8599\\) \\(P(Z&gt;-0.66)=1-P(Z\\leq -0.66)=1-\\phi(-0.66)=1-0.2566=0.7434\\) Tarea: Revisar los ejercicios a partir de la página 511 "]
]
